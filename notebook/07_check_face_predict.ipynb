{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import torch\n",
    "import numpy as np\n",
    "import open3d as o3d\n",
    "import meshplot as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7003 1088\n"
     ]
    }
   ],
   "source": [
    "base_dir = os.path.dirname(os.getcwd())\n",
    "out_dir = os.path.join(base_dir, \"results\", \"models\")\n",
    "data_dir = os.path.join(base_dir, \"data\", \"original\")\n",
    "train_files = glob.glob(os.path.join(data_dir, \"train\", \"*\", \"*.obj\"))\n",
    "valid_files = glob.glob(os.path.join(data_dir, \"val\", \"*\", \"*.obj\"))\n",
    "print(len(train_files), len(valid_files))\n",
    "\n",
    "src_dir = os.path.join(base_dir, \"src\")\n",
    "sys.path.append(os.path.join(src_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils_polygen import load_pipeline\n",
    "from pytorch_trainer import Trainer, Reporter\n",
    "from models import FacePolyGenConfig, FacePolyGen, VertexPolyGenConfig, VertexPolyGen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_objfile(file_path):\n",
    "    vertices = []\n",
    "    normals = []\n",
    "    faces = []\n",
    "    \n",
    "    with open(file_path) as fr:\n",
    "        for line in fr:\n",
    "            data = line.split()\n",
    "            if len(data) > 0:\n",
    "                if data[0] == \"v\":\n",
    "                    vertices.append(data[1:])\n",
    "                elif data[0] == \"vn\":\n",
    "                    normals.append(data[1:])\n",
    "                elif data[0] == \"f\":\n",
    "                    face = np.array([\n",
    "                        [int(p.split(\"/\")[0]), int(p.split(\"/\")[2])]\n",
    "                        for p in data[1:]\n",
    "                    ]) - 1\n",
    "                    faces.append(face)\n",
    "    \n",
    "    vertices = np.array(vertices, dtype=np.float32)\n",
    "    normals = np.array(normals, dtype=np.float32)\n",
    "    return vertices, normals, faces\n",
    "\n",
    "def read_objfile_for_validate(file_path, return_o3d=False):\n",
    "    # only for develop-time validation purpose.\n",
    "    # this func force to load .obj file as triangle-mesh.\n",
    "    \n",
    "    obj = o3d.io.read_triangle_mesh(file_path)\n",
    "    if return_o3d:\n",
    "        return obj\n",
    "    else:\n",
    "        v = np.asarray(obj.vertices, dtype=np.float32)\n",
    "        f = np.asarray(obj.triangles, dtype=np.int32)\n",
    "        return v, f\n",
    "\n",
    "def write_objfile(file_path, vertices, normals, faces):\n",
    "    # write .obj file input-obj-style (mainly, header string is copy and paste).\n",
    "    \n",
    "    with open(file_path, \"w\") as fw:\n",
    "        print(\"# Blender v2.82 (sub 7) OBJ File: ''\", file=fw)\n",
    "        print(\"# www.blender.org\", file=fw)\n",
    "        print(\"o test\", file=fw)\n",
    "        \n",
    "        for v in vertices:\n",
    "            print(\"v \" + \" \".join([str(c) for c in v]), file=fw)\n",
    "        print(\"# {} vertices\\n\".format(len(vertices)), file=fw)\n",
    "        \n",
    "        for n in normals:\n",
    "            print(\"vn \" + \" \".join([str(c) for c in n]), file=fw)\n",
    "        print(\"# {} normals\\n\".format(len(normals)), file=fw)\n",
    "            \n",
    "        for f in faces:\n",
    "            print(\"f \" + \" \".join([\"{}//{}\".format(c[0]+1, c[1]+1) for c in f]), file=fw)\n",
    "        print(\"# {} faces\\n\".format(len(faces)), file=fw)\n",
    "        \n",
    "        print(\"# End of File\", file=fw)\n",
    "\n",
    "def validate_pipeline(v, n, f, out_dir):\n",
    "    temp_path = os.path.join(out_dir, \"temp.obj\")\n",
    "    write_objfile(temp_path, v, n, f)\n",
    "    v_valid, f_valid = read_objfile_for_validate(temp_path)\n",
    "    print(v_valid.shape, f_valid.shape)\n",
    "    mp.plot(v_valid, f_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lamp': 0, 'basket': 402, 'chair': 452, 'sofa': 2294, 'table': 3231}\n",
      "{'lamp': 0, 'basket': 60, 'chair': 66, 'sofa': 388, 'table': 517}\n"
     ]
    }
   ],
   "source": [
    "now_state = \"lamp\"\n",
    "indeces = {\n",
    "    \"lamp\": 0,\n",
    "}\n",
    "for i, path in enumerate(train_files):\n",
    "    state = path.split(\"/\")[9]\n",
    "    if now_state != state:\n",
    "        now_state = state\n",
    "        indeces[state] = i\n",
    "print(indeces)\n",
    "\n",
    "now_state = \"lamp\"\n",
    "indeces = {\n",
    "    \"lamp\": 0,\n",
    "}\n",
    "for i, path in enumerate(valid_files):\n",
    "    state = path.split(\"/\")[9]\n",
    "    if now_state != state:\n",
    "        now_state = state\n",
    "        indeces[state] = i\n",
    "print(indeces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode2files = {\n",
    "    0: train_files,\n",
    "    1: valid_files,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(58, 3) (18, 3) 31\n",
      "(174, 3) (112, 3)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "259c6698627b49dc8510057d43d0e6e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Renderer(camera=PerspectiveCamera(children=(DirectionalLight(color='white', intensity=0.6, position=(0.0, 0.0,…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mode = 0\n",
    "#idx = 458\n",
    "idx = 460\n",
    "#mode = 1\n",
    "#idx = 458\n",
    "vertices, normals, faces = read_objfile(mode2files[mode][idx])\n",
    "print(vertices.shape, normals.shape, len(faces))\n",
    "validate_pipeline(vertices, normals, faces, out_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(174, 3) (112, 3)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67502508f71b4d4793c60aeee8c74ba0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Renderer(camera=PerspectiveCamera(children=(DirectionalLight(color='white', intensity=0.6, position=(127.0, 12…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vs, ns, fs = load_pipeline(mode2files[mode][idx], remove_normal_ids=False)\n",
    "validate_pipeline(vs, ns, fs, out_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "src__max_seq_len changed, because of lsh-attention's bucket_size\n",
      "before: 2400 --> after: 2592 (with bucket_size: 48)\n",
      "tgt__max_seq_len changed, because of lsh-attention's bucket_size\n",
      "before: 5600 --> after: 5664 (with bucket_size: 48)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = FacePolyGenConfig(embed_dim=128, src__reformer__depth=9, tgt__reformer__depth=9)\n",
    "model = FacePolyGen(config)\n",
    "ckpt = torch.load(os.path.join(out_dir, \"model_epoch_47\"), map_location=torch.device('cpu'))\n",
    "model.load_state_dict(ckpt['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "174\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([57, 56, 53, 52, 55, 54, 50, 48, 46, 42, 43, 39, 40, 41, 44, 45, 47,\n",
       "        49, 51]),\n",
       " array([57, 51, 36, 38,  1,  7, 15, 11, 19, 23]),\n",
       " array([57, 23, 22, 56]),\n",
       " array([56, 22, 18, 53]),\n",
       " array([55, 52, 17, 21]),\n",
       " array([55, 21, 20, 54]),\n",
       " array([54, 20, 16,  8, 12,  4,  0, 37, 35, 50]),\n",
       " array([53, 18, 19, 11, 10,  3,  2,  9,  8, 16, 17, 52]),\n",
       " array([51, 49, 34, 36]),\n",
       " array([50, 35, 33, 48]),\n",
       " array([49, 47, 32, 34]),\n",
       " array([48, 33, 31, 46]),\n",
       " array([47, 45, 30, 32]),\n",
       " array([46, 31, 27, 42]),\n",
       " array([45, 44, 29, 30]),\n",
       " array([44, 41, 26, 29]),\n",
       " array([43, 42, 27, 28]),\n",
       " array([43, 28, 24, 39]),\n",
       " array([41, 40, 25, 26]),\n",
       " array([40, 39, 24, 25]),\n",
       " array([38, 37,  0,  1]),\n",
       " array([38, 36, 34, 32, 30, 29, 26, 25, 24, 28, 27, 31, 33, 35, 37]),\n",
       " array([23, 19, 18, 22]),\n",
       " array([21, 17, 16, 20]),\n",
       " array([15, 14, 10, 11]),\n",
       " array([15,  7,  6, 14]),\n",
       " array([14,  6,  3, 10]),\n",
       " array([13, 12,  8,  9]),\n",
       " array([13,  9,  2,  5]),\n",
       " array([13,  5,  4, 12]),\n",
       " array([7, 1, 0, 4, 5, 2, 3, 6])]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = {\"vertices\": [torch.tensor(vs)]}\n",
    "lengths = [len(f) for f in fs]\n",
    "print(sum(lengths))\n",
    "[f[:, 0] for f in fs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, tensor([57, 56, 53, 52, 55, 54, 50, 48, 46, 42, 43, 39, 40, 41, 45, 47, 49, 51])\n",
      "19, 20, 21, 22, 23, tensor([57, 51, 36, 49])\n",
      "24, 25, 26, 27, 28, tensor([57, 23, 22, 56])\n",
      "29, 30, 31, 32, 33, 34, 35, 36, 37, tensor([56, 22, 18, 10,  3,  2, 16, 20])\n",
      "38, 39, 40, 41, 42, tensor([55, 52, 17, 53])\n",
      "43, 44, 45, 46, 47, tensor([47, 32, 28, 43])\n",
      "48, 49, 50, 51, 52, tensor([47, 45, 30, 29])\n",
      "53, 54, 55, 56, 57, tensor([44, 40, 25, 39])\n",
      "58, 59, 60, 61, 62, 63, 64, tensor([41, 40, 25, 26, 29, 30])\n",
      "65, 66, 67, 68, 69, tensor([38, 37, 35, 36])\n",
      "70, 71, 72, 73, 74, tensor([23, 22, 21,  5])\n",
      "75, 76, 77, 78, 79, tensor([23, 19, 18, 22])\n",
      "80, 81, 82, 83, 84, tensor([19, 11, 10, 18])\n",
      "85, 86, 87, 88, 89, 90, 91, 92, 93, "
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    pred = model.predict(inputs, seed=0, max_seq_len=sum(lengths))\n",
    "    # pred = model.predict(inputs, seed=0, max_seq_len=83)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([57, 56, 53, 52, 55, 54, 50, 48, 46, 42, 43, 39, 40, 41, 45, 47, 49, 51]),\n",
       " tensor([57, 51, 36, 49]),\n",
       " tensor([57, 23, 22, 56]),\n",
       " tensor([56, 22, 18, 10,  3,  2, 16, 20]),\n",
       " tensor([55, 52, 17, 53]),\n",
       " tensor([47, 32, 28, 43]),\n",
       " tensor([47, 45, 30, 29]),\n",
       " tensor([44, 40, 25, 39]),\n",
       " tensor([41, 40, 25, 26, 29, 30]),\n",
       " tensor([38, 37, 35, 36]),\n",
       " tensor([23, 22, 21,  5]),\n",
       " tensor([23, 19, 18, 22]),\n",
       " tensor([19, 11, 10, 18]),\n",
       " tensor([ 7,  1,  0,  4, 12,  8,  3,  6])]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "faces = []\n",
    "for f in pred[:-1]:\n",
    "    if len(f) <= 2:\n",
    "        continue\n",
    "    f = f[:, None].repeat(1, 2)\n",
    "    faces.append(f.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcd = o3d.geometry.PointCloud()\n",
    "pcd.points = o3d.utility.Vector3dVector(vs)\n",
    "pcd.estimate_normals(\n",
    "    search_param=o3d.geometry.KDTreeSearchParamHybrid(radius=0.1, max_nn=30)\n",
    ")\n",
    "normals = np.asarray(pcd.normals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((58, 3), (58, 3))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vs.shape, normals.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(58, 3) (58, 3) 13\n",
      "(41, 3) (40, 3)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7ac96410a414ec4943f9afe0b9f196b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Renderer(camera=PerspectiveCamera(children=(DirectionalLight(color='white', intensity=0.6, position=(0.0, 0.0,…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(vs.shape, normals.shape, len(faces))\n",
    "validate_pipeline(vertices, normals, faces, out_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
