{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import open3d as o3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = os.path.dirname(os.getcwd())\n",
    "data_dir = os.path.join(base_dir, \"data\")\n",
    "src_dir = os.path.join(base_dir, \"src\")\n",
    "sys.path.append(os.path.join(src_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7003, 1088)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_files = glob.glob(os.path.join(data_dir, \"original\", \"train\", \"*\", \"*.obj\"))\n",
    "valid_files = glob.glob(os.path.join(data_dir, \"original\", \"val\", \"*\", \"*.obj\"))\n",
    "len(train_files), len(valid_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils_polygen import load_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tokenizer(object):\n",
    "    \n",
    "    def _padding(self, ids_tensor, pad_token, max_length=None):\n",
    "        if max_length is None:\n",
    "            max_length = max([len(ids) for ids in ids_tensor])\n",
    "        \n",
    "        ids_tensor = [\n",
    "            torch.cat([\n",
    "                ids, pad_token.repeat(max_length - len(ids) + 1)\n",
    "            ])\n",
    "            for ids in ids_tensor\n",
    "        ]\n",
    "        return ids_tensor\n",
    "    \n",
    "    def _make_padding_mask(self, ids_tensor, pad_id):\n",
    "        mask = torch.where(\n",
    "            ids_tensor==pad_id,\n",
    "            torch.ones_like(ids_tensor),\n",
    "            torch.zeros_like(ids_tensor)\n",
    "        ).type(torch.bool)\n",
    "        return mask\n",
    "\n",
    "    def _make_future_mask(self, ids_tensor):\n",
    "        batch, length = ids_tensor.shape\n",
    "        arange = torch.arange(length)\n",
    "        mask = torch.where(\n",
    "            arange[None, :] <= arange[:, None],\n",
    "            torch.zeros((length, length)),\n",
    "            torch.ones((length, length))*(-np.inf)\n",
    "        ).type(torch.float32)\n",
    "        return mask\n",
    "    \n",
    "    def get_pred_start(self, start_token=\"bos\", batch_size=1):\n",
    "        special_tokens = self.special_tokens\n",
    "        not_coord_token = self.not_coord_token\n",
    "        max_seq_len = self.max_seq_len\n",
    "        \n",
    "        values = torch.stack(\n",
    "            self._padding(\n",
    "                [special_tokens[start_token]] * batch_size, \n",
    "                special_tokens[\"pad\"],\n",
    "                max_seq_len\n",
    "            )\n",
    "        )\n",
    "        coord_type_tokens = torch.stack(\n",
    "            self._padding(\n",
    "                [self.not_coord_token] * batch_size,\n",
    "                not_coord_token,\n",
    "                max_seq_len\n",
    "            )\n",
    "        )\n",
    "        position_tokens = torch.stack(\n",
    "            self._padding(\n",
    "                [self.not_coord_token] * batch_size,\n",
    "                not_coord_token,\n",
    "                max_seq_len\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        padding_mask = self._make_padding_mask(values, self.pad_id)\n",
    "        \n",
    "        outputs = {\n",
    "            \"value_tokens\": values,\n",
    "            \"coord_type_tokens\": coord_type_tokens,\n",
    "            \"position_tokens\": position_tokens,\n",
    "            \"padding_mask\": padding_mask,\n",
    "        }\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([204, 3]) 160\n",
      "============================================================\n",
      "torch.Size([62, 3]) 45\n",
      "============================================================\n",
      "torch.Size([64, 3]) 601\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "v_batch, f_batch = [], []\n",
    "for i in range(3):\n",
    "    vs, _, fs = load_pipeline(train_files[i])\n",
    "    \n",
    "    vs = torch.tensor(vs)\n",
    "    fs = [torch.tensor(f) for f in fs]\n",
    "    \n",
    "    v_batch.append(vs)\n",
    "    f_batch.append(fs)\n",
    "    print(vs.shape, len(fs))\n",
    "    print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[166, 121, 166],\n",
       "        [166, 121,  88],\n",
       "        [166, 108, 166],\n",
       "        [166, 108,  88],\n",
       "        [165, 106, 165],\n",
       "        [165, 106,  89],\n",
       "        [165, 104, 165],\n",
       "        [165, 104,  89],\n",
       "        [165, 103, 165],\n",
       "        [165, 103,  89],\n",
       "        [164, 121, 164],\n",
       "        [164, 121,  90],\n",
       "        [164, 108, 164],\n",
       "        [164, 108,  90],\n",
       "        [164, 106, 164],\n",
       "        [164, 106,  90],\n",
       "        [164, 105, 164],\n",
       "        [164, 105,  90],\n",
       "        [164, 101, 164],\n",
       "        [164, 101,  90],\n",
       "        [163, 103, 163],\n",
       "        [163, 103,  91],\n",
       "        [163, 102, 163],\n",
       "        [163, 102,  91],\n",
       "        [163,  99, 163],\n",
       "        [163,  99,  91],\n",
       "        [162, 100, 162],\n",
       "        [162, 100,  92],\n",
       "        [162,  98, 162],\n",
       "        [162,  98,  92],\n",
       "        [161,  99, 161],\n",
       "        [161,  99,  93],\n",
       "        [160,  97, 160],\n",
       "        [160,  97,  94],\n",
       "        [159,  98, 159],\n",
       "        [159,  98,  95],\n",
       "        [159,  96, 159],\n",
       "        [159,  96,  95],\n",
       "        [158,  97, 158],\n",
       "        [158,  97,  96],\n",
       "        [157,  96, 157],\n",
       "        [157,  96,  97],\n",
       "        [157,  95, 157],\n",
       "        [157,  95,  97],\n",
       "        [155,  96, 155],\n",
       "        [155,  96,  99],\n",
       "        [155,  94, 155],\n",
       "        [155,  94,  99],\n",
       "        [153,  95, 153],\n",
       "        [153,  95, 101],\n",
       "        [153,  94, 153],\n",
       "        [153,  94, 101],\n",
       "        [152,  95, 152],\n",
       "        [152,  95, 102],\n",
       "        [152,  94, 152],\n",
       "        [152,  94, 102],\n",
       "        [131, 160, 161],\n",
       "        [131, 160, 160],\n",
       "        [131, 160, 159],\n",
       "        [131, 160,  95],\n",
       "        [131, 160,  94],\n",
       "        [131, 160,  93],\n",
       "        [131, 159, 163],\n",
       "        [131, 159, 162],\n",
       "        [131, 159, 161],\n",
       "        [131, 159, 160],\n",
       "        [131, 159, 159],\n",
       "        [131, 159,  95],\n",
       "        [131, 159,  94],\n",
       "        [131, 159,  93],\n",
       "        [131, 159,  92],\n",
       "        [131, 159,  91],\n",
       "        [131, 158, 164],\n",
       "        [131, 158, 162],\n",
       "        [131, 158,  92],\n",
       "        [131, 158,  90],\n",
       "        [131, 157, 165],\n",
       "        [131, 157, 164],\n",
       "        [131, 157, 163],\n",
       "        [131, 157,  91],\n",
       "        [131, 157,  90],\n",
       "        [131, 157,  89],\n",
       "        [131, 156, 165],\n",
       "        [131, 156, 164],\n",
       "        [131, 156,  90],\n",
       "        [131, 156,  89],\n",
       "        [131, 155, 165],\n",
       "        [131, 155, 164],\n",
       "        [131, 155,  90],\n",
       "        [131, 155,  89],\n",
       "        [131, 154, 166],\n",
       "        [131, 154, 164],\n",
       "        [131, 154,  90],\n",
       "        [131, 154,  88],\n",
       "        [131, 153, 166],\n",
       "        [131, 153, 164],\n",
       "        [131, 153,  90],\n",
       "        [131, 153,  88],\n",
       "        [131, 121, 166],\n",
       "        [131, 121, 164],\n",
       "        [131, 121,  90],\n",
       "        [131, 121,  88],\n",
       "        [123, 160, 161],\n",
       "        [123, 160, 160],\n",
       "        [123, 160, 159],\n",
       "        [123, 160,  95],\n",
       "        [123, 160,  94],\n",
       "        [123, 160,  93],\n",
       "        [123, 159, 163],\n",
       "        [123, 159, 162],\n",
       "        [123, 159, 161],\n",
       "        [123, 159, 160],\n",
       "        [123, 159, 159],\n",
       "        [123, 159,  95],\n",
       "        [123, 159,  94],\n",
       "        [123, 159,  93],\n",
       "        [123, 159,  92],\n",
       "        [123, 159,  91],\n",
       "        [123, 158, 164],\n",
       "        [123, 158, 162],\n",
       "        [123, 158,  92],\n",
       "        [123, 158,  90],\n",
       "        [123, 157, 165],\n",
       "        [123, 157, 164],\n",
       "        [123, 157, 163],\n",
       "        [123, 157,  91],\n",
       "        [123, 157,  90],\n",
       "        [123, 157,  89],\n",
       "        [123, 156, 165],\n",
       "        [123, 156, 164],\n",
       "        [123, 156,  90],\n",
       "        [123, 156,  89],\n",
       "        [123, 155, 165],\n",
       "        [123, 155, 164],\n",
       "        [123, 155,  90],\n",
       "        [123, 155,  89],\n",
       "        [123, 154, 166],\n",
       "        [123, 154, 164],\n",
       "        [123, 154,  90],\n",
       "        [123, 154,  88],\n",
       "        [123, 153, 166],\n",
       "        [123, 153, 164],\n",
       "        [123, 153,  90],\n",
       "        [123, 153,  88],\n",
       "        [123, 121, 166],\n",
       "        [123, 121, 164],\n",
       "        [123, 121,  90],\n",
       "        [123, 121,  88],\n",
       "        [102,  95, 152],\n",
       "        [102,  95, 102],\n",
       "        [102,  94, 152],\n",
       "        [102,  94, 102],\n",
       "        [101,  95, 153],\n",
       "        [101,  95, 101],\n",
       "        [101,  94, 153],\n",
       "        [101,  94, 101],\n",
       "        [ 99,  96, 155],\n",
       "        [ 99,  96,  99],\n",
       "        [ 99,  94, 155],\n",
       "        [ 99,  94,  99],\n",
       "        [ 97,  96, 157],\n",
       "        [ 97,  96,  97],\n",
       "        [ 97,  95, 157],\n",
       "        [ 97,  95,  97],\n",
       "        [ 96,  97, 158],\n",
       "        [ 96,  97,  96],\n",
       "        [ 95,  98, 159],\n",
       "        [ 95,  98,  95],\n",
       "        [ 95,  96, 159],\n",
       "        [ 95,  96,  95],\n",
       "        [ 94,  97, 160],\n",
       "        [ 94,  97,  94],\n",
       "        [ 93,  99, 161],\n",
       "        [ 93,  99,  93],\n",
       "        [ 92, 100, 162],\n",
       "        [ 92, 100,  92],\n",
       "        [ 92,  98, 162],\n",
       "        [ 92,  98,  92],\n",
       "        [ 91, 103, 163],\n",
       "        [ 91, 103,  91],\n",
       "        [ 91, 102, 163],\n",
       "        [ 91, 102,  91],\n",
       "        [ 91,  99, 163],\n",
       "        [ 91,  99,  91],\n",
       "        [ 90, 121, 164],\n",
       "        [ 90, 121,  90],\n",
       "        [ 90, 108, 164],\n",
       "        [ 90, 108,  90],\n",
       "        [ 90, 106, 164],\n",
       "        [ 90, 106,  90],\n",
       "        [ 90, 105, 164],\n",
       "        [ 90, 105,  90],\n",
       "        [ 90, 101, 164],\n",
       "        [ 90, 101,  90],\n",
       "        [ 89, 106, 165],\n",
       "        [ 89, 106,  89],\n",
       "        [ 89, 104, 165],\n",
       "        [ 89, 104,  89],\n",
       "        [ 89, 103, 165],\n",
       "        [ 89, 103,  89],\n",
       "        [ 88, 121, 166],\n",
       "        [ 88, 121,  88],\n",
       "        [ 88, 108, 166],\n",
       "        [ 88, 108,  88]], dtype=torch.int32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_batch[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tokenizer for vertex model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncodeVertexTokenizer(Tokenizer):\n",
    "    \n",
    "    def __init__(self, pad_id=0, max_seq_len=None):\n",
    "        self.pad_token = torch.tensor([pad_id])\n",
    "        self.pad_id = pad_id\n",
    "        \n",
    "        if max_seq_len is not None:\n",
    "            self.max_seq_len = max_seq_len - 1\n",
    "        else:\n",
    "            self.max_seq_len = max_seq_len\n",
    "        \n",
    "    def tokenize(self, vertices, padding=True):\n",
    "        max_seq_len = self.max_seq_len\n",
    "        vertices = [v.reshape(-1,) + 1 for v in vertices]\n",
    "        coord_type_tokens = [torch.arange(len(v)) % 3 + 1 for v in vertices]\n",
    "        position_tokens = [torch.arange(len(v)) // 3 + 1 for v in vertices]\n",
    "        \n",
    "        if padding:\n",
    "            vertices = torch.stack(self._padding(vertices, self.pad_token, max_seq_len))\n",
    "            coord_type_tokens = torch.stack(self._padding(coord_type_tokens, self.pad_token, max_seq_len))\n",
    "            position_tokens = torch.stack(self._padding(position_tokens, self.pad_token, max_seq_len))\n",
    "            padding_mask = self._make_padding_mask(vertices, self.pad_id)\n",
    "            \n",
    "            outputs = {\n",
    "                \"value_tokens\": vertices,\n",
    "                \"coord_type_tokens\": coord_type_tokens,\n",
    "                \"position_tokens\": position_tokens,\n",
    "                \"padding_mask\": padding_mask,\n",
    "            }\n",
    "        else:\n",
    "            outputs = {\n",
    "                \"value_tokens\": vertices,\n",
    "                \"coord_type_tokens\": coord_type_tokens,\n",
    "                \"position_tokens\": position_tokens,\n",
    "            }\n",
    "            \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_vtk = EncodeVertexTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'value_tokens': tensor([[167, 122, 167,  ..., 109,  89,   0],\n",
       "         [165, 164, 165,  ...,   0,   0,   0],\n",
       "         [165, 165, 128,  ...,   0,   0,   0]]),\n",
       " 'coord_type_tokens': tensor([[1, 2, 3,  ..., 2, 3, 0],\n",
       "         [1, 2, 3,  ..., 0, 0, 0],\n",
       "         [1, 2, 3,  ..., 0, 0, 0]]),\n",
       " 'position_tokens': tensor([[  1,   1,   1,  ..., 204, 204,   0],\n",
       "         [  1,   1,   1,  ...,   0,   0,   0],\n",
       "         [  1,   1,   1,  ...,   0,   0,   0]]),\n",
       " 'padding_mask': tensor([[False, False, False,  ..., False, False,  True],\n",
       "         [False, False, False,  ...,  True,  True,  True],\n",
       "         [False, False, False,  ...,  True,  True,  True]])}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_vtk.tokenize(v_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value_tokens :\n",
      "torch.Size([3, 613])\n",
      "tensor([[167, 122, 167, 167, 122,  89, 167, 109, 167, 167],\n",
      "        [165, 164, 165, 165, 164,  91, 165, 155, 165, 165],\n",
      "        [165, 165, 128, 164, 165, 128, 163, 165, 137, 163]])\n",
      "tensor([[ 89, 122,  89,  89, 109, 167,  89, 109,  89,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0]])\n",
      "============================================================\n",
      "coord_type_tokens :\n",
      "torch.Size([3, 613])\n",
      "tensor([[1, 2, 3, 1, 2, 3, 1, 2, 3, 1],\n",
      "        [1, 2, 3, 1, 2, 3, 1, 2, 3, 1],\n",
      "        [1, 2, 3, 1, 2, 3, 1, 2, 3, 1]])\n",
      "tensor([[1, 2, 3, 1, 2, 3, 1, 2, 3, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
      "============================================================\n",
      "position_tokens :\n",
      "torch.Size([3, 613])\n",
      "tensor([[1, 1, 1, 2, 2, 2, 3, 3, 3, 4],\n",
      "        [1, 1, 1, 2, 2, 2, 3, 3, 3, 4],\n",
      "        [1, 1, 1, 2, 2, 2, 3, 3, 3, 4]])\n",
      "tensor([[202, 202, 202, 203, 203, 203, 204, 204, 204,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0]])\n",
      "============================================================\n",
      "padding_mask :\n",
      "torch.Size([3, 613])\n",
      "tensor([[False, False, False, False, False, False, False, False, False, False],\n",
      "        [False, False, False, False, False, False, False, False, False, False],\n",
      "        [False, False, False, False, False, False, False, False, False, False]])\n",
      "tensor([[False, False, False, False, False, False, False, False, False,  True],\n",
      "        [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True]])\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "for k, vs in enc_vtk.tokenize(v_batch).items():\n",
    "    print(k, \":\")\n",
    "    print(vs.shape)\n",
    "    print(torch.stack([v[:10] for v in vs]))\n",
    "    print(torch.stack([v[-10:] for v in vs]))\n",
    "    print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'value_tokens': [tensor([167, 122, 167, 167, 122,  89, 167, 109, 167, 167, 109,  89, 166, 107,\n",
       "          166, 166, 107,  90, 166, 105, 166, 166, 105,  90, 166, 104, 166, 166,\n",
       "          104,  90, 165, 122, 165, 165, 122,  91, 165, 109, 165, 165, 109,  91,\n",
       "          165, 107, 165, 165, 107,  91, 165, 106, 165, 165, 106,  91, 165, 102,\n",
       "          165, 165, 102,  91, 164, 104, 164, 164, 104,  92, 164, 103, 164, 164,\n",
       "          103,  92, 164, 100, 164, 164, 100,  92, 163, 101, 163, 163, 101,  93,\n",
       "          163,  99, 163, 163,  99,  93, 162, 100, 162, 162, 100,  94, 161,  98,\n",
       "          161, 161,  98,  95, 160,  99, 160, 160,  99,  96, 160,  97, 160, 160,\n",
       "           97,  96, 159,  98, 159, 159,  98,  97, 158,  97, 158, 158,  97,  98,\n",
       "          158,  96, 158, 158,  96,  98, 156,  97, 156, 156,  97, 100, 156,  95,\n",
       "          156, 156,  95, 100, 154,  96, 154, 154,  96, 102, 154,  95, 154, 154,\n",
       "           95, 102, 153,  96, 153, 153,  96, 103, 153,  95, 153, 153,  95, 103,\n",
       "          132, 161, 162, 132, 161, 161, 132, 161, 160, 132, 161,  96, 132, 161,\n",
       "           95, 132, 161,  94, 132, 160, 164, 132, 160, 163, 132, 160, 162, 132,\n",
       "          160, 161, 132, 160, 160, 132, 160,  96, 132, 160,  95, 132, 160,  94,\n",
       "          132, 160,  93, 132, 160,  92, 132, 159, 165, 132, 159, 163, 132, 159,\n",
       "           93, 132, 159,  91, 132, 158, 166, 132, 158, 165, 132, 158, 164, 132,\n",
       "          158,  92, 132, 158,  91, 132, 158,  90, 132, 157, 166, 132, 157, 165,\n",
       "          132, 157,  91, 132, 157,  90, 132, 156, 166, 132, 156, 165, 132, 156,\n",
       "           91, 132, 156,  90, 132, 155, 167, 132, 155, 165, 132, 155,  91, 132,\n",
       "          155,  89, 132, 154, 167, 132, 154, 165, 132, 154,  91, 132, 154,  89,\n",
       "          132, 122, 167, 132, 122, 165, 132, 122,  91, 132, 122,  89, 124, 161,\n",
       "          162, 124, 161, 161, 124, 161, 160, 124, 161,  96, 124, 161,  95, 124,\n",
       "          161,  94, 124, 160, 164, 124, 160, 163, 124, 160, 162, 124, 160, 161,\n",
       "          124, 160, 160, 124, 160,  96, 124, 160,  95, 124, 160,  94, 124, 160,\n",
       "           93, 124, 160,  92, 124, 159, 165, 124, 159, 163, 124, 159,  93, 124,\n",
       "          159,  91, 124, 158, 166, 124, 158, 165, 124, 158, 164, 124, 158,  92,\n",
       "          124, 158,  91, 124, 158,  90, 124, 157, 166, 124, 157, 165, 124, 157,\n",
       "           91, 124, 157,  90, 124, 156, 166, 124, 156, 165, 124, 156,  91, 124,\n",
       "          156,  90, 124, 155, 167, 124, 155, 165, 124, 155,  91, 124, 155,  89,\n",
       "          124, 154, 167, 124, 154, 165, 124, 154,  91, 124, 154,  89, 124, 122,\n",
       "          167, 124, 122, 165, 124, 122,  91, 124, 122,  89, 103,  96, 153, 103,\n",
       "           96, 103, 103,  95, 153, 103,  95, 103, 102,  96, 154, 102,  96, 102,\n",
       "          102,  95, 154, 102,  95, 102, 100,  97, 156, 100,  97, 100, 100,  95,\n",
       "          156, 100,  95, 100,  98,  97, 158,  98,  97,  98,  98,  96, 158,  98,\n",
       "           96,  98,  97,  98, 159,  97,  98,  97,  96,  99, 160,  96,  99,  96,\n",
       "           96,  97, 160,  96,  97,  96,  95,  98, 161,  95,  98,  95,  94, 100,\n",
       "          162,  94, 100,  94,  93, 101, 163,  93, 101,  93,  93,  99, 163,  93,\n",
       "           99,  93,  92, 104, 164,  92, 104,  92,  92, 103, 164,  92, 103,  92,\n",
       "           92, 100, 164,  92, 100,  92,  91, 122, 165,  91, 122,  91,  91, 109,\n",
       "          165,  91, 109,  91,  91, 107, 165,  91, 107,  91,  91, 106, 165,  91,\n",
       "          106,  91,  91, 102, 165,  91, 102,  91,  90, 107, 166,  90, 107,  90,\n",
       "           90, 105, 166,  90, 105,  90,  90, 104, 166,  90, 104,  90,  89, 122,\n",
       "          167,  89, 122,  89,  89, 109, 167,  89, 109,  89], dtype=torch.int32),\n",
       "  tensor([165, 164, 165, 165, 164,  91, 165, 155, 165, 165, 155,  91, 164, 155,\n",
       "          165, 164, 155, 164, 164, 155,  92, 164,  92, 164, 164,  92,  92, 163,\n",
       "          164, 163, 163, 164,  93, 163,  93, 163, 163,  93,  93, 163,  92, 163,\n",
       "          163,  92,  93, 145, 154,  93, 145, 154,  92, 145, 147,  93, 145, 147,\n",
       "           92, 139, 154, 164, 139, 154, 163, 139, 147, 164, 139, 147, 163, 134,\n",
       "          154,  93, 134, 154,  92, 134, 147,  93, 134, 147,  92, 129, 155,  93,\n",
       "          129, 155,  92, 129, 147,  93, 129, 147,  92, 126, 154, 164, 126, 154,\n",
       "          163, 126, 147, 164, 126, 147, 163, 122, 154, 164, 122, 154, 163, 122,\n",
       "          147, 164, 122, 147, 163, 118, 155,  93, 118, 155,  92, 118, 147,  93,\n",
       "          118, 147,  92, 112, 154, 164, 112, 154, 163, 112, 147, 164, 112, 147,\n",
       "          163,  93, 164, 163,  93, 164,  93,  93,  93, 163,  93,  93,  93,  93,\n",
       "           92, 163,  93,  92,  93,  92, 155, 164,  92, 155,  92,  92, 155,  91,\n",
       "           92,  92, 164,  92,  92,  92,  91, 164, 165,  91, 164,  91,  91, 155,\n",
       "          165,  91, 155,  91], dtype=torch.int32),\n",
       "  tensor([165, 165, 128, 164, 165, 128, 163, 165, 137, 163, 165, 119, 160, 165,\n",
       "          146, 160, 165, 110, 159, 165, 146, 159, 165, 110, 157,  91, 128, 156,\n",
       "           91, 135, 156,  91, 121, 154, 165, 154, 154, 165, 102, 153, 165, 153,\n",
       "          153, 165, 103, 153,  91, 142, 153,  91, 114, 148,  91, 148, 148,  91,\n",
       "          108, 146, 165, 160, 146, 165, 159, 146, 165,  97, 146, 165,  96, 142,\n",
       "           91, 153, 142,  91, 103, 137, 165, 163, 137, 165,  93, 135,  91, 156,\n",
       "          135,  91, 100, 128, 165, 165, 128, 165, 164, 128, 165,  92, 128, 165,\n",
       "           91, 128,  91, 157, 128,  91,  99, 121,  91, 156, 121,  91, 100, 119,\n",
       "          165, 163, 119, 165,  93, 114,  91, 153, 114,  91, 103, 110, 165, 160,\n",
       "          110, 165, 159, 110, 165,  97, 110, 165,  96, 108,  91, 148, 108,  91,\n",
       "          108, 103, 165, 153, 103, 165, 103, 103,  91, 142, 103,  91, 114, 102,\n",
       "          165, 154, 102, 165, 102, 100,  91, 135, 100,  91, 121,  99,  91, 128,\n",
       "           97, 165, 146,  97, 165, 110,  96, 165, 146,  96, 165, 110,  93, 165,\n",
       "          137,  93, 165, 119,  92, 165, 128,  91, 165, 128], dtype=torch.int32)],\n",
       " 'coord_type_tokens': [tensor([1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3,\n",
       "          1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3,\n",
       "          1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3,\n",
       "          1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3,\n",
       "          1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3,\n",
       "          1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3,\n",
       "          1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3,\n",
       "          1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3,\n",
       "          1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3,\n",
       "          1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3,\n",
       "          1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3,\n",
       "          1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3,\n",
       "          1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3,\n",
       "          1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3,\n",
       "          1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3,\n",
       "          1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3,\n",
       "          1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3,\n",
       "          1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3,\n",
       "          1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3,\n",
       "          1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3,\n",
       "          1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3,\n",
       "          1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3,\n",
       "          1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3,\n",
       "          1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3,\n",
       "          1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3,\n",
       "          1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3]),\n",
       "  tensor([1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3,\n",
       "          1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3,\n",
       "          1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3,\n",
       "          1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3,\n",
       "          1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3,\n",
       "          1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3,\n",
       "          1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3,\n",
       "          1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3]),\n",
       "  tensor([1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3,\n",
       "          1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3,\n",
       "          1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3,\n",
       "          1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3,\n",
       "          1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3,\n",
       "          1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3,\n",
       "          1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3,\n",
       "          1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3])],\n",
       " 'position_tokens': [tensor([  1,   1,   1,   2,   2,   2,   3,   3,   3,   4,   4,   4,   5,   5,\n",
       "            5,   6,   6,   6,   7,   7,   7,   8,   8,   8,   9,   9,   9,  10,\n",
       "           10,  10,  11,  11,  11,  12,  12,  12,  13,  13,  13,  14,  14,  14,\n",
       "           15,  15,  15,  16,  16,  16,  17,  17,  17,  18,  18,  18,  19,  19,\n",
       "           19,  20,  20,  20,  21,  21,  21,  22,  22,  22,  23,  23,  23,  24,\n",
       "           24,  24,  25,  25,  25,  26,  26,  26,  27,  27,  27,  28,  28,  28,\n",
       "           29,  29,  29,  30,  30,  30,  31,  31,  31,  32,  32,  32,  33,  33,\n",
       "           33,  34,  34,  34,  35,  35,  35,  36,  36,  36,  37,  37,  37,  38,\n",
       "           38,  38,  39,  39,  39,  40,  40,  40,  41,  41,  41,  42,  42,  42,\n",
       "           43,  43,  43,  44,  44,  44,  45,  45,  45,  46,  46,  46,  47,  47,\n",
       "           47,  48,  48,  48,  49,  49,  49,  50,  50,  50,  51,  51,  51,  52,\n",
       "           52,  52,  53,  53,  53,  54,  54,  54,  55,  55,  55,  56,  56,  56,\n",
       "           57,  57,  57,  58,  58,  58,  59,  59,  59,  60,  60,  60,  61,  61,\n",
       "           61,  62,  62,  62,  63,  63,  63,  64,  64,  64,  65,  65,  65,  66,\n",
       "           66,  66,  67,  67,  67,  68,  68,  68,  69,  69,  69,  70,  70,  70,\n",
       "           71,  71,  71,  72,  72,  72,  73,  73,  73,  74,  74,  74,  75,  75,\n",
       "           75,  76,  76,  76,  77,  77,  77,  78,  78,  78,  79,  79,  79,  80,\n",
       "           80,  80,  81,  81,  81,  82,  82,  82,  83,  83,  83,  84,  84,  84,\n",
       "           85,  85,  85,  86,  86,  86,  87,  87,  87,  88,  88,  88,  89,  89,\n",
       "           89,  90,  90,  90,  91,  91,  91,  92,  92,  92,  93,  93,  93,  94,\n",
       "           94,  94,  95,  95,  95,  96,  96,  96,  97,  97,  97,  98,  98,  98,\n",
       "           99,  99,  99, 100, 100, 100, 101, 101, 101, 102, 102, 102, 103, 103,\n",
       "          103, 104, 104, 104, 105, 105, 105, 106, 106, 106, 107, 107, 107, 108,\n",
       "          108, 108, 109, 109, 109, 110, 110, 110, 111, 111, 111, 112, 112, 112,\n",
       "          113, 113, 113, 114, 114, 114, 115, 115, 115, 116, 116, 116, 117, 117,\n",
       "          117, 118, 118, 118, 119, 119, 119, 120, 120, 120, 121, 121, 121, 122,\n",
       "          122, 122, 123, 123, 123, 124, 124, 124, 125, 125, 125, 126, 126, 126,\n",
       "          127, 127, 127, 128, 128, 128, 129, 129, 129, 130, 130, 130, 131, 131,\n",
       "          131, 132, 132, 132, 133, 133, 133, 134, 134, 134, 135, 135, 135, 136,\n",
       "          136, 136, 137, 137, 137, 138, 138, 138, 139, 139, 139, 140, 140, 140,\n",
       "          141, 141, 141, 142, 142, 142, 143, 143, 143, 144, 144, 144, 145, 145,\n",
       "          145, 146, 146, 146, 147, 147, 147, 148, 148, 148, 149, 149, 149, 150,\n",
       "          150, 150, 151, 151, 151, 152, 152, 152, 153, 153, 153, 154, 154, 154,\n",
       "          155, 155, 155, 156, 156, 156, 157, 157, 157, 158, 158, 158, 159, 159,\n",
       "          159, 160, 160, 160, 161, 161, 161, 162, 162, 162, 163, 163, 163, 164,\n",
       "          164, 164, 165, 165, 165, 166, 166, 166, 167, 167, 167, 168, 168, 168,\n",
       "          169, 169, 169, 170, 170, 170, 171, 171, 171, 172, 172, 172, 173, 173,\n",
       "          173, 174, 174, 174, 175, 175, 175, 176, 176, 176, 177, 177, 177, 178,\n",
       "          178, 178, 179, 179, 179, 180, 180, 180, 181, 181, 181, 182, 182, 182,\n",
       "          183, 183, 183, 184, 184, 184, 185, 185, 185, 186, 186, 186, 187, 187,\n",
       "          187, 188, 188, 188, 189, 189, 189, 190, 190, 190, 191, 191, 191, 192,\n",
       "          192, 192, 193, 193, 193, 194, 194, 194, 195, 195, 195, 196, 196, 196,\n",
       "          197, 197, 197, 198, 198, 198, 199, 199, 199, 200, 200, 200, 201, 201,\n",
       "          201, 202, 202, 202, 203, 203, 203, 204, 204, 204]),\n",
       "  tensor([ 1,  1,  1,  2,  2,  2,  3,  3,  3,  4,  4,  4,  5,  5,  5,  6,  6,  6,\n",
       "           7,  7,  7,  8,  8,  8,  9,  9,  9, 10, 10, 10, 11, 11, 11, 12, 12, 12,\n",
       "          13, 13, 13, 14, 14, 14, 15, 15, 15, 16, 16, 16, 17, 17, 17, 18, 18, 18,\n",
       "          19, 19, 19, 20, 20, 20, 21, 21, 21, 22, 22, 22, 23, 23, 23, 24, 24, 24,\n",
       "          25, 25, 25, 26, 26, 26, 27, 27, 27, 28, 28, 28, 29, 29, 29, 30, 30, 30,\n",
       "          31, 31, 31, 32, 32, 32, 33, 33, 33, 34, 34, 34, 35, 35, 35, 36, 36, 36,\n",
       "          37, 37, 37, 38, 38, 38, 39, 39, 39, 40, 40, 40, 41, 41, 41, 42, 42, 42,\n",
       "          43, 43, 43, 44, 44, 44, 45, 45, 45, 46, 46, 46, 47, 47, 47, 48, 48, 48,\n",
       "          49, 49, 49, 50, 50, 50, 51, 51, 51, 52, 52, 52, 53, 53, 53, 54, 54, 54,\n",
       "          55, 55, 55, 56, 56, 56, 57, 57, 57, 58, 58, 58, 59, 59, 59, 60, 60, 60,\n",
       "          61, 61, 61, 62, 62, 62]),\n",
       "  tensor([ 1,  1,  1,  2,  2,  2,  3,  3,  3,  4,  4,  4,  5,  5,  5,  6,  6,  6,\n",
       "           7,  7,  7,  8,  8,  8,  9,  9,  9, 10, 10, 10, 11, 11, 11, 12, 12, 12,\n",
       "          13, 13, 13, 14, 14, 14, 15, 15, 15, 16, 16, 16, 17, 17, 17, 18, 18, 18,\n",
       "          19, 19, 19, 20, 20, 20, 21, 21, 21, 22, 22, 22, 23, 23, 23, 24, 24, 24,\n",
       "          25, 25, 25, 26, 26, 26, 27, 27, 27, 28, 28, 28, 29, 29, 29, 30, 30, 30,\n",
       "          31, 31, 31, 32, 32, 32, 33, 33, 33, 34, 34, 34, 35, 35, 35, 36, 36, 36,\n",
       "          37, 37, 37, 38, 38, 38, 39, 39, 39, 40, 40, 40, 41, 41, 41, 42, 42, 42,\n",
       "          43, 43, 43, 44, 44, 44, 45, 45, 45, 46, 46, 46, 47, 47, 47, 48, 48, 48,\n",
       "          49, 49, 49, 50, 50, 50, 51, 51, 51, 52, 52, 52, 53, 53, 53, 54, 54, 54,\n",
       "          55, 55, 55, 56, 56, 56, 57, 57, 57, 58, 58, 58, 59, 59, 59, 60, 60, 60,\n",
       "          61, 61, 61, 62, 62, 62, 63, 63, 63, 64, 64, 64])]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_vtk.tokenize(v_batch, padding=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value_tokens :\n",
      "tensor([[167, 122, 167, 167, 122,  89, 167, 109, 167, 167],\n",
      "        [165, 164, 165, 165, 164,  91, 165, 155, 165, 165],\n",
      "        [165, 165, 128, 164, 165, 128, 163, 165, 137, 163]], dtype=torch.int32)\n",
      "tensor([[167,  89, 122,  89,  89, 109, 167,  89, 109,  89],\n",
      "        [165,  91, 164,  91,  91, 155, 165,  91, 155,  91],\n",
      "        [137,  93, 165, 119,  92, 165, 128,  91, 165, 128]], dtype=torch.int32)\n",
      "============================================================\n",
      "coord_type_tokens :\n",
      "tensor([[1, 2, 3, 1, 2, 3, 1, 2, 3, 1],\n",
      "        [1, 2, 3, 1, 2, 3, 1, 2, 3, 1],\n",
      "        [1, 2, 3, 1, 2, 3, 1, 2, 3, 1]])\n",
      "tensor([[3, 1, 2, 3, 1, 2, 3, 1, 2, 3],\n",
      "        [3, 1, 2, 3, 1, 2, 3, 1, 2, 3],\n",
      "        [3, 1, 2, 3, 1, 2, 3, 1, 2, 3]])\n",
      "============================================================\n",
      "position_tokens :\n",
      "tensor([[1, 1, 1, 2, 2, 2, 3, 3, 3, 4],\n",
      "        [1, 1, 1, 2, 2, 2, 3, 3, 3, 4],\n",
      "        [1, 1, 1, 2, 2, 2, 3, 3, 3, 4]])\n",
      "tensor([[201, 202, 202, 202, 203, 203, 203, 204, 204, 204],\n",
      "        [ 59,  60,  60,  60,  61,  61,  61,  62,  62,  62],\n",
      "        [ 61,  62,  62,  62,  63,  63,  63,  64,  64,  64]])\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "for k, vs in enc_vtk.tokenize(v_batch, padding=False).items():\n",
    "    print(k, \":\")\n",
    "    print(torch.stack([v[:10] for v in vs]))\n",
    "    print(torch.stack([v[-10:] for v in vs]))\n",
    "    print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tokenizer for face model (encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecodeVertexTokenizer(Tokenizer):\n",
    "    \n",
    "    def __init__(self, bos_id=0, eos_id=1, pad_id=2, max_seq_len=None):\n",
    "        \n",
    "        self.special_tokens = {\n",
    "            \"bos\": torch.tensor([bos_id]),\n",
    "            \"eos\": torch.tensor([eos_id]),\n",
    "            \"pad\": torch.tensor([pad_id]),\n",
    "        }\n",
    "        self.pad_id = pad_id\n",
    "        self.not_coord_token = torch.tensor([0])\n",
    "        if max_seq_len is not None:\n",
    "            self.max_seq_len = max_seq_len - 1\n",
    "        else:\n",
    "            self.max_seq_len = max_seq_len\n",
    "        \n",
    "    \n",
    "    def tokenize(self, vertices, padding=True):\n",
    "        special_tokens = self.special_tokens\n",
    "        not_coord_token = self.not_coord_token\n",
    "        max_seq_len = self.max_seq_len\n",
    "        \n",
    "        vertices = [\n",
    "            torch.cat([\n",
    "                special_tokens[\"bos\"], \n",
    "                v.reshape(-1,)  + len(special_tokens), \n",
    "                special_tokens[\"eos\"]\n",
    "            ])\n",
    "            for v in vertices\n",
    "        ]\n",
    "        \n",
    "        coord_type_tokens = [\n",
    "            torch.cat([\n",
    "                not_coord_token,\n",
    "                torch.arange(len(v)-2) % 3 + 1,\n",
    "                not_coord_token\n",
    "            ])\n",
    "            for v in vertices\n",
    "        ]\n",
    "        \n",
    "        position_tokens = [\n",
    "            torch.cat([\n",
    "                not_coord_token,\n",
    "                torch.arange(len(v)-2) // 3 + 1,\n",
    "                not_coord_token\n",
    "            ])\n",
    "            for v in vertices\n",
    "        ]\n",
    "        \n",
    "        vertices_target = [\n",
    "            torch.cat([v, special_tokens[\"pad\"]])[1:] \n",
    "            for v in vertices\n",
    "        ]\n",
    "        \n",
    "        if padding:\n",
    "            vertices = torch.stack(\n",
    "                self._padding(vertices, special_tokens[\"pad\"], max_seq_len)\n",
    "            )\n",
    "            vertices_target = torch.stack(\n",
    "                self._padding(vertices_target, special_tokens[\"pad\"], max_seq_len)\n",
    "            )\n",
    "            coord_type_tokens = torch.stack(\n",
    "                self._padding(coord_type_tokens, not_coord_token, max_seq_len)\n",
    "            )\n",
    "            position_tokens = torch.stack(\n",
    "                self._padding(position_tokens, not_coord_token, max_seq_len)\n",
    "            )\n",
    "            \n",
    "            padding_mask = self._make_padding_mask(vertices, self.pad_id)\n",
    "            # future_mask = self._make_future_mask(vertices)\n",
    "            outputs = {\n",
    "                \"value_tokens\": vertices,\n",
    "                \"target_tokens\": vertices_target,\n",
    "                \"coord_type_tokens\": coord_type_tokens,\n",
    "                \"position_tokens\": position_tokens,\n",
    "                \"padding_mask\": padding_mask,\n",
    "                # \"future_mask\": future_mask,\n",
    "            }\n",
    "        else:\n",
    "            outputs = {\n",
    "                \"value_tokens\": vertices,\n",
    "                \"target_tokens\": vertices_target,\n",
    "                \"coord_type_tokens\": coord_type_tokens,\n",
    "                \"position_tokens\": position_tokens,\n",
    "            }\n",
    "            \n",
    "        return outputs\n",
    "    \n",
    "    def detokenize(self, vertices):\n",
    "        special_tokens = self.special_tokens\n",
    "        \n",
    "        result = []\n",
    "        for vertex in vertices:\n",
    "            vertex = vertex - len(special_tokens)\n",
    "            result.append(\n",
    "                vertex[torch.where(vertex >= 0)]\n",
    "            )\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_vtk = DecodeVertexTokenizer(max_seq_len=2400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'value_tokens': tensor([[  0, 169, 124,  ...,   2,   2,   2],\n",
       "         [  0, 167, 166,  ...,   2,   2,   2],\n",
       "         [  0, 167, 167,  ...,   2,   2,   2]]),\n",
       " 'target_tokens': tensor([[169, 124, 169,  ...,   2,   2,   2],\n",
       "         [167, 166, 167,  ...,   2,   2,   2],\n",
       "         [167, 167, 130,  ...,   2,   2,   2]]),\n",
       " 'coord_type_tokens': tensor([[0, 1, 2,  ..., 0, 0, 0],\n",
       "         [0, 1, 2,  ..., 0, 0, 0],\n",
       "         [0, 1, 2,  ..., 0, 0, 0]]),\n",
       " 'position_tokens': tensor([[0, 1, 1,  ..., 0, 0, 0],\n",
       "         [0, 1, 1,  ..., 0, 0, 0],\n",
       "         [0, 1, 1,  ..., 0, 0, 0]]),\n",
       " 'padding_mask': tensor([[False, False, False,  ...,  True,  True,  True],\n",
       "         [False, False, False,  ...,  True,  True,  True],\n",
       "         [False, False, False,  ...,  True,  True,  True]])}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec_vtk.tokenize(v_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value_tokens :\n",
      "torch.Size([3, 2400])\n",
      "tensor([[  0, 169, 124, 169, 169, 124,  91, 169, 111, 169],\n",
      "        [  0, 167, 166, 167, 167, 166,  93, 167, 157, 167],\n",
      "        [  0, 167, 167, 130, 166, 167, 130, 165, 167, 139]])\n",
      "tensor([[2, 2, 2, 2, 2, 2, 2, 2, 2, 2],\n",
      "        [2, 2, 2, 2, 2, 2, 2, 2, 2, 2],\n",
      "        [2, 2, 2, 2, 2, 2, 2, 2, 2, 2]])\n",
      "============================================================\n",
      "target_tokens :\n",
      "torch.Size([3, 2400])\n",
      "tensor([[169, 124, 169, 169, 124,  91, 169, 111, 169, 169],\n",
      "        [167, 166, 167, 167, 166,  93, 167, 157, 167, 167],\n",
      "        [167, 167, 130, 166, 167, 130, 165, 167, 139, 165]])\n",
      "tensor([[2, 2, 2, 2, 2, 2, 2, 2, 2, 2],\n",
      "        [2, 2, 2, 2, 2, 2, 2, 2, 2, 2],\n",
      "        [2, 2, 2, 2, 2, 2, 2, 2, 2, 2]])\n",
      "============================================================\n",
      "coord_type_tokens :\n",
      "torch.Size([3, 2400])\n",
      "tensor([[0, 1, 2, 3, 1, 2, 3, 1, 2, 3],\n",
      "        [0, 1, 2, 3, 1, 2, 3, 1, 2, 3],\n",
      "        [0, 1, 2, 3, 1, 2, 3, 1, 2, 3]])\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
      "============================================================\n",
      "position_tokens :\n",
      "torch.Size([3, 2400])\n",
      "tensor([[0, 1, 1, 1, 2, 2, 2, 3, 3, 3],\n",
      "        [0, 1, 1, 1, 2, 2, 2, 3, 3, 3],\n",
      "        [0, 1, 1, 1, 2, 2, 2, 3, 3, 3]])\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
      "============================================================\n",
      "padding_mask :\n",
      "torch.Size([3, 2400])\n",
      "tensor([[False, False, False, False, False, False, False, False, False, False],\n",
      "        [False, False, False, False, False, False, False, False, False, False],\n",
      "        [False, False, False, False, False, False, False, False, False, False]])\n",
      "tensor([[True, True, True, True, True, True, True, True, True, True],\n",
      "        [True, True, True, True, True, True, True, True, True, True],\n",
      "        [True, True, True, True, True, True, True, True, True, True]])\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "for k, vs in dec_vtk.tokenize(v_batch).items():\n",
    "    print(k, \":\")\n",
    "    print(vs.shape)\n",
    "    print(torch.stack([v[:10] for v in vs]))\n",
    "    print(torch.stack([v[-10:] for v in vs]))\n",
    "    print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'value_tokens': [tensor([  0, 169, 124, 169, 169, 124,  91, 169, 111, 169, 169, 111,  91, 168,\n",
       "          109, 168, 168, 109,  92, 168, 107, 168, 168, 107,  92, 168, 106, 168,\n",
       "          168, 106,  92, 167, 124, 167, 167, 124,  93, 167, 111, 167, 167, 111,\n",
       "           93, 167, 109, 167, 167, 109,  93, 167, 108, 167, 167, 108,  93, 167,\n",
       "          104, 167, 167, 104,  93, 166, 106, 166, 166, 106,  94, 166, 105, 166,\n",
       "          166, 105,  94, 166, 102, 166, 166, 102,  94, 165, 103, 165, 165, 103,\n",
       "           95, 165, 101, 165, 165, 101,  95, 164, 102, 164, 164, 102,  96, 163,\n",
       "          100, 163, 163, 100,  97, 162, 101, 162, 162, 101,  98, 162,  99, 162,\n",
       "          162,  99,  98, 161, 100, 161, 161, 100,  99, 160,  99, 160, 160,  99,\n",
       "          100, 160,  98, 160, 160,  98, 100, 158,  99, 158, 158,  99, 102, 158,\n",
       "           97, 158, 158,  97, 102, 156,  98, 156, 156,  98, 104, 156,  97, 156,\n",
       "          156,  97, 104, 155,  98, 155, 155,  98, 105, 155,  97, 155, 155,  97,\n",
       "          105, 134, 163, 164, 134, 163, 163, 134, 163, 162, 134, 163,  98, 134,\n",
       "          163,  97, 134, 163,  96, 134, 162, 166, 134, 162, 165, 134, 162, 164,\n",
       "          134, 162, 163, 134, 162, 162, 134, 162,  98, 134, 162,  97, 134, 162,\n",
       "           96, 134, 162,  95, 134, 162,  94, 134, 161, 167, 134, 161, 165, 134,\n",
       "          161,  95, 134, 161,  93, 134, 160, 168, 134, 160, 167, 134, 160, 166,\n",
       "          134, 160,  94, 134, 160,  93, 134, 160,  92, 134, 159, 168, 134, 159,\n",
       "          167, 134, 159,  93, 134, 159,  92, 134, 158, 168, 134, 158, 167, 134,\n",
       "          158,  93, 134, 158,  92, 134, 157, 169, 134, 157, 167, 134, 157,  93,\n",
       "          134, 157,  91, 134, 156, 169, 134, 156, 167, 134, 156,  93, 134, 156,\n",
       "           91, 134, 124, 169, 134, 124, 167, 134, 124,  93, 134, 124,  91, 126,\n",
       "          163, 164, 126, 163, 163, 126, 163, 162, 126, 163,  98, 126, 163,  97,\n",
       "          126, 163,  96, 126, 162, 166, 126, 162, 165, 126, 162, 164, 126, 162,\n",
       "          163, 126, 162, 162, 126, 162,  98, 126, 162,  97, 126, 162,  96, 126,\n",
       "          162,  95, 126, 162,  94, 126, 161, 167, 126, 161, 165, 126, 161,  95,\n",
       "          126, 161,  93, 126, 160, 168, 126, 160, 167, 126, 160, 166, 126, 160,\n",
       "           94, 126, 160,  93, 126, 160,  92, 126, 159, 168, 126, 159, 167, 126,\n",
       "          159,  93, 126, 159,  92, 126, 158, 168, 126, 158, 167, 126, 158,  93,\n",
       "          126, 158,  92, 126, 157, 169, 126, 157, 167, 126, 157,  93, 126, 157,\n",
       "           91, 126, 156, 169, 126, 156, 167, 126, 156,  93, 126, 156,  91, 126,\n",
       "          124, 169, 126, 124, 167, 126, 124,  93, 126, 124,  91, 105,  98, 155,\n",
       "          105,  98, 105, 105,  97, 155, 105,  97, 105, 104,  98, 156, 104,  98,\n",
       "          104, 104,  97, 156, 104,  97, 104, 102,  99, 158, 102,  99, 102, 102,\n",
       "           97, 158, 102,  97, 102, 100,  99, 160, 100,  99, 100, 100,  98, 160,\n",
       "          100,  98, 100,  99, 100, 161,  99, 100,  99,  98, 101, 162,  98, 101,\n",
       "           98,  98,  99, 162,  98,  99,  98,  97, 100, 163,  97, 100,  97,  96,\n",
       "          102, 164,  96, 102,  96,  95, 103, 165,  95, 103,  95,  95, 101, 165,\n",
       "           95, 101,  95,  94, 106, 166,  94, 106,  94,  94, 105, 166,  94, 105,\n",
       "           94,  94, 102, 166,  94, 102,  94,  93, 124, 167,  93, 124,  93,  93,\n",
       "          111, 167,  93, 111,  93,  93, 109, 167,  93, 109,  93,  93, 108, 167,\n",
       "           93, 108,  93,  93, 104, 167,  93, 104,  93,  92, 109, 168,  92, 109,\n",
       "           92,  92, 107, 168,  92, 107,  92,  92, 106, 168,  92, 106,  92,  91,\n",
       "          124, 169,  91, 124,  91,  91, 111, 169,  91, 111,  91,   1]),\n",
       "  tensor([  0, 167, 166, 167, 167, 166,  93, 167, 157, 167, 167, 157,  93, 166,\n",
       "          157, 167, 166, 157, 166, 166, 157,  94, 166,  94, 166, 166,  94,  94,\n",
       "          165, 166, 165, 165, 166,  95, 165,  95, 165, 165,  95,  95, 165,  94,\n",
       "          165, 165,  94,  95, 147, 156,  95, 147, 156,  94, 147, 149,  95, 147,\n",
       "          149,  94, 141, 156, 166, 141, 156, 165, 141, 149, 166, 141, 149, 165,\n",
       "          136, 156,  95, 136, 156,  94, 136, 149,  95, 136, 149,  94, 131, 157,\n",
       "           95, 131, 157,  94, 131, 149,  95, 131, 149,  94, 128, 156, 166, 128,\n",
       "          156, 165, 128, 149, 166, 128, 149, 165, 124, 156, 166, 124, 156, 165,\n",
       "          124, 149, 166, 124, 149, 165, 120, 157,  95, 120, 157,  94, 120, 149,\n",
       "           95, 120, 149,  94, 114, 156, 166, 114, 156, 165, 114, 149, 166, 114,\n",
       "          149, 165,  95, 166, 165,  95, 166,  95,  95,  95, 165,  95,  95,  95,\n",
       "           95,  94, 165,  95,  94,  95,  94, 157, 166,  94, 157,  94,  94, 157,\n",
       "           93,  94,  94, 166,  94,  94,  94,  93, 166, 167,  93, 166,  93,  93,\n",
       "          157, 167,  93, 157,  93,   1]),\n",
       "  tensor([  0, 167, 167, 130, 166, 167, 130, 165, 167, 139, 165, 167, 121, 162,\n",
       "          167, 148, 162, 167, 112, 161, 167, 148, 161, 167, 112, 159,  93, 130,\n",
       "          158,  93, 137, 158,  93, 123, 156, 167, 156, 156, 167, 104, 155, 167,\n",
       "          155, 155, 167, 105, 155,  93, 144, 155,  93, 116, 150,  93, 150, 150,\n",
       "           93, 110, 148, 167, 162, 148, 167, 161, 148, 167,  99, 148, 167,  98,\n",
       "          144,  93, 155, 144,  93, 105, 139, 167, 165, 139, 167,  95, 137,  93,\n",
       "          158, 137,  93, 102, 130, 167, 167, 130, 167, 166, 130, 167,  94, 130,\n",
       "          167,  93, 130,  93, 159, 130,  93, 101, 123,  93, 158, 123,  93, 102,\n",
       "          121, 167, 165, 121, 167,  95, 116,  93, 155, 116,  93, 105, 112, 167,\n",
       "          162, 112, 167, 161, 112, 167,  99, 112, 167,  98, 110,  93, 150, 110,\n",
       "           93, 110, 105, 167, 155, 105, 167, 105, 105,  93, 144, 105,  93, 116,\n",
       "          104, 167, 156, 104, 167, 104, 102,  93, 137, 102,  93, 123, 101,  93,\n",
       "          130,  99, 167, 148,  99, 167, 112,  98, 167, 148,  98, 167, 112,  95,\n",
       "          167, 139,  95, 167, 121,  94, 167, 130,  93, 167, 130,   1])],\n",
       " 'target_tokens': [tensor([169, 124, 169, 169, 124,  91, 169, 111, 169, 169, 111,  91, 168, 109,\n",
       "          168, 168, 109,  92, 168, 107, 168, 168, 107,  92, 168, 106, 168, 168,\n",
       "          106,  92, 167, 124, 167, 167, 124,  93, 167, 111, 167, 167, 111,  93,\n",
       "          167, 109, 167, 167, 109,  93, 167, 108, 167, 167, 108,  93, 167, 104,\n",
       "          167, 167, 104,  93, 166, 106, 166, 166, 106,  94, 166, 105, 166, 166,\n",
       "          105,  94, 166, 102, 166, 166, 102,  94, 165, 103, 165, 165, 103,  95,\n",
       "          165, 101, 165, 165, 101,  95, 164, 102, 164, 164, 102,  96, 163, 100,\n",
       "          163, 163, 100,  97, 162, 101, 162, 162, 101,  98, 162,  99, 162, 162,\n",
       "           99,  98, 161, 100, 161, 161, 100,  99, 160,  99, 160, 160,  99, 100,\n",
       "          160,  98, 160, 160,  98, 100, 158,  99, 158, 158,  99, 102, 158,  97,\n",
       "          158, 158,  97, 102, 156,  98, 156, 156,  98, 104, 156,  97, 156, 156,\n",
       "           97, 104, 155,  98, 155, 155,  98, 105, 155,  97, 155, 155,  97, 105,\n",
       "          134, 163, 164, 134, 163, 163, 134, 163, 162, 134, 163,  98, 134, 163,\n",
       "           97, 134, 163,  96, 134, 162, 166, 134, 162, 165, 134, 162, 164, 134,\n",
       "          162, 163, 134, 162, 162, 134, 162,  98, 134, 162,  97, 134, 162,  96,\n",
       "          134, 162,  95, 134, 162,  94, 134, 161, 167, 134, 161, 165, 134, 161,\n",
       "           95, 134, 161,  93, 134, 160, 168, 134, 160, 167, 134, 160, 166, 134,\n",
       "          160,  94, 134, 160,  93, 134, 160,  92, 134, 159, 168, 134, 159, 167,\n",
       "          134, 159,  93, 134, 159,  92, 134, 158, 168, 134, 158, 167, 134, 158,\n",
       "           93, 134, 158,  92, 134, 157, 169, 134, 157, 167, 134, 157,  93, 134,\n",
       "          157,  91, 134, 156, 169, 134, 156, 167, 134, 156,  93, 134, 156,  91,\n",
       "          134, 124, 169, 134, 124, 167, 134, 124,  93, 134, 124,  91, 126, 163,\n",
       "          164, 126, 163, 163, 126, 163, 162, 126, 163,  98, 126, 163,  97, 126,\n",
       "          163,  96, 126, 162, 166, 126, 162, 165, 126, 162, 164, 126, 162, 163,\n",
       "          126, 162, 162, 126, 162,  98, 126, 162,  97, 126, 162,  96, 126, 162,\n",
       "           95, 126, 162,  94, 126, 161, 167, 126, 161, 165, 126, 161,  95, 126,\n",
       "          161,  93, 126, 160, 168, 126, 160, 167, 126, 160, 166, 126, 160,  94,\n",
       "          126, 160,  93, 126, 160,  92, 126, 159, 168, 126, 159, 167, 126, 159,\n",
       "           93, 126, 159,  92, 126, 158, 168, 126, 158, 167, 126, 158,  93, 126,\n",
       "          158,  92, 126, 157, 169, 126, 157, 167, 126, 157,  93, 126, 157,  91,\n",
       "          126, 156, 169, 126, 156, 167, 126, 156,  93, 126, 156,  91, 126, 124,\n",
       "          169, 126, 124, 167, 126, 124,  93, 126, 124,  91, 105,  98, 155, 105,\n",
       "           98, 105, 105,  97, 155, 105,  97, 105, 104,  98, 156, 104,  98, 104,\n",
       "          104,  97, 156, 104,  97, 104, 102,  99, 158, 102,  99, 102, 102,  97,\n",
       "          158, 102,  97, 102, 100,  99, 160, 100,  99, 100, 100,  98, 160, 100,\n",
       "           98, 100,  99, 100, 161,  99, 100,  99,  98, 101, 162,  98, 101,  98,\n",
       "           98,  99, 162,  98,  99,  98,  97, 100, 163,  97, 100,  97,  96, 102,\n",
       "          164,  96, 102,  96,  95, 103, 165,  95, 103,  95,  95, 101, 165,  95,\n",
       "          101,  95,  94, 106, 166,  94, 106,  94,  94, 105, 166,  94, 105,  94,\n",
       "           94, 102, 166,  94, 102,  94,  93, 124, 167,  93, 124,  93,  93, 111,\n",
       "          167,  93, 111,  93,  93, 109, 167,  93, 109,  93,  93, 108, 167,  93,\n",
       "          108,  93,  93, 104, 167,  93, 104,  93,  92, 109, 168,  92, 109,  92,\n",
       "           92, 107, 168,  92, 107,  92,  92, 106, 168,  92, 106,  92,  91, 124,\n",
       "          169,  91, 124,  91,  91, 111, 169,  91, 111,  91,   1,   2]),\n",
       "  tensor([167, 166, 167, 167, 166,  93, 167, 157, 167, 167, 157,  93, 166, 157,\n",
       "          167, 166, 157, 166, 166, 157,  94, 166,  94, 166, 166,  94,  94, 165,\n",
       "          166, 165, 165, 166,  95, 165,  95, 165, 165,  95,  95, 165,  94, 165,\n",
       "          165,  94,  95, 147, 156,  95, 147, 156,  94, 147, 149,  95, 147, 149,\n",
       "           94, 141, 156, 166, 141, 156, 165, 141, 149, 166, 141, 149, 165, 136,\n",
       "          156,  95, 136, 156,  94, 136, 149,  95, 136, 149,  94, 131, 157,  95,\n",
       "          131, 157,  94, 131, 149,  95, 131, 149,  94, 128, 156, 166, 128, 156,\n",
       "          165, 128, 149, 166, 128, 149, 165, 124, 156, 166, 124, 156, 165, 124,\n",
       "          149, 166, 124, 149, 165, 120, 157,  95, 120, 157,  94, 120, 149,  95,\n",
       "          120, 149,  94, 114, 156, 166, 114, 156, 165, 114, 149, 166, 114, 149,\n",
       "          165,  95, 166, 165,  95, 166,  95,  95,  95, 165,  95,  95,  95,  95,\n",
       "           94, 165,  95,  94,  95,  94, 157, 166,  94, 157,  94,  94, 157,  93,\n",
       "           94,  94, 166,  94,  94,  94,  93, 166, 167,  93, 166,  93,  93, 157,\n",
       "          167,  93, 157,  93,   1,   2]),\n",
       "  tensor([167, 167, 130, 166, 167, 130, 165, 167, 139, 165, 167, 121, 162, 167,\n",
       "          148, 162, 167, 112, 161, 167, 148, 161, 167, 112, 159,  93, 130, 158,\n",
       "           93, 137, 158,  93, 123, 156, 167, 156, 156, 167, 104, 155, 167, 155,\n",
       "          155, 167, 105, 155,  93, 144, 155,  93, 116, 150,  93, 150, 150,  93,\n",
       "          110, 148, 167, 162, 148, 167, 161, 148, 167,  99, 148, 167,  98, 144,\n",
       "           93, 155, 144,  93, 105, 139, 167, 165, 139, 167,  95, 137,  93, 158,\n",
       "          137,  93, 102, 130, 167, 167, 130, 167, 166, 130, 167,  94, 130, 167,\n",
       "           93, 130,  93, 159, 130,  93, 101, 123,  93, 158, 123,  93, 102, 121,\n",
       "          167, 165, 121, 167,  95, 116,  93, 155, 116,  93, 105, 112, 167, 162,\n",
       "          112, 167, 161, 112, 167,  99, 112, 167,  98, 110,  93, 150, 110,  93,\n",
       "          110, 105, 167, 155, 105, 167, 105, 105,  93, 144, 105,  93, 116, 104,\n",
       "          167, 156, 104, 167, 104, 102,  93, 137, 102,  93, 123, 101,  93, 130,\n",
       "           99, 167, 148,  99, 167, 112,  98, 167, 148,  98, 167, 112,  95, 167,\n",
       "          139,  95, 167, 121,  94, 167, 130,  93, 167, 130,   1,   2])],\n",
       " 'coord_type_tokens': [tensor([0, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2,\n",
       "          3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2,\n",
       "          3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2,\n",
       "          3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2,\n",
       "          3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2,\n",
       "          3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2,\n",
       "          3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2,\n",
       "          3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2,\n",
       "          3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2,\n",
       "          3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2,\n",
       "          3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2,\n",
       "          3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2,\n",
       "          3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2,\n",
       "          3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2,\n",
       "          3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2,\n",
       "          3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2,\n",
       "          3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2,\n",
       "          3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2,\n",
       "          3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2,\n",
       "          3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2,\n",
       "          3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2,\n",
       "          3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2,\n",
       "          3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2,\n",
       "          3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2,\n",
       "          3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2,\n",
       "          3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 0]),\n",
       "  tensor([0, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2,\n",
       "          3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2,\n",
       "          3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2,\n",
       "          3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2,\n",
       "          3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2,\n",
       "          3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2,\n",
       "          3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2,\n",
       "          3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 0]),\n",
       "  tensor([0, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2,\n",
       "          3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2,\n",
       "          3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2,\n",
       "          3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2,\n",
       "          3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2,\n",
       "          3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2,\n",
       "          3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2,\n",
       "          3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2,\n",
       "          3, 0])],\n",
       " 'position_tokens': [tensor([  0,   1,   1,   1,   2,   2,   2,   3,   3,   3,   4,   4,   4,   5,\n",
       "            5,   5,   6,   6,   6,   7,   7,   7,   8,   8,   8,   9,   9,   9,\n",
       "           10,  10,  10,  11,  11,  11,  12,  12,  12,  13,  13,  13,  14,  14,\n",
       "           14,  15,  15,  15,  16,  16,  16,  17,  17,  17,  18,  18,  18,  19,\n",
       "           19,  19,  20,  20,  20,  21,  21,  21,  22,  22,  22,  23,  23,  23,\n",
       "           24,  24,  24,  25,  25,  25,  26,  26,  26,  27,  27,  27,  28,  28,\n",
       "           28,  29,  29,  29,  30,  30,  30,  31,  31,  31,  32,  32,  32,  33,\n",
       "           33,  33,  34,  34,  34,  35,  35,  35,  36,  36,  36,  37,  37,  37,\n",
       "           38,  38,  38,  39,  39,  39,  40,  40,  40,  41,  41,  41,  42,  42,\n",
       "           42,  43,  43,  43,  44,  44,  44,  45,  45,  45,  46,  46,  46,  47,\n",
       "           47,  47,  48,  48,  48,  49,  49,  49,  50,  50,  50,  51,  51,  51,\n",
       "           52,  52,  52,  53,  53,  53,  54,  54,  54,  55,  55,  55,  56,  56,\n",
       "           56,  57,  57,  57,  58,  58,  58,  59,  59,  59,  60,  60,  60,  61,\n",
       "           61,  61,  62,  62,  62,  63,  63,  63,  64,  64,  64,  65,  65,  65,\n",
       "           66,  66,  66,  67,  67,  67,  68,  68,  68,  69,  69,  69,  70,  70,\n",
       "           70,  71,  71,  71,  72,  72,  72,  73,  73,  73,  74,  74,  74,  75,\n",
       "           75,  75,  76,  76,  76,  77,  77,  77,  78,  78,  78,  79,  79,  79,\n",
       "           80,  80,  80,  81,  81,  81,  82,  82,  82,  83,  83,  83,  84,  84,\n",
       "           84,  85,  85,  85,  86,  86,  86,  87,  87,  87,  88,  88,  88,  89,\n",
       "           89,  89,  90,  90,  90,  91,  91,  91,  92,  92,  92,  93,  93,  93,\n",
       "           94,  94,  94,  95,  95,  95,  96,  96,  96,  97,  97,  97,  98,  98,\n",
       "           98,  99,  99,  99, 100, 100, 100, 101, 101, 101, 102, 102, 102, 103,\n",
       "          103, 103, 104, 104, 104, 105, 105, 105, 106, 106, 106, 107, 107, 107,\n",
       "          108, 108, 108, 109, 109, 109, 110, 110, 110, 111, 111, 111, 112, 112,\n",
       "          112, 113, 113, 113, 114, 114, 114, 115, 115, 115, 116, 116, 116, 117,\n",
       "          117, 117, 118, 118, 118, 119, 119, 119, 120, 120, 120, 121, 121, 121,\n",
       "          122, 122, 122, 123, 123, 123, 124, 124, 124, 125, 125, 125, 126, 126,\n",
       "          126, 127, 127, 127, 128, 128, 128, 129, 129, 129, 130, 130, 130, 131,\n",
       "          131, 131, 132, 132, 132, 133, 133, 133, 134, 134, 134, 135, 135, 135,\n",
       "          136, 136, 136, 137, 137, 137, 138, 138, 138, 139, 139, 139, 140, 140,\n",
       "          140, 141, 141, 141, 142, 142, 142, 143, 143, 143, 144, 144, 144, 145,\n",
       "          145, 145, 146, 146, 146, 147, 147, 147, 148, 148, 148, 149, 149, 149,\n",
       "          150, 150, 150, 151, 151, 151, 152, 152, 152, 153, 153, 153, 154, 154,\n",
       "          154, 155, 155, 155, 156, 156, 156, 157, 157, 157, 158, 158, 158, 159,\n",
       "          159, 159, 160, 160, 160, 161, 161, 161, 162, 162, 162, 163, 163, 163,\n",
       "          164, 164, 164, 165, 165, 165, 166, 166, 166, 167, 167, 167, 168, 168,\n",
       "          168, 169, 169, 169, 170, 170, 170, 171, 171, 171, 172, 172, 172, 173,\n",
       "          173, 173, 174, 174, 174, 175, 175, 175, 176, 176, 176, 177, 177, 177,\n",
       "          178, 178, 178, 179, 179, 179, 180, 180, 180, 181, 181, 181, 182, 182,\n",
       "          182, 183, 183, 183, 184, 184, 184, 185, 185, 185, 186, 186, 186, 187,\n",
       "          187, 187, 188, 188, 188, 189, 189, 189, 190, 190, 190, 191, 191, 191,\n",
       "          192, 192, 192, 193, 193, 193, 194, 194, 194, 195, 195, 195, 196, 196,\n",
       "          196, 197, 197, 197, 198, 198, 198, 199, 199, 199, 200, 200, 200, 201,\n",
       "          201, 201, 202, 202, 202, 203, 203, 203, 204, 204, 204,   0]),\n",
       "  tensor([ 0,  1,  1,  1,  2,  2,  2,  3,  3,  3,  4,  4,  4,  5,  5,  5,  6,  6,\n",
       "           6,  7,  7,  7,  8,  8,  8,  9,  9,  9, 10, 10, 10, 11, 11, 11, 12, 12,\n",
       "          12, 13, 13, 13, 14, 14, 14, 15, 15, 15, 16, 16, 16, 17, 17, 17, 18, 18,\n",
       "          18, 19, 19, 19, 20, 20, 20, 21, 21, 21, 22, 22, 22, 23, 23, 23, 24, 24,\n",
       "          24, 25, 25, 25, 26, 26, 26, 27, 27, 27, 28, 28, 28, 29, 29, 29, 30, 30,\n",
       "          30, 31, 31, 31, 32, 32, 32, 33, 33, 33, 34, 34, 34, 35, 35, 35, 36, 36,\n",
       "          36, 37, 37, 37, 38, 38, 38, 39, 39, 39, 40, 40, 40, 41, 41, 41, 42, 42,\n",
       "          42, 43, 43, 43, 44, 44, 44, 45, 45, 45, 46, 46, 46, 47, 47, 47, 48, 48,\n",
       "          48, 49, 49, 49, 50, 50, 50, 51, 51, 51, 52, 52, 52, 53, 53, 53, 54, 54,\n",
       "          54, 55, 55, 55, 56, 56, 56, 57, 57, 57, 58, 58, 58, 59, 59, 59, 60, 60,\n",
       "          60, 61, 61, 61, 62, 62, 62,  0]),\n",
       "  tensor([ 0,  1,  1,  1,  2,  2,  2,  3,  3,  3,  4,  4,  4,  5,  5,  5,  6,  6,\n",
       "           6,  7,  7,  7,  8,  8,  8,  9,  9,  9, 10, 10, 10, 11, 11, 11, 12, 12,\n",
       "          12, 13, 13, 13, 14, 14, 14, 15, 15, 15, 16, 16, 16, 17, 17, 17, 18, 18,\n",
       "          18, 19, 19, 19, 20, 20, 20, 21, 21, 21, 22, 22, 22, 23, 23, 23, 24, 24,\n",
       "          24, 25, 25, 25, 26, 26, 26, 27, 27, 27, 28, 28, 28, 29, 29, 29, 30, 30,\n",
       "          30, 31, 31, 31, 32, 32, 32, 33, 33, 33, 34, 34, 34, 35, 35, 35, 36, 36,\n",
       "          36, 37, 37, 37, 38, 38, 38, 39, 39, 39, 40, 40, 40, 41, 41, 41, 42, 42,\n",
       "          42, 43, 43, 43, 44, 44, 44, 45, 45, 45, 46, 46, 46, 47, 47, 47, 48, 48,\n",
       "          48, 49, 49, 49, 50, 50, 50, 51, 51, 51, 52, 52, 52, 53, 53, 53, 54, 54,\n",
       "          54, 55, 55, 55, 56, 56, 56, 57, 57, 57, 58, 58, 58, 59, 59, 59, 60, 60,\n",
       "          60, 61, 61, 61, 62, 62, 62, 63, 63, 63, 64, 64, 64,  0])]}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec_vtk.tokenize(v_batch, padding=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value_tokens :\n",
      "tensor([[  0, 169, 124, 169, 169, 124,  91, 169, 111, 169],\n",
      "        [  0, 167, 166, 167, 167, 166,  93, 167, 157, 167],\n",
      "        [  0, 167, 167, 130, 166, 167, 130, 165, 167, 139]])\n",
      "tensor([[ 91, 124,  91,  91, 111, 169,  91, 111,  91,   1],\n",
      "        [ 93, 166,  93,  93, 157, 167,  93, 157,  93,   1],\n",
      "        [ 95, 167, 121,  94, 167, 130,  93, 167, 130,   1]])\n",
      "============================================================\n",
      "target_tokens :\n",
      "tensor([[169, 124, 169, 169, 124,  91, 169, 111, 169, 169],\n",
      "        [167, 166, 167, 167, 166,  93, 167, 157, 167, 167],\n",
      "        [167, 167, 130, 166, 167, 130, 165, 167, 139, 165]])\n",
      "tensor([[124,  91,  91, 111, 169,  91, 111,  91,   1,   2],\n",
      "        [166,  93,  93, 157, 167,  93, 157,  93,   1,   2],\n",
      "        [167, 121,  94, 167, 130,  93, 167, 130,   1,   2]])\n",
      "============================================================\n",
      "coord_type_tokens :\n",
      "tensor([[0, 1, 2, 3, 1, 2, 3, 1, 2, 3],\n",
      "        [0, 1, 2, 3, 1, 2, 3, 1, 2, 3],\n",
      "        [0, 1, 2, 3, 1, 2, 3, 1, 2, 3]])\n",
      "tensor([[1, 2, 3, 1, 2, 3, 1, 2, 3, 0],\n",
      "        [1, 2, 3, 1, 2, 3, 1, 2, 3, 0],\n",
      "        [1, 2, 3, 1, 2, 3, 1, 2, 3, 0]])\n",
      "============================================================\n",
      "position_tokens :\n",
      "tensor([[0, 1, 1, 1, 2, 2, 2, 3, 3, 3],\n",
      "        [0, 1, 1, 1, 2, 2, 2, 3, 3, 3],\n",
      "        [0, 1, 1, 1, 2, 2, 2, 3, 3, 3]])\n",
      "tensor([[202, 202, 202, 203, 203, 203, 204, 204, 204,   0],\n",
      "        [ 60,  60,  60,  61,  61,  61,  62,  62,  62,   0],\n",
      "        [ 62,  62,  62,  63,  63,  63,  64,  64,  64,   0]])\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "for k, vs in dec_vtk.tokenize(v_batch, padding=False).items():\n",
    "    print(k, \":\")\n",
    "    print(torch.stack([v[:10] for v in vs]))\n",
    "    print(torch.stack([v[-10:] for v in vs]))\n",
    "    print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([166, 121, 166, 166, 121,  88, 166, 108, 166, 166, 108,  88, 165, 106,\n",
       "         165, 165, 106,  89, 165, 104, 165, 165, 104,  89, 165, 103, 165, 165,\n",
       "         103,  89, 164, 121, 164, 164, 121,  90, 164, 108, 164, 164, 108,  90,\n",
       "         164, 106, 164, 164, 106,  90, 164, 105, 164, 164, 105,  90, 164, 101,\n",
       "         164, 164, 101,  90, 163, 103, 163, 163, 103,  91, 163, 102, 163, 163,\n",
       "         102,  91, 163,  99, 163, 163,  99,  91, 162, 100, 162, 162, 100,  92,\n",
       "         162,  98, 162, 162,  98,  92, 161,  99, 161, 161,  99,  93, 160,  97,\n",
       "         160, 160,  97,  94, 159,  98, 159, 159,  98,  95, 159,  96, 159, 159,\n",
       "          96,  95, 158,  97, 158, 158,  97,  96, 157,  96, 157, 157,  96,  97,\n",
       "         157,  95, 157, 157,  95,  97, 155,  96, 155, 155,  96,  99, 155,  94,\n",
       "         155, 155,  94,  99, 153,  95, 153, 153,  95, 101, 153,  94, 153, 153,\n",
       "          94, 101, 152,  95, 152, 152,  95, 102, 152,  94, 152, 152,  94, 102,\n",
       "         131, 160, 161, 131, 160, 160, 131, 160, 159, 131, 160,  95, 131, 160,\n",
       "          94, 131, 160,  93, 131, 159, 163, 131, 159, 162, 131, 159, 161, 131,\n",
       "         159, 160, 131, 159, 159, 131, 159,  95, 131, 159,  94, 131, 159,  93,\n",
       "         131, 159,  92, 131, 159,  91, 131, 158, 164, 131, 158, 162, 131, 158,\n",
       "          92, 131, 158,  90, 131, 157, 165, 131, 157, 164, 131, 157, 163, 131,\n",
       "         157,  91, 131, 157,  90, 131, 157,  89, 131, 156, 165, 131, 156, 164,\n",
       "         131, 156,  90, 131, 156,  89, 131, 155, 165, 131, 155, 164, 131, 155,\n",
       "          90, 131, 155,  89, 131, 154, 166, 131, 154, 164, 131, 154,  90, 131,\n",
       "         154,  88, 131, 153, 166, 131, 153, 164, 131, 153,  90, 131, 153,  88,\n",
       "         131, 121, 166, 131, 121, 164, 131, 121,  90, 131, 121,  88, 123, 160,\n",
       "         161, 123, 160, 160, 123, 160, 159, 123, 160,  95, 123, 160,  94, 123,\n",
       "         160,  93, 123, 159, 163, 123, 159, 162, 123, 159, 161, 123, 159, 160,\n",
       "         123, 159, 159, 123, 159,  95, 123, 159,  94, 123, 159,  93, 123, 159,\n",
       "          92, 123, 159,  91, 123, 158, 164, 123, 158, 162, 123, 158,  92, 123,\n",
       "         158,  90, 123, 157, 165, 123, 157, 164, 123, 157, 163, 123, 157,  91,\n",
       "         123, 157,  90, 123, 157,  89, 123, 156, 165, 123, 156, 164, 123, 156,\n",
       "          90, 123, 156,  89, 123, 155, 165, 123, 155, 164, 123, 155,  90, 123,\n",
       "         155,  89, 123, 154, 166, 123, 154, 164, 123, 154,  90, 123, 154,  88,\n",
       "         123, 153, 166, 123, 153, 164, 123, 153,  90, 123, 153,  88, 123, 121,\n",
       "         166, 123, 121, 164, 123, 121,  90, 123, 121,  88, 102,  95, 152, 102,\n",
       "          95, 102, 102,  94, 152, 102,  94, 102, 101,  95, 153, 101,  95, 101,\n",
       "         101,  94, 153, 101,  94, 101,  99,  96, 155,  99,  96,  99,  99,  94,\n",
       "         155,  99,  94,  99,  97,  96, 157,  97,  96,  97,  97,  95, 157,  97,\n",
       "          95,  97,  96,  97, 158,  96,  97,  96,  95,  98, 159,  95,  98,  95,\n",
       "          95,  96, 159,  95,  96,  95,  94,  97, 160,  94,  97,  94,  93,  99,\n",
       "         161,  93,  99,  93,  92, 100, 162,  92, 100,  92,  92,  98, 162,  92,\n",
       "          98,  92,  91, 103, 163,  91, 103,  91,  91, 102, 163,  91, 102,  91,\n",
       "          91,  99, 163,  91,  99,  91,  90, 121, 164,  90, 121,  90,  90, 108,\n",
       "         164,  90, 108,  90,  90, 106, 164,  90, 106,  90,  90, 105, 164,  90,\n",
       "         105,  90,  90, 101, 164,  90, 101,  90,  89, 106, 165,  89, 106,  89,\n",
       "          89, 104, 165,  89, 104,  89,  89, 103, 165,  89, 103,  89,  88, 121,\n",
       "         166,  88, 121,  88,  88, 108, 166,  88, 108,  88]),\n",
       " tensor([164, 163, 164, 164, 163,  90, 164, 154, 164, 164, 154,  90, 163, 154,\n",
       "         164, 163, 154, 163, 163, 154,  91, 163,  91, 163, 163,  91,  91, 162,\n",
       "         163, 162, 162, 163,  92, 162,  92, 162, 162,  92,  92, 162,  91, 162,\n",
       "         162,  91,  92, 144, 153,  92, 144, 153,  91, 144, 146,  92, 144, 146,\n",
       "          91, 138, 153, 163, 138, 153, 162, 138, 146, 163, 138, 146, 162, 133,\n",
       "         153,  92, 133, 153,  91, 133, 146,  92, 133, 146,  91, 128, 154,  92,\n",
       "         128, 154,  91, 128, 146,  92, 128, 146,  91, 125, 153, 163, 125, 153,\n",
       "         162, 125, 146, 163, 125, 146, 162, 121, 153, 163, 121, 153, 162, 121,\n",
       "         146, 163, 121, 146, 162, 117, 154,  92, 117, 154,  91, 117, 146,  92,\n",
       "         117, 146,  91, 111, 153, 163, 111, 153, 162, 111, 146, 163, 111, 146,\n",
       "         162,  92, 163, 162,  92, 163,  92,  92,  92, 162,  92,  92,  92,  92,\n",
       "          91, 162,  92,  91,  92,  91, 154, 163,  91, 154,  91,  91, 154,  90,\n",
       "          91,  91, 163,  91,  91,  91,  90, 163, 164,  90, 163,  90,  90, 154,\n",
       "         164,  90, 154,  90]),\n",
       " tensor([164, 164, 127, 163, 164, 127, 162, 164, 136, 162, 164, 118, 159, 164,\n",
       "         145, 159, 164, 109, 158, 164, 145, 158, 164, 109, 156,  90, 127, 155,\n",
       "          90, 134, 155,  90, 120, 153, 164, 153, 153, 164, 101, 152, 164, 152,\n",
       "         152, 164, 102, 152,  90, 141, 152,  90, 113, 147,  90, 147, 147,  90,\n",
       "         107, 145, 164, 159, 145, 164, 158, 145, 164,  96, 145, 164,  95, 141,\n",
       "          90, 152, 141,  90, 102, 136, 164, 162, 136, 164,  92, 134,  90, 155,\n",
       "         134,  90,  99, 127, 164, 164, 127, 164, 163, 127, 164,  91, 127, 164,\n",
       "          90, 127,  90, 156, 127,  90,  98, 120,  90, 155, 120,  90,  99, 118,\n",
       "         164, 162, 118, 164,  92, 113,  90, 152, 113,  90, 102, 109, 164, 159,\n",
       "         109, 164, 158, 109, 164,  96, 109, 164,  95, 107,  90, 147, 107,  90,\n",
       "         107, 102, 164, 152, 102, 164, 102, 102,  90, 141, 102,  90, 113, 101,\n",
       "         164, 153, 101, 164, 101,  99,  90, 134,  99,  90, 120,  98,  90, 127,\n",
       "          96, 164, 145,  96, 164, 109,  95, 164, 145,  95, 164, 109,  92, 164,\n",
       "         136,  92, 164, 118,  91, 164, 127,  90, 164, 127])]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = dec_vtk.detokenize(dec_vtk.tokenize(v_batch)[\"value_tokens\"])\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'value_tokens': tensor([[0, 2, 2,  ..., 2, 2, 2]]),\n",
       " 'coord_type_tokens': tensor([[0, 0, 0,  ..., 0, 0, 0]]),\n",
       " 'position_tokens': tensor([[0, 0, 0,  ..., 0, 0, 0]]),\n",
       " 'padding_mask': tensor([[False,  True,  True,  ...,  True,  True,  True]])}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec_vtk.get_pred_start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tokenizer for face model (decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([203, 202, 200, 201]),\n",
       " tensor([203, 201, 147, 143,  97, 101,   1,   3]),\n",
       " tensor([203, 195, 194, 202]),\n",
       " tensor([203,   3,   5, 195]),\n",
       " tensor([202, 194,   4,   2])]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_batch[0][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FaceTokenizer(Tokenizer):\n",
    "    \n",
    "    def __init__(self, bof_id=0, eos_id=1, pad_id=2, max_seq_len=None):\n",
    "        self.special_tokens = {\n",
    "            \"bof\": torch.tensor([bof_id]),\n",
    "            \"eos\": torch.tensor([eos_id]),\n",
    "            \"pad\": torch.tensor([pad_id]),\n",
    "        }\n",
    "        self.pad_id = pad_id\n",
    "        self.not_coord_token = torch.tensor([0])\n",
    "        if max_seq_len is not None:\n",
    "            self.max_seq_len = max_seq_len - 1\n",
    "        else:\n",
    "            self.max_seq_len = max_seq_len\n",
    "        \n",
    "    def tokenize(self, faces, padding=True):\n",
    "        special_tokens = self.special_tokens\n",
    "        not_coord_token = self.not_coord_token\n",
    "        max_seq_len = self.max_seq_len\n",
    "        \n",
    "        faces_ids = []\n",
    "        in_position_tokens = []\n",
    "        out_position_tokens = []\n",
    "        faces_target = []\n",
    "\n",
    "        for face in faces:\n",
    "            face_with_bof = [\n",
    "                torch.cat([\n",
    "                    special_tokens[\"bof\"],\n",
    "                    f + len(special_tokens)\n",
    "                ])\n",
    "                for f in face\n",
    "            ]\n",
    "            face = torch.cat([\n",
    "                torch.cat(face_with_bof),\n",
    "                special_tokens[\"eos\"]\n",
    "            ])\n",
    "            faces_ids.append(face)\n",
    "            faces_target.append(torch.cat([face, special_tokens[\"pad\"]])[1:])\n",
    "\n",
    "            in_position_token = torch.cat([\n",
    "                torch.arange(1, len(f)+1)\n",
    "                for f in face_with_bof\n",
    "            ])\n",
    "            in_position_token = torch.cat([in_position_token, not_coord_token])\n",
    "            in_position_tokens.append(in_position_token)\n",
    "\n",
    "            out_position_token = torch.cat([\n",
    "                torch.ones((len(f), ), dtype=torch.int32) * (idx+1)\n",
    "                for idx, f in enumerate(face_with_bof)\n",
    "            ])\n",
    "            out_position_token = torch.cat([out_position_token, not_coord_token])\n",
    "            out_position_tokens.append(out_position_token)\n",
    "        \n",
    "        \n",
    "        if padding:\n",
    "            faces_ids = torch.stack(\n",
    "                self._padding(faces_ids, special_tokens[\"pad\"], max_seq_len)\n",
    "            )\n",
    "            faces_target = torch.stack(\n",
    "                self._padding(faces_target, special_tokens[\"pad\"], max_seq_len)\n",
    "            )\n",
    "            in_position_tokens = torch.stack(\n",
    "                self._padding(in_position_tokens, not_coord_token, max_seq_len)\n",
    "            )\n",
    "            out_position_tokens = torch.stack(\n",
    "                self._padding(out_position_tokens, not_coord_token, max_seq_len)\n",
    "            )\n",
    "\n",
    "            padding_mask = self._make_padding_mask(faces_ids, self.pad_id)\n",
    "            # future_mask = self._make_future_mask(faces)\n",
    "\n",
    "            cond_vertice = faces_ids >= len(special_tokens)\n",
    "            reference_vertices_mask = torch.where(cond_vertice, 1., 0.)\n",
    "            reference_vertices_ids = torch.where(cond_vertice, faces_ids-len(special_tokens), 0)\n",
    "            reference_embed_mask = torch.where(cond_vertice, 0., 1.)\n",
    "            reference_embed_ids = torch.where(cond_vertice, 0, faces_ids)\n",
    "\n",
    "            outputs = {\n",
    "                \"value_tokens\": faces_ids,\n",
    "                \"target_tokens\": faces_target,\n",
    "                \"in_position_tokens\": in_position_tokens,\n",
    "                \"out_position_tokens\": out_position_tokens,\n",
    "                \"ref_v_mask\": reference_vertices_mask,\n",
    "                \"ref_v_ids\": reference_vertices_ids,\n",
    "                \"ref_e_mask\": reference_embed_mask,\n",
    "                \"ref_e_ids\": reference_embed_ids,\n",
    "                \"padding_mask\": padding_mask,\n",
    "                # \"future_mask\": future_mask,\n",
    "            }\n",
    "            \n",
    "        else:\n",
    "            reference_vertices_mask = []\n",
    "            reference_vertices_ids = []\n",
    "            reference_embed_mask = []\n",
    "            reference_embed_ids = []\n",
    "\n",
    "            for f in faces_ids:\n",
    "                cond_vertice = f >= len(special_tokens)\n",
    "\n",
    "                ref_v_mask = torch.where(cond_vertice, 1., 0.)\n",
    "                ref_e_mask = torch.where(cond_vertice, 0., 1.)\n",
    "                ref_v_ids = torch.where(cond_vertice, f-len(special_tokens), 0)\n",
    "                ref_e_ids = torch.where(cond_vertice, 0, f)\n",
    "                \n",
    "                reference_vertices_mask.append(ref_v_mask)\n",
    "                reference_vertices_ids.append(ref_v_ids)\n",
    "                reference_embed_mask.append(ref_e_mask)\n",
    "                reference_embed_ids.append(ref_e_ids)\n",
    "            \n",
    "            outputs = {\n",
    "                \"value_tokens\": faces_ids,\n",
    "                \"target_tokens\": faces_target,\n",
    "                \"in_position_tokens\": in_position_tokens,\n",
    "                \"out_position_tokens\": out_position_tokens,\n",
    "                \"ref_v_mask\": reference_vertices_mask,\n",
    "                \"ref_v_ids\": reference_vertices_ids,\n",
    "                \"ref_e_mask\": reference_embed_mask,\n",
    "                \"ref_e_ids\": reference_embed_ids,\n",
    "            }\n",
    "        \n",
    "        return outputs\n",
    "\n",
    "    def tokenize_prediction(self, faces):\n",
    "        special_tokens = self.special_tokens\n",
    "        not_coord_token = self.not_coord_token\n",
    "        max_seq_len = self.max_seq_len\n",
    "        \n",
    "        faces_ids = []\n",
    "        in_position_tokens = []\n",
    "        out_position_tokens = []\n",
    "        faces_target = []    \n",
    "        \n",
    "        for face in faces:\n",
    "            face = torch.cat([special_tokens[\"bof\"], face])\n",
    "            faces_ids.append(face)\n",
    "            faces_target.append(torch.cat([face, special_tokens[\"pad\"]])[1:])\n",
    "            \n",
    "            \n",
    "            bof_indeces = torch.where(face==special_tokens[\"bof\"])[0]\n",
    "            now_pos_in = 1\n",
    "            now_pos_out = 0\n",
    "            in_position_token = []\n",
    "            out_position_token = []\n",
    "            \n",
    "            for idx, point in enumerate(face):\n",
    "                if idx in bof_indeces:\n",
    "                    now_pos_out += 1\n",
    "                    now_pos_in = 1\n",
    "                \n",
    "                in_position_token.append(now_pos_in)\n",
    "                out_position_token.append(now_pos_out)\n",
    "                now_pos_in += 1\n",
    "                \n",
    "            in_position_tokens.append(torch.tensor(in_position_token))\n",
    "            out_position_tokens.append(torch.tensor(out_position_token))\n",
    "            \n",
    "\n",
    "        faces_ids = torch.stack(\n",
    "            self._padding(faces_ids, special_tokens[\"pad\"], max_seq_len)\n",
    "        )\n",
    "        faces_target = torch.stack(\n",
    "            self._padding(faces_target, special_tokens[\"pad\"], max_seq_len)\n",
    "        )\n",
    "        in_position_tokens = torch.stack(\n",
    "            self._padding(in_position_tokens, not_coord_token, max_seq_len)\n",
    "        )\n",
    "        out_position_tokens = torch.stack(\n",
    "            self._padding(out_position_tokens, not_coord_token, max_seq_len)\n",
    "        )\n",
    "\n",
    "        padding_mask = self._make_padding_mask(faces_ids, self.pad_id)\n",
    "        # future_mask = self._make_future_mask(faces)\n",
    "\n",
    "        cond_vertice = faces_ids >= len(special_tokens)\n",
    "        reference_vertices_mask = torch.where(cond_vertice, 1., 0.)\n",
    "        reference_vertices_ids = torch.where(cond_vertice, faces_ids-len(special_tokens), 0)\n",
    "        reference_embed_mask = torch.where(cond_vertice, 0., 1.)\n",
    "        reference_embed_ids = torch.where(cond_vertice, 0, faces_ids)\n",
    "\n",
    "        outputs = {\n",
    "            \"value_tokens\": faces_ids,\n",
    "            \"target_tokens\": faces_target,\n",
    "            \"in_position_tokens\": in_position_tokens,\n",
    "            \"out_position_tokens\": out_position_tokens,\n",
    "            \"ref_v_mask\": reference_vertices_mask,\n",
    "            \"ref_v_ids\": reference_vertices_ids,\n",
    "            \"ref_e_mask\": reference_embed_mask,\n",
    "            \"ref_e_ids\": reference_embed_ids,\n",
    "            \"padding_mask\": padding_mask,\n",
    "            # \"future_mask\": future_mask,\n",
    "        }\n",
    "        \n",
    "        return outputs\n",
    "    \n",
    "    \n",
    "    def detokenize(self, faces):\n",
    "        special_tokens = self.special_tokens\n",
    "        \n",
    "        result = []\n",
    "        for face in faces:\n",
    "            face = face - len(special_tokens)\n",
    "            result.append(\n",
    "                face[torch.where(face >= 0)]\n",
    "            )\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "ftk = FaceTokenizer(max_seq_len=3800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value_tokens :\n",
      "torch.Size([3, 3800])\n",
      "tensor([[  0, 206, 205, 203, 204,   0, 206, 204, 150, 146],\n",
      "        [  0,  64,  63,  61,  62,   0,  64,  62,   4,   6],\n",
      "        [  0,  66,  66,  64,  64,   0,  66,  66,  64,  64]])\n",
      "tensor([[2, 2, 2, 2, 2, 2, 2, 2, 2, 2],\n",
      "        [2, 2, 2, 2, 2, 2, 2, 2, 2, 2],\n",
      "        [2, 2, 2, 2, 2, 2, 2, 2, 2, 2]])\n",
      "============================================================\n",
      "target_tokens :\n",
      "torch.Size([3, 3800])\n",
      "tensor([[206, 205, 203, 204,   0, 206, 204, 150, 146, 100],\n",
      "        [ 64,  63,  61,  62,   0,  64,  62,   4,   6,  58],\n",
      "        [ 66,  66,  64,  64,   0,  66,  66,  64,  64,   0]])\n",
      "tensor([[2, 2, 2, 2, 2, 2, 2, 2, 2, 2],\n",
      "        [2, 2, 2, 2, 2, 2, 2, 2, 2, 2],\n",
      "        [2, 2, 2, 2, 2, 2, 2, 2, 2, 2]])\n",
      "============================================================\n",
      "in_position_tokens :\n",
      "torch.Size([3, 3800])\n",
      "tensor([[1, 2, 3, 4, 5, 1, 2, 3, 4, 5],\n",
      "        [1, 2, 3, 4, 5, 1, 2, 3, 4, 5],\n",
      "        [1, 2, 3, 4, 5, 1, 2, 3, 4, 5]])\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
      "============================================================\n",
      "out_position_tokens :\n",
      "torch.Size([3, 3800])\n",
      "tensor([[1, 1, 1, 1, 1, 2, 2, 2, 2, 2],\n",
      "        [1, 1, 1, 1, 1, 2, 2, 2, 2, 2],\n",
      "        [1, 1, 1, 1, 1, 2, 2, 2, 2, 2]])\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
      "============================================================\n",
      "ref_v_mask :\n",
      "torch.Size([3, 3800])\n",
      "tensor([[0., 1., 1., 1., 1., 0., 1., 1., 1., 1.],\n",
      "        [0., 1., 1., 1., 1., 0., 1., 1., 1., 1.],\n",
      "        [0., 1., 1., 1., 1., 0., 1., 1., 1., 1.]])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "============================================================\n",
      "ref_v_ids :\n",
      "torch.Size([3, 3800])\n",
      "tensor([[  0, 203, 202, 200, 201,   0, 203, 201, 147, 143],\n",
      "        [  0,  61,  60,  58,  59,   0,  61,  59,   1,   3],\n",
      "        [  0,  63,  63,  61,  61,   0,  63,  63,  61,  61]])\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
      "============================================================\n",
      "ref_e_mask :\n",
      "torch.Size([3, 3800])\n",
      "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 1., 0., 0., 0., 0.]])\n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]])\n",
      "============================================================\n",
      "ref_e_ids :\n",
      "torch.Size([3, 3800])\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
      "tensor([[2, 2, 2, 2, 2, 2, 2, 2, 2, 2],\n",
      "        [2, 2, 2, 2, 2, 2, 2, 2, 2, 2],\n",
      "        [2, 2, 2, 2, 2, 2, 2, 2, 2, 2]])\n",
      "============================================================\n",
      "padding_mask :\n",
      "torch.Size([3, 3800])\n",
      "tensor([[False, False, False, False, False, False, False, False, False, False],\n",
      "        [False, False, False, False, False, False, False, False, False, False],\n",
      "        [False, False, False, False, False, False, False, False, False, False]])\n",
      "tensor([[True, True, True, True, True, True, True, True, True, True],\n",
      "        [True, True, True, True, True, True, True, True, True, True],\n",
      "        [True, True, True, True, True, True, True, True, True, True]])\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "for k, vs in ftk.tokenize(f_batch).items():\n",
    "    print(k, \":\")\n",
    "    print(vs.shape)\n",
    "    print(torch.stack([v[:10] for v in vs]))\n",
    "    print(torch.stack([v[-10:] for v in vs]))\n",
    "    print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value_tokens :\n",
      "tensor([[  0, 206, 205, 203, 204,   0, 206, 204, 150, 146],\n",
      "        [  0,  64,  63,  61,  62,   0,  64,  62,   4,   6],\n",
      "        [  0,  66,  66,  64,  64,   0,  66,  66,  64,  64]])\n",
      "tensor([[ 8,  6,  5,  7,  0,  6,  4,  3,  5,  1],\n",
      "        [11,  9,  8, 10,  0,  6,  4,  3,  5,  1],\n",
      "        [ 5,  4,  4,  5,  0,  5,  4,  3,  5,  1]])\n",
      "============================================================\n",
      "target_tokens :\n",
      "tensor([[206, 205, 203, 204,   0, 206, 204, 150, 146, 100],\n",
      "        [ 64,  63,  61,  62,   0,  64,  62,   4,   6,  58],\n",
      "        [ 66,  66,  64,  64,   0,  66,  66,  64,  64,   0]])\n",
      "tensor([[ 6,  5,  7,  0,  6,  4,  3,  5,  1,  2],\n",
      "        [ 9,  8, 10,  0,  6,  4,  3,  5,  1,  2],\n",
      "        [ 4,  4,  5,  0,  5,  4,  3,  5,  1,  2]])\n",
      "============================================================\n",
      "in_position_tokens :\n",
      "tensor([[1, 2, 3, 4, 5, 1, 2, 3, 4, 5],\n",
      "        [1, 2, 3, 4, 5, 1, 2, 3, 4, 5],\n",
      "        [1, 2, 3, 4, 5, 1, 2, 3, 4, 5]])\n",
      "tensor([[2, 3, 4, 5, 1, 2, 3, 4, 5, 0],\n",
      "        [2, 3, 4, 5, 1, 2, 3, 4, 5, 0],\n",
      "        [2, 3, 4, 5, 1, 2, 3, 4, 5, 0]])\n",
      "============================================================\n",
      "out_position_tokens :\n",
      "tensor([[1, 1, 1, 1, 1, 2, 2, 2, 2, 2],\n",
      "        [1, 1, 1, 1, 1, 2, 2, 2, 2, 2],\n",
      "        [1, 1, 1, 1, 1, 2, 2, 2, 2, 2]])\n",
      "tensor([[159, 159, 159, 159, 160, 160, 160, 160, 160,   0],\n",
      "        [ 44,  44,  44,  44,  45,  45,  45,  45,  45,   0],\n",
      "        [600, 600, 600, 600, 601, 601, 601, 601, 601,   0]])\n",
      "============================================================\n",
      "ref_v_mask :\n",
      "tensor([[0., 1., 1., 1., 1., 0., 1., 1., 1., 1.],\n",
      "        [0., 1., 1., 1., 1., 0., 1., 1., 1., 1.],\n",
      "        [0., 1., 1., 1., 1., 0., 1., 1., 1., 1.]])\n",
      "tensor([[1., 1., 1., 1., 0., 1., 1., 1., 1., 0.],\n",
      "        [1., 1., 1., 1., 0., 1., 1., 1., 1., 0.],\n",
      "        [1., 1., 1., 1., 0., 1., 1., 1., 1., 0.]])\n",
      "============================================================\n",
      "ref_v_ids :\n",
      "tensor([[  0, 203, 202, 200, 201,   0, 203, 201, 147, 143],\n",
      "        [  0,  61,  60,  58,  59,   0,  61,  59,   1,   3],\n",
      "        [  0,  63,  63,  61,  61,   0,  63,  63,  61,  61]])\n",
      "tensor([[5, 3, 2, 4, 0, 3, 1, 0, 2, 0],\n",
      "        [8, 6, 5, 7, 0, 3, 1, 0, 2, 0],\n",
      "        [2, 1, 1, 2, 0, 2, 1, 0, 2, 0]])\n",
      "============================================================\n",
      "ref_e_mask :\n",
      "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 1., 0., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 1.]])\n",
      "============================================================\n",
      "ref_e_ids :\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]])\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "for k, vs in ftk.tokenize(f_batch, padding=False).items():\n",
    "    print(k, \":\")\n",
    "    print(torch.stack([v[:10] for v in vs]))\n",
    "    print(torch.stack([v[-10:] for v in vs]))\n",
    "    print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([203, 202, 200, 201, 203, 201, 147, 143,  97, 101,   1,   3, 203, 195,\n",
       "         194, 202, 203,   3,   5, 195, 202, 194,   4,   2, 202,   2,   0,  98,\n",
       "          94, 140, 144, 200, 201, 200, 144, 145, 184, 185, 146, 147, 199, 198,\n",
       "         196, 197, 199, 197,   7,   9, 199, 193, 192, 198, 199,   9,  19, 193,\n",
       "         198, 192,  18,   8, 198,   8,   6, 196, 197, 196, 194, 195, 197, 195,\n",
       "           5,   7, 196,   6,   4, 194, 193, 183, 182, 192, 193,  19,  25, 183,\n",
       "         192, 182,  24,  18, 191, 190, 178, 179, 191, 189, 188, 190, 191, 179,\n",
       "          21,  17, 191,  17,  15, 189, 190, 188,  14,  16, 190,  16,  20, 178,\n",
       "         189, 187, 186, 188, 189,  15,  13, 187, 188, 186,  12,  14, 187, 185,\n",
       "         184, 186, 187,  13,  11, 100,  96, 142, 146, 185, 186, 184, 145, 141,\n",
       "          95,  99,  10,  12, 183, 177, 176, 182, 183,  25,  29, 177, 182, 176,\n",
       "          28,  24, 181, 180, 174, 175, 181, 179, 178, 180, 181, 175,  27,  23,\n",
       "         181,  23,  21, 179, 180, 178,  20,  22, 180,  22,  26, 174, 177, 171,\n",
       "         170, 176, 177,  29,  33, 171, 176, 170,  32,  28, 175, 174, 172, 173,\n",
       "         175, 173,  31,  27, 174,  26,  30, 172, 173, 172, 166, 167, 173, 167,\n",
       "          35,  31, 172,  30,  34, 166, 171, 169, 168, 170, 171,  33,  37, 169,\n",
       "         170, 168,  36,  32, 169, 163, 162, 168, 169,  37,  43, 163, 168, 162,\n",
       "          42,  36, 167, 166, 164, 165, 167, 165,  39,  35, 166,  34,  38, 164,\n",
       "         165, 164, 160, 161, 165, 161,  41,  39, 164,  38,  40, 160, 163, 159,\n",
       "         158, 162, 163,  43,  47, 159, 162, 158,  46,  42, 161, 160, 156, 157,\n",
       "         161, 157,  45,  41, 160,  40,  44, 156, 159, 155, 154, 158, 159,  47,\n",
       "          51, 155, 158, 154,  50,  46, 157, 156, 152, 153, 157, 153,  49,  45,\n",
       "         156,  44,  48, 152, 155, 151, 150, 154, 155,  51,  55, 151, 154, 150,\n",
       "          54,  50, 153, 152, 148, 149, 153, 149,  53,  49, 152,  48,  52, 148,\n",
       "         151,  55,  54, 150, 149, 148,  52,  53, 147, 146, 142, 138, 134, 130,\n",
       "         130, 125, 125, 120, 120, 115, 114, 114, 113, 112, 111, 111, 110, 119,\n",
       "         119, 124, 124, 129, 129, 133, 137, 141, 145, 144, 140, 136, 132, 128,\n",
       "         122, 123, 118, 108, 109, 109, 102, 103, 104, 105, 106, 107, 115, 116,\n",
       "         117, 121, 126, 127, 131, 135, 139, 143, 143, 139,  93,  97, 142,  96,\n",
       "          92, 138, 141, 137,  91,  95, 140,  94,  90, 136, 139, 135,  89,  93,\n",
       "         138,  92,  88, 134, 137, 133,  87,  91, 136,  90,  86, 132, 135, 131,\n",
       "          85,  89, 134,  88,  84, 130, 133, 129,  83,  87, 132,  86,  82, 128,\n",
       "         131, 127,  81,  85, 130, 130,  84,  84, 130,  84,  79, 125, 129, 129,\n",
       "          83,  83, 129, 124,  78,  83, 128,  82,  76, 122, 127, 126,  80,  81,\n",
       "         126, 121,  75,  80, 125, 125,  79,  79, 125,  79,  74, 120, 124, 124,\n",
       "          78,  78, 124, 119,  73,  78, 123, 122,  76,  77, 123,  77,  72, 118,\n",
       "         121, 117,  71,  75, 120, 120,  74,  74, 120,  74,  69, 115, 119, 110,\n",
       "          64,  73, 119,  73,  73, 119, 118,  72,  62, 108, 117, 116,  70,  71,\n",
       "         116, 115,  69,  70, 115, 107,  61,  69, 115,  69,  68, 114, 114,  68,\n",
       "          68, 114, 114,  68,  67, 113, 113,  67,  66, 112, 112,  66,  65, 111,\n",
       "         111, 111,  65,  65, 111,  65,  64, 110, 109, 109,  63,  63, 109, 108,\n",
       "          62,  63, 109,  63,  56, 102, 107, 106,  60,  61, 106, 105,  59,  60,\n",
       "         105, 104,  58,  59, 104, 103,  57,  58, 103, 102,  56,  57, 101, 100,\n",
       "          11,  10,  99,  98,   0,   1, 101,  97,  93,  89,  85,  81,  80,  75,\n",
       "          71,  70,  69,  61,  60,  59,  58,  57,  56,  63,  63,  62,  72,  77,\n",
       "          76,  82,  86,  90,  94,  98,  99,  95,  91,  87,  83,  83,  78,  78,\n",
       "          73,  73,  64,  65,  65,  66,  67,  68,  68,  69,  74,  74,  79,  79,\n",
       "          84,  84,  88,  92,  96, 100,  55,  51,  50,  54,  53,  52,  48,  49,\n",
       "          51,  47,  46,  50,  49,  48,  44,  45,  47,  43,  42,  46,  45,  44,\n",
       "          40,  41,  43,  37,  36,  42,  41,  40,  38,  39,  39,  38,  34,  35,\n",
       "          37,  33,  32,  36,  35,  34,  30,  31,  33,  29,  28,  32,  31,  30,\n",
       "          26,  27,  29,  25,  24,  28,  27,  26,  22,  23,  25,  19,  18,  24,\n",
       "          23,  22,  20,  21,  21,  20,  16,  17,  19,   9,   8,  18,  17,  16,\n",
       "          14,  15,  15,  14,  12,  13,  13,  12,  10,  11,   9,   7,   6,   8,\n",
       "           7,   5,   4,   6,   5,   3,   2,   4,   3,   1,   0,   2]),\n",
       " tensor([61, 60, 58, 59, 61, 59,  1,  3, 55, 61, 55, 53,  4, 60, 60,  4,  2,  0,\n",
       "         58, 59, 58,  0,  1, 48, 10,  9, 47, 59, 47, 48,  1, 57, 56, 53, 54, 57,\n",
       "         54, 42, 30, 24, 26, 18, 16, 28,  6,  8, 57,  8, 52, 51, 13,  7, 56, 56,\n",
       "          7,  5, 21, 33, 31, 43, 35, 37, 45, 53, 55, 54, 53, 55,  3,  2,  4, 53,\n",
       "          5,  6, 54, 54,  6, 28, 40, 42, 53, 45, 43, 31, 19, 21,  5, 52, 50, 49,\n",
       "         51, 52, 14, 12, 50, 52,  8,  7, 13, 14, 51, 49, 11, 13, 50, 48, 47, 49,\n",
       "         50, 25, 23, 29, 41, 39, 27, 10, 48, 50, 12, 11, 49, 50, 12, 10, 27, 29,\n",
       "         23, 15, 17, 25, 49, 47, 44, 46, 38, 34, 22, 11, 47,  9, 11, 22, 20, 32,\n",
       "         34, 38, 36, 44, 46, 45, 37, 38, 46, 44, 43, 45, 44, 36, 35, 43, 42, 41,\n",
       "         29, 30, 42, 40, 39, 41, 40, 28, 27, 39, 38, 37, 35, 36, 34, 33, 21, 22,\n",
       "         34, 32, 31, 33, 32, 20, 19, 31, 30, 29, 27, 28, 30, 28, 16, 24, 26, 25,\n",
       "         17, 18, 26, 24, 23, 25, 24, 16, 15, 23, 22, 21, 19, 20, 18, 17, 15, 16,\n",
       "         14, 13, 11, 12, 12, 11,  9, 10,  8,  6,  5,  7,  3,  1,  0,  2]),\n",
       " tensor([63, 63, 61,  ...,  1,  0,  2])]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = ftk.detokenize(ftk.tokenize(f_batch)[\"value_tokens\"])\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'value_tokens': tensor([[0, 2, 2,  ..., 2, 2, 2]]),\n",
       " 'coord_type_tokens': tensor([[0, 0, 0,  ..., 0, 0, 0]]),\n",
       " 'position_tokens': tensor([[0, 0, 0,  ..., 0, 0, 0]]),\n",
       " 'padding_mask': tensor([[False,  True,  True,  ...,  True,  True,  True]])}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ftk.get_pred_start(\"bof\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'value_tokens': tensor([[  0, 589, 423,  ...,   2,   2,   2]]),\n",
       " 'target_tokens': tensor([[589, 423,   0,  ...,   2,   2,   2]]),\n",
       " 'in_position_tokens': tensor([[1, 2, 3,  ..., 0, 0, 0]]),\n",
       " 'out_position_tokens': tensor([[1, 1, 1,  ..., 0, 0, 0]]),\n",
       " 'ref_v_mask': tensor([[0., 1., 1.,  ..., 0., 0., 0.]]),\n",
       " 'ref_v_ids': tensor([[  0, 586, 420,  ...,   0,   0,   0]]),\n",
       " 'ref_e_mask': tensor([[1., 0., 0.,  ..., 1., 1., 1.]]),\n",
       " 'ref_e_ids': tensor([[0, 0, 0,  ..., 2, 2, 2]]),\n",
       " 'padding_mask': tensor([[False, False, False,  ...,  True,  True,  True]])}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ftk.tokenize_prediction([torch.tensor([589, 423, 0, 30, 21])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
