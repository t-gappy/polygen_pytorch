{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import open3d as o3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = os.path.dirname(os.getcwd())\n",
    "data_dir = os.path.join(base_dir, \"data\")\n",
    "src_dir = os.path.join(base_dir, \"src\")\n",
    "sys.path.append(os.path.join(src_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7003, 1088)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_files = glob.glob(os.path.join(data_dir, \"original\", \"train\", \"*\", \"*.obj\"))\n",
    "valid_files = glob.glob(os.path.join(data_dir, \"original\", \"val\", \"*\", \"*.obj\"))\n",
    "len(train_files), len(valid_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import load_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tokenizer(object):\n",
    "    \n",
    "    def _padding(self, ids_tensor, pad_token):\n",
    "        max_length = max([len(ids) for ids in ids_tensor])\n",
    "        ids_tensor = [\n",
    "            torch.cat([\n",
    "                ids, pad_token.repeat(max_length - len(ids) + 1)\n",
    "            ])\n",
    "            for ids in ids_tensor\n",
    "        ]\n",
    "        return ids_tensor\n",
    "    \n",
    "    def _make_padding_mask(self, ids_tensor, pad_id):\n",
    "        mask = torch.where(\n",
    "            ids_tensor==pad_id,\n",
    "            torch.ones_like(ids_tensor),\n",
    "            torch.zeros_like(ids_tensor)\n",
    "        ).type(torch.bool)\n",
    "        return mask\n",
    "\n",
    "    def _make_future_mask(self, ids_tensor):\n",
    "        batch, length = ids_tensor.shape\n",
    "        arange = torch.arange(length)\n",
    "        mask = torch.where(\n",
    "            arange[None, :] <= arange[:, None],\n",
    "            torch.zeros((length, length)),\n",
    "            torch.ones((length, length))*(-np.inf)\n",
    "        ).type(torch.float32)\n",
    "        return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([655, 3]) torch.Size([1317, 3])\n",
      "============================================================\n",
      "torch.Size([310, 3]) torch.Size([676, 3])\n",
      "============================================================\n",
      "torch.Size([396, 3]) torch.Size([1184, 3])\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "v_batch, f_batch = [], []\n",
    "for i in range(3):\n",
    "    v, f = load_pipeline(train_files[i])\n",
    "    v = torch.tensor(v)\n",
    "    f = torch.tensor(f)\n",
    "    v_batch.append(v)\n",
    "    f_batch.append(f)\n",
    "    print(v.shape, f.shape)\n",
    "    print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 頂点エンコーダ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncodeVertexTokenizer(Tokenizer):\n",
    "    \n",
    "    def __init__(self, pad_id=0):\n",
    "        self.pad_token = torch.tensor([pad_id])\n",
    "        self.pad_id = pad_id\n",
    "        \n",
    "    def tokenize(self, vertices, padding=True):\n",
    "        vertices = [v.reshape(-1,) + 1 for v in vertices]\n",
    "        coord_type_tokens = [torch.arange(len(v)) % 3 + 1 for v in vertices]\n",
    "        position_ids = [torch.arange(len(v)) // 3 + 1 for v in vertices]\n",
    "        \n",
    "        if padding:\n",
    "            vertices = torch.stack(self._padding(vertices, self.pad_token))\n",
    "            coord_type_tokens = torch.stack(self._padding(coord_type_tokens, self.pad_token))\n",
    "            position_ids = torch.stack(self._padding(position_ids, self.pad_token))\n",
    "            padding_mask = self._make_padding_mask(vertices, self.pad_id)\n",
    "            \n",
    "            outputs = {\n",
    "                \"value_tokens\": vertices,\n",
    "                \"coord_type_tokens\": coord_type_tokens,\n",
    "                \"position_ids\": position_ids,\n",
    "                \"padding_mask\": padding_mask,\n",
    "            }\n",
    "        else:\n",
    "            outputs = {\n",
    "                \"value_token\": vertices,\n",
    "                \"coord_type_tokens\": coord_type_tokens,\n",
    "                \"position_ids\": position_ids,\n",
    "            }\n",
    "            \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_vtk = EncodeVertexTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'value_tokens': tensor([[161, 137, 133,  ..., 137, 123,   0],\n",
       "         [135, 162, 130,  ...,   0,   0,   0],\n",
       "         [163,  99, 134,  ...,   0,   0,   0]]),\n",
       " 'coord_type_tokens': tensor([[1, 2, 3,  ..., 2, 3, 0],\n",
       "         [1, 2, 3,  ..., 0, 0, 0],\n",
       "         [1, 2, 3,  ..., 0, 0, 0]]),\n",
       " 'position_ids': tensor([[  1,   1,   1,  ..., 655, 655,   0],\n",
       "         [  1,   1,   1,  ...,   0,   0,   0],\n",
       "         [  1,   1,   1,  ...,   0,   0,   0]]),\n",
       " 'padding_mask': tensor([[False, False, False,  ..., False, False,  True],\n",
       "         [False, False, False,  ...,  True,  True,  True],\n",
       "         [False, False, False,  ...,  True,  True,  True]])}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_vtk.tokenize(v_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value_tokens :\n",
      "torch.Size([3, 1966])\n",
      "tensor([[161, 137, 133, 161, 137, 131, 161, 137, 127, 161],\n",
      "        [135, 162, 130, 135, 162, 126, 135, 153, 130, 135],\n",
      "        [163,  99, 134, 163,  99, 130, 163,  99, 125, 163]])\n",
      "tensor([[ 95, 137, 128,  95, 137, 125,  95, 137, 123,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0]])\n",
      "============================================================\n",
      "coord_type_tokens :\n",
      "torch.Size([3, 1966])\n",
      "tensor([[1, 2, 3, 1, 2, 3, 1, 2, 3, 1],\n",
      "        [1, 2, 3, 1, 2, 3, 1, 2, 3, 1],\n",
      "        [1, 2, 3, 1, 2, 3, 1, 2, 3, 1]])\n",
      "tensor([[1, 2, 3, 1, 2, 3, 1, 2, 3, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
      "============================================================\n",
      "position_ids :\n",
      "torch.Size([3, 1966])\n",
      "tensor([[1, 1, 1, 2, 2, 2, 3, 3, 3, 4],\n",
      "        [1, 1, 1, 2, 2, 2, 3, 3, 3, 4],\n",
      "        [1, 1, 1, 2, 2, 2, 3, 3, 3, 4]])\n",
      "tensor([[653, 653, 653, 654, 654, 654, 655, 655, 655,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0]])\n",
      "============================================================\n",
      "padding_mask :\n",
      "torch.Size([3, 1966])\n",
      "tensor([[False, False, False, False, False, False, False, False, False, False],\n",
      "        [False, False, False, False, False, False, False, False, False, False],\n",
      "        [False, False, False, False, False, False, False, False, False, False]])\n",
      "tensor([[False, False, False, False, False, False, False, False, False,  True],\n",
      "        [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True]])\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "for k, vs in enc_vtk.tokenize(v_batch).items():\n",
    "    print(k, \":\")\n",
    "    print(vs.shape)\n",
    "    print(torch.stack([v[:10] for v in vs]))\n",
    "    print(torch.stack([v[-10:] for v in vs]))\n",
    "    print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'value_token': [tensor([161, 137, 133,  ...,  95, 137, 123]),\n",
       "  tensor([135, 162, 130, 135, 162, 126, 135, 153, 130, 135, 153, 128, 135, 153,\n",
       "          126, 135, 143, 128, 135, 143, 126, 135, 134, 130, 135, 134, 128, 135,\n",
       "          134, 126, 135, 124, 128, 135, 124, 126, 135, 115, 130, 135, 115, 128,\n",
       "          135, 115, 126, 135, 105, 130, 135, 105, 126, 135,  67, 130, 135,  67,\n",
       "          128, 135,  67, 126, 135,  65, 130, 135,  65, 128, 135,  65, 126, 134,\n",
       "          181, 130, 134, 181, 126, 134, 172, 131, 134, 172, 130, 134, 172, 128,\n",
       "          134, 172, 126, 134, 172, 125, 134, 162, 131, 134, 162, 125, 134, 153,\n",
       "          132, 134, 153, 124, 134, 143, 132, 134, 143, 124, 134, 134, 132, 134,\n",
       "          134, 124, 134, 124, 132, 134, 124, 124, 134, 115, 132, 134, 115, 124,\n",
       "          134, 105, 131, 134, 105, 125, 134,  96, 131, 134,  96, 130, 134,  96,\n",
       "          128, 134,  96, 126, 134,  96, 125, 134,  86, 130, 134,  86, 126, 134,\n",
       "           67, 132, 134,  67, 124, 134,  65, 132, 134,  65, 124, 133, 191, 131,\n",
       "          133, 191, 129, 133, 191, 128, 133, 191, 127, 133, 191, 125, 133, 181,\n",
       "          131, 133, 181, 125, 133, 172, 133, 133, 172, 123, 133, 153, 133, 133,\n",
       "          153, 123, 133, 143, 133, 133, 143, 123, 133, 134, 123, 133, 124, 133,\n",
       "          133, 124, 123, 133, 115, 133, 133, 115, 123, 133,  96, 133, 133,  96,\n",
       "          123, 133,  86, 131, 133,  86, 125, 133,  77, 131, 133,  77, 129, 133,\n",
       "           77, 128, 133,  77, 127, 133,  77, 125, 133,  67, 133, 133,  67, 123,\n",
       "          133,  65, 133, 133,  65, 123, 132, 191, 132, 132, 191, 124, 132, 153,\n",
       "          134, 132, 153, 122, 132, 143, 134, 132, 134, 134, 132, 134, 122, 132,\n",
       "          124, 134, 132, 115, 134, 132, 115, 122, 132,  77, 132, 132,  77, 124,\n",
       "          132,  67, 134, 132,  67, 122, 132,  65, 134, 132,  65, 122, 131, 191,\n",
       "          133, 131, 191, 123, 131, 181, 133, 131, 181, 123, 131, 172, 134, 131,\n",
       "          172, 122, 131, 162, 134, 131, 162, 122, 131, 105, 134, 131, 105, 122,\n",
       "          131,  96, 134, 131,  96, 122, 131,  86, 133, 131,  86, 123, 131,  77,\n",
       "          133, 131,  77, 123, 130, 181, 134, 130, 181, 122, 130, 162, 135, 130,\n",
       "          162, 121, 130, 153, 135, 130, 153, 121, 130, 143, 135, 130, 134, 135,\n",
       "          130, 134, 121, 130, 124, 135, 130, 115, 135, 130, 115, 121, 130, 105,\n",
       "          135, 130, 105, 121, 130,  86, 134, 130,  86, 122, 130,  67, 135, 130,\n",
       "           67, 121, 130,  65, 135, 130,  65, 121, 129, 191, 133, 129, 191, 123,\n",
       "          129,  77, 133, 129,  77, 129, 129,  77, 128, 129,  77, 127, 129,  77,\n",
       "          123, 129,  67, 129, 129,  67, 128, 129,  67, 127, 128, 191, 133, 128,\n",
       "          191, 123, 128, 181, 134, 128, 181, 122, 128, 172, 122, 128, 162, 135,\n",
       "          128, 162, 121, 128, 153, 121, 128, 143, 135, 128, 134, 121, 128, 124,\n",
       "          135, 128, 124, 121, 128, 115, 121, 128, 105, 135, 128, 105, 121, 128,\n",
       "           86, 134, 128,  86, 122, 128,  77, 133, 128,  77, 129, 128,  77, 127,\n",
       "          128,  77, 123, 128,  67, 135, 128,  67, 129, 128,  67, 127, 128,  67,\n",
       "          121, 128,  65, 135, 128,  65, 121, 127, 191, 133, 127, 191, 123, 127,\n",
       "           77, 133, 127,  77, 129, 127,  77, 128, 127,  77, 127, 127,  77, 123,\n",
       "          127,  67, 129, 127,  67, 128, 127,  67, 127, 126, 181, 134, 126, 172,\n",
       "          134, 126, 172, 122, 126, 162, 135, 126, 153, 135, 126, 153, 121, 126,\n",
       "          143, 135, 126, 134, 135, 126, 134, 121, 126, 124, 135, 126, 124, 121,\n",
       "          126, 115, 135, 126, 115, 121, 126, 105, 135, 126, 105, 121, 126,  96,\n",
       "          134, 126,  96, 122, 126,  86, 134, 126,  86, 122, 126,  67, 135, 126,\n",
       "           67, 121, 126,  65, 135, 126,  65, 121, 125, 191, 133, 125, 191, 123,\n",
       "          125, 181, 133, 125, 181, 123, 125, 172, 134, 125, 172, 122, 125, 162,\n",
       "          134, 125, 162, 122, 125, 105, 134, 125, 105, 122, 125,  96, 134, 125,\n",
       "           96, 122, 125,  86, 133, 125,  86, 123, 125,  77, 133, 125,  77, 123,\n",
       "          124, 191, 132, 124, 191, 124, 124, 181, 132, 124, 181, 124, 124, 153,\n",
       "          134, 124, 153, 122, 124, 134, 134, 124, 134, 122, 124, 115, 134, 124,\n",
       "          115, 122, 124,  86, 132, 124,  86, 124, 124,  77, 132, 124,  77, 124,\n",
       "          124,  67, 134, 124,  67, 122, 124,  65, 134, 124,  65, 122, 123, 191,\n",
       "          131, 123, 191, 129, 123, 191, 128, 123, 191, 127, 123, 191, 125, 123,\n",
       "          172, 133, 123, 172, 123, 123, 162, 133, 123, 162, 123, 123, 153, 133,\n",
       "          123, 153, 123, 123, 143, 133, 123, 134, 133, 123, 134, 123, 123, 124,\n",
       "          133, 123, 115, 133, 123, 115, 123, 123, 105, 133, 123, 105, 123, 123,\n",
       "           96, 123, 123,  86, 131, 123,  77, 131, 123,  77, 129, 123,  77, 128,\n",
       "          123,  77, 127, 123,  77, 125, 123,  67, 133, 123,  67, 123, 123,  65,\n",
       "          133, 123,  65, 123, 122, 172, 131, 122, 172, 130, 122, 172, 128, 122,\n",
       "          172, 126, 122, 172, 125, 122, 153, 132, 122, 153, 124, 122, 143, 132,\n",
       "          122, 134, 132, 122, 134, 124, 122, 124, 132, 122, 115, 132, 122, 115,\n",
       "          124, 122, 105, 131, 122,  96, 131, 122,  96, 130, 122,  96, 128, 122,\n",
       "           96, 126, 122,  96, 125, 122,  67, 132, 122,  67, 124, 122,  65, 132,\n",
       "          122,  65, 124, 121, 153, 130, 121, 153, 128, 121, 153, 126, 121, 134,\n",
       "          130, 121, 134, 128, 121, 134, 126, 121, 115, 130, 121, 115, 128, 121,\n",
       "          115, 126, 121,  67, 130, 121,  67, 128, 121,  67, 126, 121,  65, 130,\n",
       "          121,  65, 128, 121,  65, 126]),\n",
       "  tensor([163,  99, 134,  ...,  93,  88, 122])],\n",
       " 'coord_type_tokens': [tensor([1, 2, 3,  ..., 1, 2, 3]),\n",
       "  tensor([1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3,\n",
       "          1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3,\n",
       "          1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3,\n",
       "          1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3,\n",
       "          1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3,\n",
       "          1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3,\n",
       "          1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3,\n",
       "          1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3,\n",
       "          1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3,\n",
       "          1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3,\n",
       "          1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3,\n",
       "          1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3,\n",
       "          1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3,\n",
       "          1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3,\n",
       "          1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3,\n",
       "          1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3,\n",
       "          1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3,\n",
       "          1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3,\n",
       "          1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3,\n",
       "          1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3,\n",
       "          1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3,\n",
       "          1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3,\n",
       "          1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3,\n",
       "          1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3,\n",
       "          1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3,\n",
       "          1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3,\n",
       "          1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3,\n",
       "          1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3,\n",
       "          1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3,\n",
       "          1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3,\n",
       "          1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3,\n",
       "          1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3,\n",
       "          1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3,\n",
       "          1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3,\n",
       "          1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3,\n",
       "          1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3,\n",
       "          1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3,\n",
       "          1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3,\n",
       "          1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3]),\n",
       "  tensor([1, 2, 3,  ..., 1, 2, 3])],\n",
       " 'position_ids': [tensor([  1,   1,   1,  ..., 655, 655, 655]),\n",
       "  tensor([  1,   1,   1,   2,   2,   2,   3,   3,   3,   4,   4,   4,   5,   5,\n",
       "            5,   6,   6,   6,   7,   7,   7,   8,   8,   8,   9,   9,   9,  10,\n",
       "           10,  10,  11,  11,  11,  12,  12,  12,  13,  13,  13,  14,  14,  14,\n",
       "           15,  15,  15,  16,  16,  16,  17,  17,  17,  18,  18,  18,  19,  19,\n",
       "           19,  20,  20,  20,  21,  21,  21,  22,  22,  22,  23,  23,  23,  24,\n",
       "           24,  24,  25,  25,  25,  26,  26,  26,  27,  27,  27,  28,  28,  28,\n",
       "           29,  29,  29,  30,  30,  30,  31,  31,  31,  32,  32,  32,  33,  33,\n",
       "           33,  34,  34,  34,  35,  35,  35,  36,  36,  36,  37,  37,  37,  38,\n",
       "           38,  38,  39,  39,  39,  40,  40,  40,  41,  41,  41,  42,  42,  42,\n",
       "           43,  43,  43,  44,  44,  44,  45,  45,  45,  46,  46,  46,  47,  47,\n",
       "           47,  48,  48,  48,  49,  49,  49,  50,  50,  50,  51,  51,  51,  52,\n",
       "           52,  52,  53,  53,  53,  54,  54,  54,  55,  55,  55,  56,  56,  56,\n",
       "           57,  57,  57,  58,  58,  58,  59,  59,  59,  60,  60,  60,  61,  61,\n",
       "           61,  62,  62,  62,  63,  63,  63,  64,  64,  64,  65,  65,  65,  66,\n",
       "           66,  66,  67,  67,  67,  68,  68,  68,  69,  69,  69,  70,  70,  70,\n",
       "           71,  71,  71,  72,  72,  72,  73,  73,  73,  74,  74,  74,  75,  75,\n",
       "           75,  76,  76,  76,  77,  77,  77,  78,  78,  78,  79,  79,  79,  80,\n",
       "           80,  80,  81,  81,  81,  82,  82,  82,  83,  83,  83,  84,  84,  84,\n",
       "           85,  85,  85,  86,  86,  86,  87,  87,  87,  88,  88,  88,  89,  89,\n",
       "           89,  90,  90,  90,  91,  91,  91,  92,  92,  92,  93,  93,  93,  94,\n",
       "           94,  94,  95,  95,  95,  96,  96,  96,  97,  97,  97,  98,  98,  98,\n",
       "           99,  99,  99, 100, 100, 100, 101, 101, 101, 102, 102, 102, 103, 103,\n",
       "          103, 104, 104, 104, 105, 105, 105, 106, 106, 106, 107, 107, 107, 108,\n",
       "          108, 108, 109, 109, 109, 110, 110, 110, 111, 111, 111, 112, 112, 112,\n",
       "          113, 113, 113, 114, 114, 114, 115, 115, 115, 116, 116, 116, 117, 117,\n",
       "          117, 118, 118, 118, 119, 119, 119, 120, 120, 120, 121, 121, 121, 122,\n",
       "          122, 122, 123, 123, 123, 124, 124, 124, 125, 125, 125, 126, 126, 126,\n",
       "          127, 127, 127, 128, 128, 128, 129, 129, 129, 130, 130, 130, 131, 131,\n",
       "          131, 132, 132, 132, 133, 133, 133, 134, 134, 134, 135, 135, 135, 136,\n",
       "          136, 136, 137, 137, 137, 138, 138, 138, 139, 139, 139, 140, 140, 140,\n",
       "          141, 141, 141, 142, 142, 142, 143, 143, 143, 144, 144, 144, 145, 145,\n",
       "          145, 146, 146, 146, 147, 147, 147, 148, 148, 148, 149, 149, 149, 150,\n",
       "          150, 150, 151, 151, 151, 152, 152, 152, 153, 153, 153, 154, 154, 154,\n",
       "          155, 155, 155, 156, 156, 156, 157, 157, 157, 158, 158, 158, 159, 159,\n",
       "          159, 160, 160, 160, 161, 161, 161, 162, 162, 162, 163, 163, 163, 164,\n",
       "          164, 164, 165, 165, 165, 166, 166, 166, 167, 167, 167, 168, 168, 168,\n",
       "          169, 169, 169, 170, 170, 170, 171, 171, 171, 172, 172, 172, 173, 173,\n",
       "          173, 174, 174, 174, 175, 175, 175, 176, 176, 176, 177, 177, 177, 178,\n",
       "          178, 178, 179, 179, 179, 180, 180, 180, 181, 181, 181, 182, 182, 182,\n",
       "          183, 183, 183, 184, 184, 184, 185, 185, 185, 186, 186, 186, 187, 187,\n",
       "          187, 188, 188, 188, 189, 189, 189, 190, 190, 190, 191, 191, 191, 192,\n",
       "          192, 192, 193, 193, 193, 194, 194, 194, 195, 195, 195, 196, 196, 196,\n",
       "          197, 197, 197, 198, 198, 198, 199, 199, 199, 200, 200, 200, 201, 201,\n",
       "          201, 202, 202, 202, 203, 203, 203, 204, 204, 204, 205, 205, 205, 206,\n",
       "          206, 206, 207, 207, 207, 208, 208, 208, 209, 209, 209, 210, 210, 210,\n",
       "          211, 211, 211, 212, 212, 212, 213, 213, 213, 214, 214, 214, 215, 215,\n",
       "          215, 216, 216, 216, 217, 217, 217, 218, 218, 218, 219, 219, 219, 220,\n",
       "          220, 220, 221, 221, 221, 222, 222, 222, 223, 223, 223, 224, 224, 224,\n",
       "          225, 225, 225, 226, 226, 226, 227, 227, 227, 228, 228, 228, 229, 229,\n",
       "          229, 230, 230, 230, 231, 231, 231, 232, 232, 232, 233, 233, 233, 234,\n",
       "          234, 234, 235, 235, 235, 236, 236, 236, 237, 237, 237, 238, 238, 238,\n",
       "          239, 239, 239, 240, 240, 240, 241, 241, 241, 242, 242, 242, 243, 243,\n",
       "          243, 244, 244, 244, 245, 245, 245, 246, 246, 246, 247, 247, 247, 248,\n",
       "          248, 248, 249, 249, 249, 250, 250, 250, 251, 251, 251, 252, 252, 252,\n",
       "          253, 253, 253, 254, 254, 254, 255, 255, 255, 256, 256, 256, 257, 257,\n",
       "          257, 258, 258, 258, 259, 259, 259, 260, 260, 260, 261, 261, 261, 262,\n",
       "          262, 262, 263, 263, 263, 264, 264, 264, 265, 265, 265, 266, 266, 266,\n",
       "          267, 267, 267, 268, 268, 268, 269, 269, 269, 270, 270, 270, 271, 271,\n",
       "          271, 272, 272, 272, 273, 273, 273, 274, 274, 274, 275, 275, 275, 276,\n",
       "          276, 276, 277, 277, 277, 278, 278, 278, 279, 279, 279, 280, 280, 280,\n",
       "          281, 281, 281, 282, 282, 282, 283, 283, 283, 284, 284, 284, 285, 285,\n",
       "          285, 286, 286, 286, 287, 287, 287, 288, 288, 288, 289, 289, 289, 290,\n",
       "          290, 290, 291, 291, 291, 292, 292, 292, 293, 293, 293, 294, 294, 294,\n",
       "          295, 295, 295, 296, 296, 296, 297, 297, 297, 298, 298, 298, 299, 299,\n",
       "          299, 300, 300, 300, 301, 301, 301, 302, 302, 302, 303, 303, 303, 304,\n",
       "          304, 304, 305, 305, 305, 306, 306, 306, 307, 307, 307, 308, 308, 308,\n",
       "          309, 309, 309, 310, 310, 310]),\n",
       "  tensor([  1,   1,   1,  ..., 396, 396, 396])]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_vtk.tokenize(v_batch, padding=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value_token :\n",
      "tensor([[161, 137, 133, 161, 137, 131, 161, 137, 127, 161],\n",
      "        [135, 162, 130, 135, 162, 126, 135, 153, 130, 135],\n",
      "        [163,  99, 134, 163,  99, 130, 163,  99, 125, 163]])\n",
      "tensor([[132,  95, 137, 128,  95, 137, 125,  95, 137, 123],\n",
      "        [126, 121,  65, 130, 121,  65, 128, 121,  65, 126],\n",
      "        [122,  93,  88, 131,  93,  88, 126,  93,  88, 122]])\n",
      "============================================================\n",
      "coord_type_tokens :\n",
      "tensor([[1, 2, 3, 1, 2, 3, 1, 2, 3, 1],\n",
      "        [1, 2, 3, 1, 2, 3, 1, 2, 3, 1],\n",
      "        [1, 2, 3, 1, 2, 3, 1, 2, 3, 1]])\n",
      "tensor([[3, 1, 2, 3, 1, 2, 3, 1, 2, 3],\n",
      "        [3, 1, 2, 3, 1, 2, 3, 1, 2, 3],\n",
      "        [3, 1, 2, 3, 1, 2, 3, 1, 2, 3]])\n",
      "============================================================\n",
      "position_ids :\n",
      "tensor([[1, 1, 1, 2, 2, 2, 3, 3, 3, 4],\n",
      "        [1, 1, 1, 2, 2, 2, 3, 3, 3, 4],\n",
      "        [1, 1, 1, 2, 2, 2, 3, 3, 3, 4]])\n",
      "tensor([[652, 653, 653, 653, 654, 654, 654, 655, 655, 655],\n",
      "        [307, 308, 308, 308, 309, 309, 309, 310, 310, 310],\n",
      "        [393, 394, 394, 394, 395, 395, 395, 396, 396, 396]])\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "for k, vs in enc_vtk.tokenize(v_batch, padding=False).items():\n",
    "    print(k, \":\")\n",
    "    print(torch.stack([v[:10] for v in vs]))\n",
    "    print(torch.stack([v[-10:] for v in vs]))\n",
    "    print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([160, 136, 132,  ...,  94, 136, 122]),\n",
       " tensor([134, 161, 129, 134, 161, 125, 134, 152, 129, 134, 152, 127, 134, 152,\n",
       "         125, 134, 142, 127, 134, 142, 125, 134, 133, 129, 134, 133, 127, 134,\n",
       "         133, 125, 134, 123, 127, 134, 123, 125, 134, 114, 129, 134, 114, 127,\n",
       "         134, 114, 125, 134, 104, 129, 134, 104, 125, 134,  66, 129, 134,  66,\n",
       "         127, 134,  66, 125, 134,  64, 129, 134,  64, 127, 134,  64, 125, 133,\n",
       "         180, 129, 133, 180, 125, 133, 171, 130, 133, 171, 129, 133, 171, 127,\n",
       "         133, 171, 125, 133, 171, 124, 133, 161, 130, 133, 161, 124, 133, 152,\n",
       "         131, 133, 152, 123, 133, 142, 131, 133, 142, 123, 133, 133, 131, 133,\n",
       "         133, 123, 133, 123, 131, 133, 123, 123, 133, 114, 131, 133, 114, 123,\n",
       "         133, 104, 130, 133, 104, 124, 133,  95, 130, 133,  95, 129, 133,  95,\n",
       "         127, 133,  95, 125, 133,  95, 124, 133,  85, 129, 133,  85, 125, 133,\n",
       "          66, 131, 133,  66, 123, 133,  64, 131, 133,  64, 123, 132, 190, 130,\n",
       "         132, 190, 128, 132, 190, 127, 132, 190, 126, 132, 190, 124, 132, 180,\n",
       "         130, 132, 180, 124, 132, 171, 132, 132, 171, 122, 132, 152, 132, 132,\n",
       "         152, 122, 132, 142, 132, 132, 142, 122, 132, 133, 122, 132, 123, 132,\n",
       "         132, 123, 122, 132, 114, 132, 132, 114, 122, 132,  95, 132, 132,  95,\n",
       "         122, 132,  85, 130, 132,  85, 124, 132,  76, 130, 132,  76, 128, 132,\n",
       "          76, 127, 132,  76, 126, 132,  76, 124, 132,  66, 132, 132,  66, 122,\n",
       "         132,  64, 132, 132,  64, 122, 131, 190, 131, 131, 190, 123, 131, 152,\n",
       "         133, 131, 152, 121, 131, 142, 133, 131, 133, 133, 131, 133, 121, 131,\n",
       "         123, 133, 131, 114, 133, 131, 114, 121, 131,  76, 131, 131,  76, 123,\n",
       "         131,  66, 133, 131,  66, 121, 131,  64, 133, 131,  64, 121, 130, 190,\n",
       "         132, 130, 190, 122, 130, 180, 132, 130, 180, 122, 130, 171, 133, 130,\n",
       "         171, 121, 130, 161, 133, 130, 161, 121, 130, 104, 133, 130, 104, 121,\n",
       "         130,  95, 133, 130,  95, 121, 130,  85, 132, 130,  85, 122, 130,  76,\n",
       "         132, 130,  76, 122, 129, 180, 133, 129, 180, 121, 129, 161, 134, 129,\n",
       "         161, 120, 129, 152, 134, 129, 152, 120, 129, 142, 134, 129, 133, 134,\n",
       "         129, 133, 120, 129, 123, 134, 129, 114, 134, 129, 114, 120, 129, 104,\n",
       "         134, 129, 104, 120, 129,  85, 133, 129,  85, 121, 129,  66, 134, 129,\n",
       "          66, 120, 129,  64, 134, 129,  64, 120, 128, 190, 132, 128, 190, 122,\n",
       "         128,  76, 132, 128,  76, 128, 128,  76, 127, 128,  76, 126, 128,  76,\n",
       "         122, 128,  66, 128, 128,  66, 127, 128,  66, 126, 127, 190, 132, 127,\n",
       "         190, 122, 127, 180, 133, 127, 180, 121, 127, 171, 121, 127, 161, 134,\n",
       "         127, 161, 120, 127, 152, 120, 127, 142, 134, 127, 133, 120, 127, 123,\n",
       "         134, 127, 123, 120, 127, 114, 120, 127, 104, 134, 127, 104, 120, 127,\n",
       "          85, 133, 127,  85, 121, 127,  76, 132, 127,  76, 128, 127,  76, 126,\n",
       "         127,  76, 122, 127,  66, 134, 127,  66, 128, 127,  66, 126, 127,  66,\n",
       "         120, 127,  64, 134, 127,  64, 120, 126, 190, 132, 126, 190, 122, 126,\n",
       "          76, 132, 126,  76, 128, 126,  76, 127, 126,  76, 126, 126,  76, 122,\n",
       "         126,  66, 128, 126,  66, 127, 126,  66, 126, 125, 180, 133, 125, 171,\n",
       "         133, 125, 171, 121, 125, 161, 134, 125, 152, 134, 125, 152, 120, 125,\n",
       "         142, 134, 125, 133, 134, 125, 133, 120, 125, 123, 134, 125, 123, 120,\n",
       "         125, 114, 134, 125, 114, 120, 125, 104, 134, 125, 104, 120, 125,  95,\n",
       "         133, 125,  95, 121, 125,  85, 133, 125,  85, 121, 125,  66, 134, 125,\n",
       "          66, 120, 125,  64, 134, 125,  64, 120, 124, 190, 132, 124, 190, 122,\n",
       "         124, 180, 132, 124, 180, 122, 124, 171, 133, 124, 171, 121, 124, 161,\n",
       "         133, 124, 161, 121, 124, 104, 133, 124, 104, 121, 124,  95, 133, 124,\n",
       "          95, 121, 124,  85, 132, 124,  85, 122, 124,  76, 132, 124,  76, 122,\n",
       "         123, 190, 131, 123, 190, 123, 123, 180, 131, 123, 180, 123, 123, 152,\n",
       "         133, 123, 152, 121, 123, 133, 133, 123, 133, 121, 123, 114, 133, 123,\n",
       "         114, 121, 123,  85, 131, 123,  85, 123, 123,  76, 131, 123,  76, 123,\n",
       "         123,  66, 133, 123,  66, 121, 123,  64, 133, 123,  64, 121, 122, 190,\n",
       "         130, 122, 190, 128, 122, 190, 127, 122, 190, 126, 122, 190, 124, 122,\n",
       "         171, 132, 122, 171, 122, 122, 161, 132, 122, 161, 122, 122, 152, 132,\n",
       "         122, 152, 122, 122, 142, 132, 122, 133, 132, 122, 133, 122, 122, 123,\n",
       "         132, 122, 114, 132, 122, 114, 122, 122, 104, 132, 122, 104, 122, 122,\n",
       "          95, 122, 122,  85, 130, 122,  76, 130, 122,  76, 128, 122,  76, 127,\n",
       "         122,  76, 126, 122,  76, 124, 122,  66, 132, 122,  66, 122, 122,  64,\n",
       "         132, 122,  64, 122, 121, 171, 130, 121, 171, 129, 121, 171, 127, 121,\n",
       "         171, 125, 121, 171, 124, 121, 152, 131, 121, 152, 123, 121, 142, 131,\n",
       "         121, 133, 131, 121, 133, 123, 121, 123, 131, 121, 114, 131, 121, 114,\n",
       "         123, 121, 104, 130, 121,  95, 130, 121,  95, 129, 121,  95, 127, 121,\n",
       "          95, 125, 121,  95, 124, 121,  66, 131, 121,  66, 123, 121,  64, 131,\n",
       "         121,  64, 123, 120, 152, 129, 120, 152, 127, 120, 152, 125, 120, 133,\n",
       "         129, 120, 133, 127, 120, 133, 125, 120, 114, 129, 120, 114, 127, 120,\n",
       "         114, 125, 120,  66, 129, 120,  66, 127, 120,  66, 125, 120,  64, 129,\n",
       "         120,  64, 127, 120,  64, 125]),\n",
       " tensor([162,  98, 133,  ...,  92,  87, 121])]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[v.reshape(-1, ) for v in v_batch]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 頂点デコーダ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecodeVertexTokenizer(Tokenizer):\n",
    "    \n",
    "    def __init__(self, bos_id=0, eos_id=1, pad_id=2):\n",
    "        \n",
    "        self.special_tokens = {\n",
    "            \"bos\": torch.tensor([bos_id]),\n",
    "            \"eos\": torch.tensor([eos_id]),\n",
    "            \"pad\": torch.tensor([pad_id]),\n",
    "        }\n",
    "        self.pad_id = pad_id\n",
    "        self.not_coord_token = torch.tensor([0])\n",
    "    \n",
    "    def tokenize(self, vertices, padding=True):\n",
    "        special_tokens = self.special_tokens\n",
    "        not_coord_token = self.not_coord_token\n",
    "        \n",
    "        vertices = [\n",
    "            torch.cat([\n",
    "                special_tokens[\"bos\"], \n",
    "                v.reshape(-1,)  + len(special_tokens), \n",
    "                special_tokens[\"eos\"]\n",
    "            ])\n",
    "            for v in vertices\n",
    "        ]\n",
    "        \n",
    "        coord_type_tokens = [\n",
    "            torch.cat([\n",
    "                not_coord_token,\n",
    "                torch.arange(len(v)-2) % 3 + 1,\n",
    "                not_coord_token\n",
    "            ])\n",
    "            for v in vertices\n",
    "        ]\n",
    "        \n",
    "        position_ids = [\n",
    "            torch.cat([\n",
    "                not_coord_token,\n",
    "                torch.arange(len(v)-2) // 3 + 1,\n",
    "                not_coord_token\n",
    "            ])\n",
    "            for v in vertices\n",
    "        ]\n",
    "        \n",
    "        if padding:\n",
    "            vertices = torch.stack(self._padding(vertices, special_tokens[\"pad\"]))\n",
    "            coord_type_tokens = torch.stack(self._padding(coord_type_tokens, not_coord_token))\n",
    "            position_ids = torch.stack(self._padding(position_ids, not_coord_token))\n",
    "            padding_mask = self._make_padding_mask(vertices, self.pad_id)\n",
    "            future_mask = self._make_future_mask(vertices)\n",
    "            outputs = {\n",
    "                \"value_tokens\": vertices,\n",
    "                \"coord_type_tokens\": coord_type_tokens,\n",
    "                \"position_ids\": position_ids,\n",
    "                \"padding_mask\": padding_mask,\n",
    "                \"future_mask\": future_mask,\n",
    "            }\n",
    "        else:\n",
    "            outputs = {\n",
    "                \"value_tokens\": vertices,\n",
    "                \"coord_type_tokens\": coord_type_tokens,\n",
    "                \"position_ids\": position_ids,\n",
    "            }\n",
    "            \n",
    "        return outputs\n",
    "    \n",
    "    def detokenize(self, vertices):\n",
    "        special_tokens = self.special_tokens\n",
    "        \n",
    "        result = []\n",
    "        for vertex in vertices:\n",
    "            vertex = vertex - len(special_tokens)\n",
    "            result.append(\n",
    "                vertex[torch.where(vertex >= 0)]\n",
    "            )\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_vtk = DecodeVertexTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'value_tokens': tensor([[  0, 163, 139,  ..., 125,   1,   2],\n",
       "         [  0, 137, 164,  ...,   2,   2,   2],\n",
       "         [  0, 165, 101,  ...,   2,   2,   2]]),\n",
       " 'coord_type_tokens': tensor([[0, 1, 2,  ..., 3, 0, 0],\n",
       "         [0, 1, 2,  ..., 0, 0, 0],\n",
       "         [0, 1, 2,  ..., 0, 0, 0]]),\n",
       " 'position_ids': tensor([[  0,   1,   1,  ..., 655,   0,   0],\n",
       "         [  0,   1,   1,  ...,   0,   0,   0],\n",
       "         [  0,   1,   1,  ...,   0,   0,   0]]),\n",
       " 'padding_mask': tensor([[False, False, False,  ..., False, False,  True],\n",
       "         [False, False, False,  ...,  True,  True,  True],\n",
       "         [False, False, False,  ...,  True,  True,  True]]),\n",
       " 'future_mask': tensor([[0., -inf, -inf,  ..., -inf, -inf, -inf],\n",
       "         [0., 0., -inf,  ..., -inf, -inf, -inf],\n",
       "         [0., 0., 0.,  ..., -inf, -inf, -inf],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., -inf, -inf],\n",
       "         [0., 0., 0.,  ..., 0., 0., -inf],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]])}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec_vtk.tokenize(v_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value_tokens :\n",
      "torch.Size([3, 1968])\n",
      "tensor([[  0, 163, 139, 135, 163, 139, 133, 163, 139, 129],\n",
      "        [  0, 137, 164, 132, 137, 164, 128, 137, 155, 132],\n",
      "        [  0, 165, 101, 136, 165, 101, 132, 165, 101, 127]])\n",
      "tensor([[139, 130,  97, 139, 127,  97, 139, 125,   1,   2],\n",
      "        [  2,   2,   2,   2,   2,   2,   2,   2,   2,   2],\n",
      "        [  2,   2,   2,   2,   2,   2,   2,   2,   2,   2]])\n",
      "============================================================\n",
      "coord_type_tokens :\n",
      "torch.Size([3, 1968])\n",
      "tensor([[0, 1, 2, 3, 1, 2, 3, 1, 2, 3],\n",
      "        [0, 1, 2, 3, 1, 2, 3, 1, 2, 3],\n",
      "        [0, 1, 2, 3, 1, 2, 3, 1, 2, 3]])\n",
      "tensor([[2, 3, 1, 2, 3, 1, 2, 3, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
      "============================================================\n",
      "position_ids :\n",
      "torch.Size([3, 1968])\n",
      "tensor([[0, 1, 1, 1, 2, 2, 2, 3, 3, 3],\n",
      "        [0, 1, 1, 1, 2, 2, 2, 3, 3, 3],\n",
      "        [0, 1, 1, 1, 2, 2, 2, 3, 3, 3]])\n",
      "tensor([[653, 653, 654, 654, 654, 655, 655, 655,   0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0]])\n",
      "============================================================\n",
      "padding_mask :\n",
      "torch.Size([3, 1968])\n",
      "tensor([[False, False, False, False, False, False, False, False, False, False],\n",
      "        [False, False, False, False, False, False, False, False, False, False],\n",
      "        [False, False, False, False, False, False, False, False, False, False]])\n",
      "tensor([[False, False, False, False, False, False, False, False, False,  True],\n",
      "        [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True]])\n",
      "============================================================\n",
      "future_mask :\n",
      "torch.Size([1968, 1968])\n",
      "tensor([[0., -inf, -inf,  ..., -inf, -inf, -inf],\n",
      "        [0., 0., -inf,  ..., -inf, -inf, -inf],\n",
      "        [0., 0., 0.,  ..., -inf, -inf, -inf],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf],\n",
      "        [-inf, -inf, -inf,  ..., -inf, -inf, -inf],\n",
      "        [-inf, -inf, -inf,  ..., -inf, -inf, -inf],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., -inf, -inf],\n",
      "        [0., 0., 0.,  ..., 0., 0., -inf],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "for k, vs in dec_vtk.tokenize(v_batch).items():\n",
    "    print(k, \":\")\n",
    "    print(vs.shape)\n",
    "    print(torch.stack([v[:10] for v in vs]))\n",
    "    print(torch.stack([v[-10:] for v in vs]))\n",
    "    print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'value_tokens': [tensor([  0, 163, 139,  ..., 139, 125,   1]),\n",
       "  tensor([  0, 137, 164, 132, 137, 164, 128, 137, 155, 132, 137, 155, 130, 137,\n",
       "          155, 128, 137, 145, 130, 137, 145, 128, 137, 136, 132, 137, 136, 130,\n",
       "          137, 136, 128, 137, 126, 130, 137, 126, 128, 137, 117, 132, 137, 117,\n",
       "          130, 137, 117, 128, 137, 107, 132, 137, 107, 128, 137,  69, 132, 137,\n",
       "           69, 130, 137,  69, 128, 137,  67, 132, 137,  67, 130, 137,  67, 128,\n",
       "          136, 183, 132, 136, 183, 128, 136, 174, 133, 136, 174, 132, 136, 174,\n",
       "          130, 136, 174, 128, 136, 174, 127, 136, 164, 133, 136, 164, 127, 136,\n",
       "          155, 134, 136, 155, 126, 136, 145, 134, 136, 145, 126, 136, 136, 134,\n",
       "          136, 136, 126, 136, 126, 134, 136, 126, 126, 136, 117, 134, 136, 117,\n",
       "          126, 136, 107, 133, 136, 107, 127, 136,  98, 133, 136,  98, 132, 136,\n",
       "           98, 130, 136,  98, 128, 136,  98, 127, 136,  88, 132, 136,  88, 128,\n",
       "          136,  69, 134, 136,  69, 126, 136,  67, 134, 136,  67, 126, 135, 193,\n",
       "          133, 135, 193, 131, 135, 193, 130, 135, 193, 129, 135, 193, 127, 135,\n",
       "          183, 133, 135, 183, 127, 135, 174, 135, 135, 174, 125, 135, 155, 135,\n",
       "          135, 155, 125, 135, 145, 135, 135, 145, 125, 135, 136, 125, 135, 126,\n",
       "          135, 135, 126, 125, 135, 117, 135, 135, 117, 125, 135,  98, 135, 135,\n",
       "           98, 125, 135,  88, 133, 135,  88, 127, 135,  79, 133, 135,  79, 131,\n",
       "          135,  79, 130, 135,  79, 129, 135,  79, 127, 135,  69, 135, 135,  69,\n",
       "          125, 135,  67, 135, 135,  67, 125, 134, 193, 134, 134, 193, 126, 134,\n",
       "          155, 136, 134, 155, 124, 134, 145, 136, 134, 136, 136, 134, 136, 124,\n",
       "          134, 126, 136, 134, 117, 136, 134, 117, 124, 134,  79, 134, 134,  79,\n",
       "          126, 134,  69, 136, 134,  69, 124, 134,  67, 136, 134,  67, 124, 133,\n",
       "          193, 135, 133, 193, 125, 133, 183, 135, 133, 183, 125, 133, 174, 136,\n",
       "          133, 174, 124, 133, 164, 136, 133, 164, 124, 133, 107, 136, 133, 107,\n",
       "          124, 133,  98, 136, 133,  98, 124, 133,  88, 135, 133,  88, 125, 133,\n",
       "           79, 135, 133,  79, 125, 132, 183, 136, 132, 183, 124, 132, 164, 137,\n",
       "          132, 164, 123, 132, 155, 137, 132, 155, 123, 132, 145, 137, 132, 136,\n",
       "          137, 132, 136, 123, 132, 126, 137, 132, 117, 137, 132, 117, 123, 132,\n",
       "          107, 137, 132, 107, 123, 132,  88, 136, 132,  88, 124, 132,  69, 137,\n",
       "          132,  69, 123, 132,  67, 137, 132,  67, 123, 131, 193, 135, 131, 193,\n",
       "          125, 131,  79, 135, 131,  79, 131, 131,  79, 130, 131,  79, 129, 131,\n",
       "           79, 125, 131,  69, 131, 131,  69, 130, 131,  69, 129, 130, 193, 135,\n",
       "          130, 193, 125, 130, 183, 136, 130, 183, 124, 130, 174, 124, 130, 164,\n",
       "          137, 130, 164, 123, 130, 155, 123, 130, 145, 137, 130, 136, 123, 130,\n",
       "          126, 137, 130, 126, 123, 130, 117, 123, 130, 107, 137, 130, 107, 123,\n",
       "          130,  88, 136, 130,  88, 124, 130,  79, 135, 130,  79, 131, 130,  79,\n",
       "          129, 130,  79, 125, 130,  69, 137, 130,  69, 131, 130,  69, 129, 130,\n",
       "           69, 123, 130,  67, 137, 130,  67, 123, 129, 193, 135, 129, 193, 125,\n",
       "          129,  79, 135, 129,  79, 131, 129,  79, 130, 129,  79, 129, 129,  79,\n",
       "          125, 129,  69, 131, 129,  69, 130, 129,  69, 129, 128, 183, 136, 128,\n",
       "          174, 136, 128, 174, 124, 128, 164, 137, 128, 155, 137, 128, 155, 123,\n",
       "          128, 145, 137, 128, 136, 137, 128, 136, 123, 128, 126, 137, 128, 126,\n",
       "          123, 128, 117, 137, 128, 117, 123, 128, 107, 137, 128, 107, 123, 128,\n",
       "           98, 136, 128,  98, 124, 128,  88, 136, 128,  88, 124, 128,  69, 137,\n",
       "          128,  69, 123, 128,  67, 137, 128,  67, 123, 127, 193, 135, 127, 193,\n",
       "          125, 127, 183, 135, 127, 183, 125, 127, 174, 136, 127, 174, 124, 127,\n",
       "          164, 136, 127, 164, 124, 127, 107, 136, 127, 107, 124, 127,  98, 136,\n",
       "          127,  98, 124, 127,  88, 135, 127,  88, 125, 127,  79, 135, 127,  79,\n",
       "          125, 126, 193, 134, 126, 193, 126, 126, 183, 134, 126, 183, 126, 126,\n",
       "          155, 136, 126, 155, 124, 126, 136, 136, 126, 136, 124, 126, 117, 136,\n",
       "          126, 117, 124, 126,  88, 134, 126,  88, 126, 126,  79, 134, 126,  79,\n",
       "          126, 126,  69, 136, 126,  69, 124, 126,  67, 136, 126,  67, 124, 125,\n",
       "          193, 133, 125, 193, 131, 125, 193, 130, 125, 193, 129, 125, 193, 127,\n",
       "          125, 174, 135, 125, 174, 125, 125, 164, 135, 125, 164, 125, 125, 155,\n",
       "          135, 125, 155, 125, 125, 145, 135, 125, 136, 135, 125, 136, 125, 125,\n",
       "          126, 135, 125, 117, 135, 125, 117, 125, 125, 107, 135, 125, 107, 125,\n",
       "          125,  98, 125, 125,  88, 133, 125,  79, 133, 125,  79, 131, 125,  79,\n",
       "          130, 125,  79, 129, 125,  79, 127, 125,  69, 135, 125,  69, 125, 125,\n",
       "           67, 135, 125,  67, 125, 124, 174, 133, 124, 174, 132, 124, 174, 130,\n",
       "          124, 174, 128, 124, 174, 127, 124, 155, 134, 124, 155, 126, 124, 145,\n",
       "          134, 124, 136, 134, 124, 136, 126, 124, 126, 134, 124, 117, 134, 124,\n",
       "          117, 126, 124, 107, 133, 124,  98, 133, 124,  98, 132, 124,  98, 130,\n",
       "          124,  98, 128, 124,  98, 127, 124,  69, 134, 124,  69, 126, 124,  67,\n",
       "          134, 124,  67, 126, 123, 155, 132, 123, 155, 130, 123, 155, 128, 123,\n",
       "          136, 132, 123, 136, 130, 123, 136, 128, 123, 117, 132, 123, 117, 130,\n",
       "          123, 117, 128, 123,  69, 132, 123,  69, 130, 123,  69, 128, 123,  67,\n",
       "          132, 123,  67, 130, 123,  67, 128,   1]),\n",
       "  tensor([  0, 165, 101,  ...,  90, 124,   1])],\n",
       " 'coord_type_tokens': [tensor([0, 1, 2,  ..., 2, 3, 0]),\n",
       "  tensor([0, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2,\n",
       "          3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2,\n",
       "          3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2,\n",
       "          3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2,\n",
       "          3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2,\n",
       "          3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2,\n",
       "          3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2,\n",
       "          3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2,\n",
       "          3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2,\n",
       "          3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2,\n",
       "          3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2,\n",
       "          3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2,\n",
       "          3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2,\n",
       "          3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2,\n",
       "          3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2,\n",
       "          3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2,\n",
       "          3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2,\n",
       "          3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2,\n",
       "          3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2,\n",
       "          3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2,\n",
       "          3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2,\n",
       "          3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2,\n",
       "          3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2,\n",
       "          3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2,\n",
       "          3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2,\n",
       "          3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2,\n",
       "          3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2,\n",
       "          3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2,\n",
       "          3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2,\n",
       "          3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2,\n",
       "          3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2,\n",
       "          3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2,\n",
       "          3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2,\n",
       "          3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2,\n",
       "          3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2,\n",
       "          3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2,\n",
       "          3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2,\n",
       "          3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2,\n",
       "          3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 0]),\n",
       "  tensor([0, 1, 2,  ..., 2, 3, 0])],\n",
       " 'position_ids': [tensor([  0,   1,   1,  ..., 655, 655,   0]),\n",
       "  tensor([  0,   1,   1,   1,   2,   2,   2,   3,   3,   3,   4,   4,   4,   5,\n",
       "            5,   5,   6,   6,   6,   7,   7,   7,   8,   8,   8,   9,   9,   9,\n",
       "           10,  10,  10,  11,  11,  11,  12,  12,  12,  13,  13,  13,  14,  14,\n",
       "           14,  15,  15,  15,  16,  16,  16,  17,  17,  17,  18,  18,  18,  19,\n",
       "           19,  19,  20,  20,  20,  21,  21,  21,  22,  22,  22,  23,  23,  23,\n",
       "           24,  24,  24,  25,  25,  25,  26,  26,  26,  27,  27,  27,  28,  28,\n",
       "           28,  29,  29,  29,  30,  30,  30,  31,  31,  31,  32,  32,  32,  33,\n",
       "           33,  33,  34,  34,  34,  35,  35,  35,  36,  36,  36,  37,  37,  37,\n",
       "           38,  38,  38,  39,  39,  39,  40,  40,  40,  41,  41,  41,  42,  42,\n",
       "           42,  43,  43,  43,  44,  44,  44,  45,  45,  45,  46,  46,  46,  47,\n",
       "           47,  47,  48,  48,  48,  49,  49,  49,  50,  50,  50,  51,  51,  51,\n",
       "           52,  52,  52,  53,  53,  53,  54,  54,  54,  55,  55,  55,  56,  56,\n",
       "           56,  57,  57,  57,  58,  58,  58,  59,  59,  59,  60,  60,  60,  61,\n",
       "           61,  61,  62,  62,  62,  63,  63,  63,  64,  64,  64,  65,  65,  65,\n",
       "           66,  66,  66,  67,  67,  67,  68,  68,  68,  69,  69,  69,  70,  70,\n",
       "           70,  71,  71,  71,  72,  72,  72,  73,  73,  73,  74,  74,  74,  75,\n",
       "           75,  75,  76,  76,  76,  77,  77,  77,  78,  78,  78,  79,  79,  79,\n",
       "           80,  80,  80,  81,  81,  81,  82,  82,  82,  83,  83,  83,  84,  84,\n",
       "           84,  85,  85,  85,  86,  86,  86,  87,  87,  87,  88,  88,  88,  89,\n",
       "           89,  89,  90,  90,  90,  91,  91,  91,  92,  92,  92,  93,  93,  93,\n",
       "           94,  94,  94,  95,  95,  95,  96,  96,  96,  97,  97,  97,  98,  98,\n",
       "           98,  99,  99,  99, 100, 100, 100, 101, 101, 101, 102, 102, 102, 103,\n",
       "          103, 103, 104, 104, 104, 105, 105, 105, 106, 106, 106, 107, 107, 107,\n",
       "          108, 108, 108, 109, 109, 109, 110, 110, 110, 111, 111, 111, 112, 112,\n",
       "          112, 113, 113, 113, 114, 114, 114, 115, 115, 115, 116, 116, 116, 117,\n",
       "          117, 117, 118, 118, 118, 119, 119, 119, 120, 120, 120, 121, 121, 121,\n",
       "          122, 122, 122, 123, 123, 123, 124, 124, 124, 125, 125, 125, 126, 126,\n",
       "          126, 127, 127, 127, 128, 128, 128, 129, 129, 129, 130, 130, 130, 131,\n",
       "          131, 131, 132, 132, 132, 133, 133, 133, 134, 134, 134, 135, 135, 135,\n",
       "          136, 136, 136, 137, 137, 137, 138, 138, 138, 139, 139, 139, 140, 140,\n",
       "          140, 141, 141, 141, 142, 142, 142, 143, 143, 143, 144, 144, 144, 145,\n",
       "          145, 145, 146, 146, 146, 147, 147, 147, 148, 148, 148, 149, 149, 149,\n",
       "          150, 150, 150, 151, 151, 151, 152, 152, 152, 153, 153, 153, 154, 154,\n",
       "          154, 155, 155, 155, 156, 156, 156, 157, 157, 157, 158, 158, 158, 159,\n",
       "          159, 159, 160, 160, 160, 161, 161, 161, 162, 162, 162, 163, 163, 163,\n",
       "          164, 164, 164, 165, 165, 165, 166, 166, 166, 167, 167, 167, 168, 168,\n",
       "          168, 169, 169, 169, 170, 170, 170, 171, 171, 171, 172, 172, 172, 173,\n",
       "          173, 173, 174, 174, 174, 175, 175, 175, 176, 176, 176, 177, 177, 177,\n",
       "          178, 178, 178, 179, 179, 179, 180, 180, 180, 181, 181, 181, 182, 182,\n",
       "          182, 183, 183, 183, 184, 184, 184, 185, 185, 185, 186, 186, 186, 187,\n",
       "          187, 187, 188, 188, 188, 189, 189, 189, 190, 190, 190, 191, 191, 191,\n",
       "          192, 192, 192, 193, 193, 193, 194, 194, 194, 195, 195, 195, 196, 196,\n",
       "          196, 197, 197, 197, 198, 198, 198, 199, 199, 199, 200, 200, 200, 201,\n",
       "          201, 201, 202, 202, 202, 203, 203, 203, 204, 204, 204, 205, 205, 205,\n",
       "          206, 206, 206, 207, 207, 207, 208, 208, 208, 209, 209, 209, 210, 210,\n",
       "          210, 211, 211, 211, 212, 212, 212, 213, 213, 213, 214, 214, 214, 215,\n",
       "          215, 215, 216, 216, 216, 217, 217, 217, 218, 218, 218, 219, 219, 219,\n",
       "          220, 220, 220, 221, 221, 221, 222, 222, 222, 223, 223, 223, 224, 224,\n",
       "          224, 225, 225, 225, 226, 226, 226, 227, 227, 227, 228, 228, 228, 229,\n",
       "          229, 229, 230, 230, 230, 231, 231, 231, 232, 232, 232, 233, 233, 233,\n",
       "          234, 234, 234, 235, 235, 235, 236, 236, 236, 237, 237, 237, 238, 238,\n",
       "          238, 239, 239, 239, 240, 240, 240, 241, 241, 241, 242, 242, 242, 243,\n",
       "          243, 243, 244, 244, 244, 245, 245, 245, 246, 246, 246, 247, 247, 247,\n",
       "          248, 248, 248, 249, 249, 249, 250, 250, 250, 251, 251, 251, 252, 252,\n",
       "          252, 253, 253, 253, 254, 254, 254, 255, 255, 255, 256, 256, 256, 257,\n",
       "          257, 257, 258, 258, 258, 259, 259, 259, 260, 260, 260, 261, 261, 261,\n",
       "          262, 262, 262, 263, 263, 263, 264, 264, 264, 265, 265, 265, 266, 266,\n",
       "          266, 267, 267, 267, 268, 268, 268, 269, 269, 269, 270, 270, 270, 271,\n",
       "          271, 271, 272, 272, 272, 273, 273, 273, 274, 274, 274, 275, 275, 275,\n",
       "          276, 276, 276, 277, 277, 277, 278, 278, 278, 279, 279, 279, 280, 280,\n",
       "          280, 281, 281, 281, 282, 282, 282, 283, 283, 283, 284, 284, 284, 285,\n",
       "          285, 285, 286, 286, 286, 287, 287, 287, 288, 288, 288, 289, 289, 289,\n",
       "          290, 290, 290, 291, 291, 291, 292, 292, 292, 293, 293, 293, 294, 294,\n",
       "          294, 295, 295, 295, 296, 296, 296, 297, 297, 297, 298, 298, 298, 299,\n",
       "          299, 299, 300, 300, 300, 301, 301, 301, 302, 302, 302, 303, 303, 303,\n",
       "          304, 304, 304, 305, 305, 305, 306, 306, 306, 307, 307, 307, 308, 308,\n",
       "          308, 309, 309, 309, 310, 310, 310,   0]),\n",
       "  tensor([  0,   1,   1,  ..., 396, 396,   0])]}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec_vtk.tokenize(v_batch, padding=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value_tokens :\n",
      "tensor([[  0, 163, 139, 135, 163, 139, 133, 163, 139, 129],\n",
      "        [  0, 137, 164, 132, 137, 164, 128, 137, 155, 132],\n",
      "        [  0, 165, 101, 136, 165, 101, 132, 165, 101, 127]])\n",
      "tensor([[ 97, 139, 130,  97, 139, 127,  97, 139, 125,   1],\n",
      "        [123,  67, 132, 123,  67, 130, 123,  67, 128,   1],\n",
      "        [ 95,  90, 133,  95,  90, 128,  95,  90, 124,   1]])\n",
      "============================================================\n",
      "coord_type_tokens :\n",
      "tensor([[0, 1, 2, 3, 1, 2, 3, 1, 2, 3],\n",
      "        [0, 1, 2, 3, 1, 2, 3, 1, 2, 3],\n",
      "        [0, 1, 2, 3, 1, 2, 3, 1, 2, 3]])\n",
      "tensor([[1, 2, 3, 1, 2, 3, 1, 2, 3, 0],\n",
      "        [1, 2, 3, 1, 2, 3, 1, 2, 3, 0],\n",
      "        [1, 2, 3, 1, 2, 3, 1, 2, 3, 0]])\n",
      "============================================================\n",
      "position_ids :\n",
      "tensor([[0, 1, 1, 1, 2, 2, 2, 3, 3, 3],\n",
      "        [0, 1, 1, 1, 2, 2, 2, 3, 3, 3],\n",
      "        [0, 1, 1, 1, 2, 2, 2, 3, 3, 3]])\n",
      "tensor([[653, 653, 653, 654, 654, 654, 655, 655, 655,   0],\n",
      "        [308, 308, 308, 309, 309, 309, 310, 310, 310,   0],\n",
      "        [394, 394, 394, 395, 395, 395, 396, 396, 396,   0]])\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "for k, vs in dec_vtk.tokenize(v_batch, padding=False).items():\n",
    "    print(k, \":\")\n",
    "    print(torch.stack([v[:10] for v in vs]))\n",
    "    print(torch.stack([v[-10:] for v in vs]))\n",
    "    print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([160, 136, 132,  ...,  94, 136, 122]),\n",
       " tensor([134, 161, 129, 134, 161, 125, 134, 152, 129, 134, 152, 127, 134, 152,\n",
       "         125, 134, 142, 127, 134, 142, 125, 134, 133, 129, 134, 133, 127, 134,\n",
       "         133, 125, 134, 123, 127, 134, 123, 125, 134, 114, 129, 134, 114, 127,\n",
       "         134, 114, 125, 134, 104, 129, 134, 104, 125, 134,  66, 129, 134,  66,\n",
       "         127, 134,  66, 125, 134,  64, 129, 134,  64, 127, 134,  64, 125, 133,\n",
       "         180, 129, 133, 180, 125, 133, 171, 130, 133, 171, 129, 133, 171, 127,\n",
       "         133, 171, 125, 133, 171, 124, 133, 161, 130, 133, 161, 124, 133, 152,\n",
       "         131, 133, 152, 123, 133, 142, 131, 133, 142, 123, 133, 133, 131, 133,\n",
       "         133, 123, 133, 123, 131, 133, 123, 123, 133, 114, 131, 133, 114, 123,\n",
       "         133, 104, 130, 133, 104, 124, 133,  95, 130, 133,  95, 129, 133,  95,\n",
       "         127, 133,  95, 125, 133,  95, 124, 133,  85, 129, 133,  85, 125, 133,\n",
       "          66, 131, 133,  66, 123, 133,  64, 131, 133,  64, 123, 132, 190, 130,\n",
       "         132, 190, 128, 132, 190, 127, 132, 190, 126, 132, 190, 124, 132, 180,\n",
       "         130, 132, 180, 124, 132, 171, 132, 132, 171, 122, 132, 152, 132, 132,\n",
       "         152, 122, 132, 142, 132, 132, 142, 122, 132, 133, 122, 132, 123, 132,\n",
       "         132, 123, 122, 132, 114, 132, 132, 114, 122, 132,  95, 132, 132,  95,\n",
       "         122, 132,  85, 130, 132,  85, 124, 132,  76, 130, 132,  76, 128, 132,\n",
       "          76, 127, 132,  76, 126, 132,  76, 124, 132,  66, 132, 132,  66, 122,\n",
       "         132,  64, 132, 132,  64, 122, 131, 190, 131, 131, 190, 123, 131, 152,\n",
       "         133, 131, 152, 121, 131, 142, 133, 131, 133, 133, 131, 133, 121, 131,\n",
       "         123, 133, 131, 114, 133, 131, 114, 121, 131,  76, 131, 131,  76, 123,\n",
       "         131,  66, 133, 131,  66, 121, 131,  64, 133, 131,  64, 121, 130, 190,\n",
       "         132, 130, 190, 122, 130, 180, 132, 130, 180, 122, 130, 171, 133, 130,\n",
       "         171, 121, 130, 161, 133, 130, 161, 121, 130, 104, 133, 130, 104, 121,\n",
       "         130,  95, 133, 130,  95, 121, 130,  85, 132, 130,  85, 122, 130,  76,\n",
       "         132, 130,  76, 122, 129, 180, 133, 129, 180, 121, 129, 161, 134, 129,\n",
       "         161, 120, 129, 152, 134, 129, 152, 120, 129, 142, 134, 129, 133, 134,\n",
       "         129, 133, 120, 129, 123, 134, 129, 114, 134, 129, 114, 120, 129, 104,\n",
       "         134, 129, 104, 120, 129,  85, 133, 129,  85, 121, 129,  66, 134, 129,\n",
       "          66, 120, 129,  64, 134, 129,  64, 120, 128, 190, 132, 128, 190, 122,\n",
       "         128,  76, 132, 128,  76, 128, 128,  76, 127, 128,  76, 126, 128,  76,\n",
       "         122, 128,  66, 128, 128,  66, 127, 128,  66, 126, 127, 190, 132, 127,\n",
       "         190, 122, 127, 180, 133, 127, 180, 121, 127, 171, 121, 127, 161, 134,\n",
       "         127, 161, 120, 127, 152, 120, 127, 142, 134, 127, 133, 120, 127, 123,\n",
       "         134, 127, 123, 120, 127, 114, 120, 127, 104, 134, 127, 104, 120, 127,\n",
       "          85, 133, 127,  85, 121, 127,  76, 132, 127,  76, 128, 127,  76, 126,\n",
       "         127,  76, 122, 127,  66, 134, 127,  66, 128, 127,  66, 126, 127,  66,\n",
       "         120, 127,  64, 134, 127,  64, 120, 126, 190, 132, 126, 190, 122, 126,\n",
       "          76, 132, 126,  76, 128, 126,  76, 127, 126,  76, 126, 126,  76, 122,\n",
       "         126,  66, 128, 126,  66, 127, 126,  66, 126, 125, 180, 133, 125, 171,\n",
       "         133, 125, 171, 121, 125, 161, 134, 125, 152, 134, 125, 152, 120, 125,\n",
       "         142, 134, 125, 133, 134, 125, 133, 120, 125, 123, 134, 125, 123, 120,\n",
       "         125, 114, 134, 125, 114, 120, 125, 104, 134, 125, 104, 120, 125,  95,\n",
       "         133, 125,  95, 121, 125,  85, 133, 125,  85, 121, 125,  66, 134, 125,\n",
       "          66, 120, 125,  64, 134, 125,  64, 120, 124, 190, 132, 124, 190, 122,\n",
       "         124, 180, 132, 124, 180, 122, 124, 171, 133, 124, 171, 121, 124, 161,\n",
       "         133, 124, 161, 121, 124, 104, 133, 124, 104, 121, 124,  95, 133, 124,\n",
       "          95, 121, 124,  85, 132, 124,  85, 122, 124,  76, 132, 124,  76, 122,\n",
       "         123, 190, 131, 123, 190, 123, 123, 180, 131, 123, 180, 123, 123, 152,\n",
       "         133, 123, 152, 121, 123, 133, 133, 123, 133, 121, 123, 114, 133, 123,\n",
       "         114, 121, 123,  85, 131, 123,  85, 123, 123,  76, 131, 123,  76, 123,\n",
       "         123,  66, 133, 123,  66, 121, 123,  64, 133, 123,  64, 121, 122, 190,\n",
       "         130, 122, 190, 128, 122, 190, 127, 122, 190, 126, 122, 190, 124, 122,\n",
       "         171, 132, 122, 171, 122, 122, 161, 132, 122, 161, 122, 122, 152, 132,\n",
       "         122, 152, 122, 122, 142, 132, 122, 133, 132, 122, 133, 122, 122, 123,\n",
       "         132, 122, 114, 132, 122, 114, 122, 122, 104, 132, 122, 104, 122, 122,\n",
       "          95, 122, 122,  85, 130, 122,  76, 130, 122,  76, 128, 122,  76, 127,\n",
       "         122,  76, 126, 122,  76, 124, 122,  66, 132, 122,  66, 122, 122,  64,\n",
       "         132, 122,  64, 122, 121, 171, 130, 121, 171, 129, 121, 171, 127, 121,\n",
       "         171, 125, 121, 171, 124, 121, 152, 131, 121, 152, 123, 121, 142, 131,\n",
       "         121, 133, 131, 121, 133, 123, 121, 123, 131, 121, 114, 131, 121, 114,\n",
       "         123, 121, 104, 130, 121,  95, 130, 121,  95, 129, 121,  95, 127, 121,\n",
       "          95, 125, 121,  95, 124, 121,  66, 131, 121,  66, 123, 121,  64, 131,\n",
       "         121,  64, 123, 120, 152, 129, 120, 152, 127, 120, 152, 125, 120, 133,\n",
       "         129, 120, 133, 127, 120, 133, 125, 120, 114, 129, 120, 114, 127, 120,\n",
       "         114, 125, 120,  66, 129, 120,  66, 127, 120,  66, 125, 120,  64, 129,\n",
       "         120,  64, 127, 120,  64, 125]),\n",
       " tensor([162,  98, 133,  ...,  92,  87, 121])]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[v.reshape(-1, ) for v in v_batch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([160, 136, 132,  ...,  94, 136, 122]),\n",
       " tensor([134, 161, 129, 134, 161, 125, 134, 152, 129, 134, 152, 127, 134, 152,\n",
       "         125, 134, 142, 127, 134, 142, 125, 134, 133, 129, 134, 133, 127, 134,\n",
       "         133, 125, 134, 123, 127, 134, 123, 125, 134, 114, 129, 134, 114, 127,\n",
       "         134, 114, 125, 134, 104, 129, 134, 104, 125, 134,  66, 129, 134,  66,\n",
       "         127, 134,  66, 125, 134,  64, 129, 134,  64, 127, 134,  64, 125, 133,\n",
       "         180, 129, 133, 180, 125, 133, 171, 130, 133, 171, 129, 133, 171, 127,\n",
       "         133, 171, 125, 133, 171, 124, 133, 161, 130, 133, 161, 124, 133, 152,\n",
       "         131, 133, 152, 123, 133, 142, 131, 133, 142, 123, 133, 133, 131, 133,\n",
       "         133, 123, 133, 123, 131, 133, 123, 123, 133, 114, 131, 133, 114, 123,\n",
       "         133, 104, 130, 133, 104, 124, 133,  95, 130, 133,  95, 129, 133,  95,\n",
       "         127, 133,  95, 125, 133,  95, 124, 133,  85, 129, 133,  85, 125, 133,\n",
       "          66, 131, 133,  66, 123, 133,  64, 131, 133,  64, 123, 132, 190, 130,\n",
       "         132, 190, 128, 132, 190, 127, 132, 190, 126, 132, 190, 124, 132, 180,\n",
       "         130, 132, 180, 124, 132, 171, 132, 132, 171, 122, 132, 152, 132, 132,\n",
       "         152, 122, 132, 142, 132, 132, 142, 122, 132, 133, 122, 132, 123, 132,\n",
       "         132, 123, 122, 132, 114, 132, 132, 114, 122, 132,  95, 132, 132,  95,\n",
       "         122, 132,  85, 130, 132,  85, 124, 132,  76, 130, 132,  76, 128, 132,\n",
       "          76, 127, 132,  76, 126, 132,  76, 124, 132,  66, 132, 132,  66, 122,\n",
       "         132,  64, 132, 132,  64, 122, 131, 190, 131, 131, 190, 123, 131, 152,\n",
       "         133, 131, 152, 121, 131, 142, 133, 131, 133, 133, 131, 133, 121, 131,\n",
       "         123, 133, 131, 114, 133, 131, 114, 121, 131,  76, 131, 131,  76, 123,\n",
       "         131,  66, 133, 131,  66, 121, 131,  64, 133, 131,  64, 121, 130, 190,\n",
       "         132, 130, 190, 122, 130, 180, 132, 130, 180, 122, 130, 171, 133, 130,\n",
       "         171, 121, 130, 161, 133, 130, 161, 121, 130, 104, 133, 130, 104, 121,\n",
       "         130,  95, 133, 130,  95, 121, 130,  85, 132, 130,  85, 122, 130,  76,\n",
       "         132, 130,  76, 122, 129, 180, 133, 129, 180, 121, 129, 161, 134, 129,\n",
       "         161, 120, 129, 152, 134, 129, 152, 120, 129, 142, 134, 129, 133, 134,\n",
       "         129, 133, 120, 129, 123, 134, 129, 114, 134, 129, 114, 120, 129, 104,\n",
       "         134, 129, 104, 120, 129,  85, 133, 129,  85, 121, 129,  66, 134, 129,\n",
       "          66, 120, 129,  64, 134, 129,  64, 120, 128, 190, 132, 128, 190, 122,\n",
       "         128,  76, 132, 128,  76, 128, 128,  76, 127, 128,  76, 126, 128,  76,\n",
       "         122, 128,  66, 128, 128,  66, 127, 128,  66, 126, 127, 190, 132, 127,\n",
       "         190, 122, 127, 180, 133, 127, 180, 121, 127, 171, 121, 127, 161, 134,\n",
       "         127, 161, 120, 127, 152, 120, 127, 142, 134, 127, 133, 120, 127, 123,\n",
       "         134, 127, 123, 120, 127, 114, 120, 127, 104, 134, 127, 104, 120, 127,\n",
       "          85, 133, 127,  85, 121, 127,  76, 132, 127,  76, 128, 127,  76, 126,\n",
       "         127,  76, 122, 127,  66, 134, 127,  66, 128, 127,  66, 126, 127,  66,\n",
       "         120, 127,  64, 134, 127,  64, 120, 126, 190, 132, 126, 190, 122, 126,\n",
       "          76, 132, 126,  76, 128, 126,  76, 127, 126,  76, 126, 126,  76, 122,\n",
       "         126,  66, 128, 126,  66, 127, 126,  66, 126, 125, 180, 133, 125, 171,\n",
       "         133, 125, 171, 121, 125, 161, 134, 125, 152, 134, 125, 152, 120, 125,\n",
       "         142, 134, 125, 133, 134, 125, 133, 120, 125, 123, 134, 125, 123, 120,\n",
       "         125, 114, 134, 125, 114, 120, 125, 104, 134, 125, 104, 120, 125,  95,\n",
       "         133, 125,  95, 121, 125,  85, 133, 125,  85, 121, 125,  66, 134, 125,\n",
       "          66, 120, 125,  64, 134, 125,  64, 120, 124, 190, 132, 124, 190, 122,\n",
       "         124, 180, 132, 124, 180, 122, 124, 171, 133, 124, 171, 121, 124, 161,\n",
       "         133, 124, 161, 121, 124, 104, 133, 124, 104, 121, 124,  95, 133, 124,\n",
       "          95, 121, 124,  85, 132, 124,  85, 122, 124,  76, 132, 124,  76, 122,\n",
       "         123, 190, 131, 123, 190, 123, 123, 180, 131, 123, 180, 123, 123, 152,\n",
       "         133, 123, 152, 121, 123, 133, 133, 123, 133, 121, 123, 114, 133, 123,\n",
       "         114, 121, 123,  85, 131, 123,  85, 123, 123,  76, 131, 123,  76, 123,\n",
       "         123,  66, 133, 123,  66, 121, 123,  64, 133, 123,  64, 121, 122, 190,\n",
       "         130, 122, 190, 128, 122, 190, 127, 122, 190, 126, 122, 190, 124, 122,\n",
       "         171, 132, 122, 171, 122, 122, 161, 132, 122, 161, 122, 122, 152, 132,\n",
       "         122, 152, 122, 122, 142, 132, 122, 133, 132, 122, 133, 122, 122, 123,\n",
       "         132, 122, 114, 132, 122, 114, 122, 122, 104, 132, 122, 104, 122, 122,\n",
       "          95, 122, 122,  85, 130, 122,  76, 130, 122,  76, 128, 122,  76, 127,\n",
       "         122,  76, 126, 122,  76, 124, 122,  66, 132, 122,  66, 122, 122,  64,\n",
       "         132, 122,  64, 122, 121, 171, 130, 121, 171, 129, 121, 171, 127, 121,\n",
       "         171, 125, 121, 171, 124, 121, 152, 131, 121, 152, 123, 121, 142, 131,\n",
       "         121, 133, 131, 121, 133, 123, 121, 123, 131, 121, 114, 131, 121, 114,\n",
       "         123, 121, 104, 130, 121,  95, 130, 121,  95, 129, 121,  95, 127, 121,\n",
       "          95, 125, 121,  95, 124, 121,  66, 131, 121,  66, 123, 121,  64, 131,\n",
       "         121,  64, 123, 120, 152, 129, 120, 152, 127, 120, 152, 125, 120, 133,\n",
       "         129, 120, 133, 127, 120, 133, 125, 120, 114, 129, 120, 114, 127, 120,\n",
       "         114, 125, 120,  66, 129, 120,  66, 127, 120,  66, 125, 120,  64, 129,\n",
       "         120,  64, 127, 120,  64, 125]),\n",
       " tensor([162,  98, 133,  ...,  92,  87, 121])]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = dec_vtk.detokenize(dec_vtk.tokenize(v_batch)[\"value_tokens\"])\n",
    "outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 表面デコーダ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FaceTokenizer(Tokenizer):\n",
    "    \n",
    "    def __init__(self, eof_id=0, eos_id=1, pad_id=2):\n",
    "        self.special_tokens = {\n",
    "            \"eof\": torch.tensor([eof_id]),\n",
    "            \"eos\": torch.tensor([eos_id]),\n",
    "            \"pad\": torch.tensor([pad_id]),\n",
    "        }\n",
    "        self.pad_id = pad_id\n",
    "        self.not_coord_token = torch.tensor([0])\n",
    "        \n",
    "    def tokenize(self, faces, target=False, padding=True):\n",
    "        special_tokens = self.special_tokens\n",
    "        not_coord_token = self.not_coord_token\n",
    "        \n",
    "        \n",
    "        if padding:\n",
    "            faces = [\n",
    "                torch.cat([\n",
    "                    torch.cat([\n",
    "                        f + len(special_tokens),\n",
    "                        special_tokens[\"eof\"].repeat(len(f))[:, None]\n",
    "                    ], dim=1).reshape(-1,),\n",
    "                    special_tokens[\"eos\"]\n",
    "                ]) for f in faces\n",
    "            ]\n",
    "            \n",
    "            coord_type_tokens = [\n",
    "                torch.cat([\n",
    "                    torch.arange(len(f)-1) % 4 + 1,\n",
    "                    not_coord_token\n",
    "                ])\n",
    "                for f in faces\n",
    "            ]\n",
    "\n",
    "            position_ids = [\n",
    "                torch.cat([\n",
    "                    torch.arange(len(f)-1) // 4 + 1,\n",
    "                    not_coord_token\n",
    "                ])\n",
    "                for f in faces\n",
    "            ]\n",
    "            \n",
    "            faces = self._padding(faces, special_tokens[\"pad\"])\n",
    "            \n",
    "            \n",
    "            if target:\n",
    "                faces = [torch.cat([f, special_tokens[\"pad\"]])[1:] for f in faces]\n",
    "                outputs = {\n",
    "                    \"value_tokens\": torch.stack(faces)\n",
    "                }\n",
    "            else: \n",
    "                faces = torch.stack(faces)\n",
    "                coord_type_tokens = torch.stack(self._padding(coord_type_tokens, not_coord_token))\n",
    "                position_ids = torch.stack(self._padding(position_ids, not_coord_token))\n",
    "                \n",
    "                padding_mask = self._make_padding_mask(faces, self.pad_id)\n",
    "                future_mask = self._make_future_mask(faces)\n",
    "                \n",
    "                cond_vertice = faces >= len(special_tokens)\n",
    "                reference_vertices_mask = torch.where(cond_vertice, 1., 0.)\n",
    "                reference_vertices_ids = torch.where(cond_vertice, faces-len(special_tokens), 0)\n",
    "                reference_embed_mask = torch.where(cond_vertice, 0., 1.)\n",
    "                reference_embed_ids = torch.where(cond_vertice, 0, faces)\n",
    "                \n",
    "                outputs = {\n",
    "                    \"value_tokens\": faces,\n",
    "                    \"coord_type_tokens\": coord_type_tokens,\n",
    "                    \"position_ids\": position_ids,\n",
    "                    \"ref_v_mask\": reference_vertices_mask,\n",
    "                    \"ref_v_ids\": reference_vertices_ids,\n",
    "                    \"ref_e_mask\": reference_embed_mask,\n",
    "                    \"ref_e_ids\": reference_embed_ids,\n",
    "                    \"padding_mask\": padding_mask,\n",
    "                    \"future_mask\": future_mask,\n",
    "                }\n",
    "            \n",
    "        else:\n",
    "            faces_ids = []\n",
    "            coord_type_tokens = []\n",
    "            position_ids = []\n",
    "            reference_vertices_mask = []\n",
    "            reference_vertices_ids = []\n",
    "            reference_embed_mask = []\n",
    "            reference_embed_ids = []\n",
    "\n",
    "            for f in faces:\n",
    "                f = torch.cat([\n",
    "                    f + len(special_tokens),\n",
    "                    special_tokens[\"eof\"].repeat(len(f))[:, None]\n",
    "                ], dim=1).reshape(-1, )\n",
    "                f = torch.cat([f, special_tokens[\"eos\"]])\n",
    "                \n",
    "                c_t_tokens = torch.cat([\n",
    "                    torch.arange(len(f)-1) % 4 + 1,\n",
    "                    not_coord_token\n",
    "                ])\n",
    "                pos_ids = torch.cat([\n",
    "                    torch.arange(len(f)-1) // 4 + 1,\n",
    "                    not_coord_token\n",
    "                ])\n",
    "                \n",
    "                if target:\n",
    "                    f = torch.cat([f, special_tokens[\"pad\"]])[1:]\n",
    "                \n",
    "                cond_vertice = f >= len(special_tokens)\n",
    "\n",
    "                ref_v_mask = torch.where(cond_vertice, 1., 0.)\n",
    "                ref_e_mask = torch.where(cond_vertice, 0., 1.)\n",
    "                ref_v_ids = torch.where(cond_vertice, f-len(special_tokens), 0)\n",
    "                ref_e_ids = torch.where(cond_vertice, 0, f)\n",
    "\n",
    "                faces_ids.append(f)\n",
    "                coord_type_tokens.append(c_t_tokens)\n",
    "                position_ids.append(pos_ids)\n",
    "                \n",
    "                reference_vertices_mask.append(ref_v_mask)\n",
    "                reference_vertices_ids.append(ref_v_ids)\n",
    "                reference_embed_mask.append(ref_e_mask)\n",
    "                reference_embed_ids.append(ref_e_ids)\n",
    "            \n",
    "            if target:\n",
    "                faces_ids = [torch.cat([f, special_tokens[\"pad\"]])[1:] for f in faces_ids]\n",
    "                outputs = {\n",
    "                    \"value_tokens\": faces_ids\n",
    "                }\n",
    "            else:\n",
    "                outputs = {\n",
    "                    \"value_tokens\": faces_ids,\n",
    "                    \"coord_type_tokens\": coord_type_tokens,\n",
    "                    \"position_ids\": position_ids,\n",
    "                    \"ref_v_mask\": reference_vertices_mask,\n",
    "                    \"ref_v_ids\": reference_vertices_ids,\n",
    "                    \"ref_e_mask\": reference_embed_mask,\n",
    "                    \"ref_e_ids\": reference_embed_ids,\n",
    "                }\n",
    "        \n",
    "        return outputs\n",
    "\n",
    "    def detokenize(self, faces):\n",
    "        special_tokens = self.special_tokens\n",
    "        \n",
    "        result = []\n",
    "        for face in faces:\n",
    "            face = face - len(special_tokens)\n",
    "            result.append(\n",
    "                face[torch.where(face >= 0)]\n",
    "            )\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "ftk = FaceTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value_tokens :\n",
      "torch.Size([3, 5270])\n",
      "tensor([[  3,   4, 156,   0,   3,   9, 106,   0,   3,   9],\n",
      "        [  3,   5,  29,   0,   3,   5,  33,   0,   3,  29],\n",
      "        [  3,   3,   4,   0,   3,   3,  12,   0,   3,   4]])\n",
      "tensor([[651, 655, 657,   0, 655, 656, 657,   0,   1,   2],\n",
      "        [  2,   2,   2,   2,   2,   2,   2,   2,   2,   2],\n",
      "        [  2,   2,   2,   2,   2,   2,   2,   2,   2,   2]])\n",
      "============================================================\n",
      "coord_type_tokens :\n",
      "torch.Size([3, 5270])\n",
      "tensor([[1, 2, 3, 4, 1, 2, 3, 4, 1, 2],\n",
      "        [1, 2, 3, 4, 1, 2, 3, 4, 1, 2],\n",
      "        [1, 2, 3, 4, 1, 2, 3, 4, 1, 2]])\n",
      "tensor([[1, 2, 3, 4, 1, 2, 3, 4, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
      "============================================================\n",
      "position_ids :\n",
      "torch.Size([3, 5270])\n",
      "tensor([[1, 1, 1, 1, 2, 2, 2, 2, 3, 3],\n",
      "        [1, 1, 1, 1, 2, 2, 2, 2, 3, 3],\n",
      "        [1, 1, 1, 1, 2, 2, 2, 2, 3, 3]])\n",
      "tensor([[1316, 1316, 1316, 1316, 1317, 1317, 1317, 1317,    0,    0],\n",
      "        [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
      "        [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0]])\n",
      "============================================================\n",
      "ref_v_mask :\n",
      "torch.Size([3, 5270])\n",
      "tensor([[1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 1., 1., 0., 1., 1., 1., 0., 1., 1.]])\n",
      "tensor([[1., 1., 1., 0., 1., 1., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "============================================================\n",
      "ref_v_ids :\n",
      "torch.Size([3, 5270])\n",
      "tensor([[  0,   1, 153,   0,   0,   6, 103,   0,   0,   6],\n",
      "        [  0,   2,  26,   0,   0,   2,  30,   0,   0,  26],\n",
      "        [  0,   0,   1,   0,   0,   0,   9,   0,   0,   1]])\n",
      "tensor([[648, 652, 654,   0, 652, 653, 654,   0,   0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0]])\n",
      "============================================================\n",
      "ref_e_mask :\n",
      "torch.Size([3, 5270])\n",
      "tensor([[0., 0., 0., 1., 0., 0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0., 0., 1., 0., 0.]])\n",
      "tensor([[0., 0., 0., 1., 0., 0., 0., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]])\n",
      "============================================================\n",
      "ref_e_ids :\n",
      "torch.Size([3, 5270])\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 1, 2],\n",
      "        [2, 2, 2, 2, 2, 2, 2, 2, 2, 2],\n",
      "        [2, 2, 2, 2, 2, 2, 2, 2, 2, 2]])\n",
      "============================================================\n",
      "padding_mask :\n",
      "torch.Size([3, 5270])\n",
      "tensor([[False, False, False, False, False, False, False, False, False, False],\n",
      "        [False, False, False, False, False, False, False, False, False, False],\n",
      "        [False, False, False, False, False, False, False, False, False, False]])\n",
      "tensor([[False, False, False, False, False, False, False, False, False,  True],\n",
      "        [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True]])\n",
      "============================================================\n",
      "future_mask :\n",
      "torch.Size([5270, 5270])\n",
      "tensor([[0., -inf, -inf,  ..., -inf, -inf, -inf],\n",
      "        [0., 0., -inf,  ..., -inf, -inf, -inf],\n",
      "        [0., 0., 0.,  ..., -inf, -inf, -inf],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf],\n",
      "        [-inf, -inf, -inf,  ..., -inf, -inf, -inf],\n",
      "        [-inf, -inf, -inf,  ..., -inf, -inf, -inf],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., -inf, -inf],\n",
      "        [0., 0., 0.,  ..., 0., 0., -inf],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "for k, vs in ftk.tokenize(f_batch).items():\n",
    "    print(k, \":\")\n",
    "    print(vs.shape)\n",
    "    print(torch.stack([v[:10] for v in vs]))\n",
    "    print(torch.stack([v[-10:] for v in vs]))\n",
    "    print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'value_tokens': tensor([[  4, 156,   0,  ...,   1,   2,   2],\n",
       "         [  5,  29,   0,  ...,   2,   2,   2],\n",
       "         [  3,   4,   0,  ...,   2,   2,   2]])}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ftk.tokenize(f_batch, target=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value_tokens :\n",
      "tensor([[  3,   4, 156,   0,   3,   9, 106,   0,   3,   9],\n",
      "        [  3,   5,  29,   0,   3,   5,  33,   0,   3,  29],\n",
      "        [  3,   3,   4,   0,   3,   3,  12,   0,   3,   4]])\n",
      "tensor([[  0, 651, 655, 657,   0, 655, 656, 657,   0,   1],\n",
      "        [  0, 308, 310, 311,   0, 309, 311, 312,   0,   1],\n",
      "        [  0, 394, 395, 398,   0, 394, 397, 398,   0,   1]])\n",
      "============================================================\n",
      "coord_type_tokens :\n",
      "tensor([[1, 2, 3, 4, 1, 2, 3, 4, 1, 2],\n",
      "        [1, 2, 3, 4, 1, 2, 3, 4, 1, 2],\n",
      "        [1, 2, 3, 4, 1, 2, 3, 4, 1, 2]])\n",
      "tensor([[4, 1, 2, 3, 4, 1, 2, 3, 4, 0],\n",
      "        [4, 1, 2, 3, 4, 1, 2, 3, 4, 0],\n",
      "        [4, 1, 2, 3, 4, 1, 2, 3, 4, 0]])\n",
      "============================================================\n",
      "position_ids :\n",
      "tensor([[1, 1, 1, 1, 2, 2, 2, 2, 3, 3],\n",
      "        [1, 1, 1, 1, 2, 2, 2, 2, 3, 3],\n",
      "        [1, 1, 1, 1, 2, 2, 2, 2, 3, 3]])\n",
      "tensor([[1315, 1316, 1316, 1316, 1316, 1317, 1317, 1317, 1317,    0],\n",
      "        [ 674,  675,  675,  675,  675,  676,  676,  676,  676,    0],\n",
      "        [1182, 1183, 1183, 1183, 1183, 1184, 1184, 1184, 1184,    0]])\n",
      "============================================================\n",
      "ref_v_mask :\n",
      "tensor([[1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 1., 1., 0., 1., 1., 1., 0., 1., 1.]])\n",
      "tensor([[0., 1., 1., 1., 0., 1., 1., 1., 0., 0.],\n",
      "        [0., 1., 1., 1., 0., 1., 1., 1., 0., 0.],\n",
      "        [0., 1., 1., 1., 0., 1., 1., 1., 0., 0.]])\n",
      "============================================================\n",
      "ref_v_ids :\n",
      "tensor([[  0,   1, 153,   0,   0,   6, 103,   0,   0,   6],\n",
      "        [  0,   2,  26,   0,   0,   2,  30,   0,   0,  26],\n",
      "        [  0,   0,   1,   0,   0,   0,   9,   0,   0,   1]])\n",
      "tensor([[  0, 648, 652, 654,   0, 652, 653, 654,   0,   0],\n",
      "        [  0, 305, 307, 308,   0, 306, 308, 309,   0,   0],\n",
      "        [  0, 391, 392, 395,   0, 391, 394, 395,   0,   0]])\n",
      "============================================================\n",
      "ref_e_mask :\n",
      "tensor([[0., 0., 0., 1., 0., 0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0., 0., 1., 0., 0.]])\n",
      "tensor([[1., 0., 0., 0., 1., 0., 0., 0., 1., 1.],\n",
      "        [1., 0., 0., 0., 1., 0., 0., 0., 1., 1.],\n",
      "        [1., 0., 0., 0., 1., 0., 0., 0., 1., 1.]])\n",
      "============================================================\n",
      "ref_e_ids :\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]])\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "for k, vs in ftk.tokenize(f_batch, padding=False).items():\n",
    "    print(k, \":\")\n",
    "    print(torch.stack([v[:10] for v in vs]))\n",
    "    print(torch.stack([v[-10:] for v in vs]))\n",
    "    print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'value_tokens': [tensor([156,   0,   3,  ...,   1,   2,   2]),\n",
       "  tensor([29,  0,  3,  ...,  1,  2,  2]),\n",
       "  tensor([4, 0, 3,  ..., 1, 2, 2])]}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ftk.tokenize(f_batch, padding=False, target=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([  0,   1, 153,  ..., 652, 653, 654]),\n",
       " tensor([  0,   2,  26,  ..., 306, 308, 309]),\n",
       " tensor([  0,   0,   1,  ..., 391, 394, 395])]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = ftk.detokenize(ftk.tokenize(f_batch)[\"value_tokens\"])\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3dEnv",
   "language": "python",
   "name": "3denv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
