{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import glob\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from reformer_pytorch import Reformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7003 1088\n"
     ]
    }
   ],
   "source": [
    "base_dir = os.path.dirname(os.getcwd())\n",
    "data_dir = os.path.join(base_dir, \"data\", \"original\")\n",
    "train_files = glob.glob(os.path.join(data_dir, \"train\", \"*\", \"*.obj\"))\n",
    "valid_files = glob.glob(os.path.join(data_dir, \"val\", \"*\", \"*.obj\"))\n",
    "print(len(train_files), len(valid_files))\n",
    "\n",
    "src_dir = os.path.join(base_dir, \"src\")\n",
    "sys.path.append(os.path.join(src_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import load_pipeline\n",
    "from tokenizers import DecodeVertexTokenizer, FaceTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([655, 3]) torch.Size([1317, 3])\n",
      "============================================================\n",
      "torch.Size([310, 3]) torch.Size([676, 3])\n",
      "============================================================\n",
      "torch.Size([396, 3]) torch.Size([1184, 3])\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "v_batch, f_batch = [], []\n",
    "for i in range(3):\n",
    "    v, f = load_pipeline(train_files[i])\n",
    "    v = torch.tensor(v)\n",
    "    f = torch.tensor(f)\n",
    "    v_batch.append(v)\n",
    "    f_batch.append(f)\n",
    "    print(v.shape, f.shape)\n",
    "    print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_tokenizer = DecodeVertexTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'value_tokens': tensor([[  0, 163, 139,  ..., 125,   1,   2],\n",
       "         [  0, 137, 164,  ...,   2,   2,   2],\n",
       "         [  0, 165, 101,  ...,   2,   2,   2]]),\n",
       " 'target_tokens': tensor([[163, 139, 135,  ...,   1,   2,   2],\n",
       "         [137, 164, 132,  ...,   2,   2,   2],\n",
       "         [165, 101, 136,  ...,   2,   2,   2]]),\n",
       " 'coord_type_tokens': tensor([[0, 1, 2,  ..., 3, 0, 0],\n",
       "         [0, 1, 2,  ..., 0, 0, 0],\n",
       "         [0, 1, 2,  ..., 0, 0, 0]]),\n",
       " 'position_tokens': tensor([[  0,   1,   1,  ..., 655,   0,   0],\n",
       "         [  0,   1,   1,  ...,   0,   0,   0],\n",
       "         [  0,   1,   1,  ...,   0,   0,   0]]),\n",
       " 'padding_mask': tensor([[False, False, False,  ..., False, False,  True],\n",
       "         [False, False, False,  ...,  True,  True,  True],\n",
       "         [False, False, False,  ...,  True,  True,  True]])}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_tokens = dec_tokenizer.tokenize(v_batch)\n",
    "input_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VertexEmbedding(nn.Module):\n",
    "    \n",
    "    def __init__(self, \n",
    "                 vocab_value=256, pad_idx_value=2, \n",
    "                 vocab_coord_type=4, pad_idx_coord_type=0,\n",
    "                 vocab_position=1000, embed_dim=256):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.value_embed = nn.Embedding(\n",
    "            vocab_value, embed_dim, padding_idx=pad_idx_value\n",
    "        )\n",
    "        self.coord_type_embed = nn.Embedding(\n",
    "            vocab_coord_type, embed_dim, padding_idx=pad_idx_coord_type\n",
    "        )\n",
    "        self.position_embed = nn.Embedding(\n",
    "            vocab_position, embed_dim\n",
    "        )\n",
    "        \n",
    "    def forward(self, value_tokens, coord_type_tokens, position_tokens):\n",
    "        embed = self.value_embed(value_tokens)\n",
    "        embed = embed + self.coord_type_embed(coord_type_tokens)\n",
    "        embed = embed + self.position_embed(position_tokens)\n",
    "        return embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed = VertexEmbedding(embed_dim=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'value_tokens': tensor([[  0, 163, 139,  ..., 125,   1,   2],\n",
       "         [  0, 137, 164,  ...,   2,   2,   2],\n",
       "         [  0, 165, 101,  ...,   2,   2,   2]]),\n",
       " 'target_tokens': tensor([[163, 139, 135,  ...,   1,   2,   2],\n",
       "         [137, 164, 132,  ...,   2,   2,   2],\n",
       "         [165, 101, 136,  ...,   2,   2,   2]]),\n",
       " 'coord_type_tokens': tensor([[0, 1, 2,  ..., 3, 0, 0],\n",
       "         [0, 1, 2,  ..., 0, 0, 0],\n",
       "         [0, 1, 2,  ..., 0, 0, 0]]),\n",
       " 'position_tokens': tensor([[  0,   1,   1,  ..., 655,   0,   0],\n",
       "         [  0,   1,   1,  ...,   0,   0,   0],\n",
       "         [  0,   1,   1,  ...,   0,   0,   0]]),\n",
       " 'padding_mask': tensor([[False, False, False,  ..., False, False,  True],\n",
       "         [False, False, False,  ...,  True,  True,  True],\n",
       "         [False, False, False,  ...,  True,  True,  True]])}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 1968]) torch.Size([3, 1968]) torch.Size([3, 1968])\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    input_tokens[\"value_tokens\"].shape,\n",
    "    input_tokens[\"coord_type_tokens\"].shape,\n",
    "    input_tokens[\"position_tokens\"].shape\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1968, 128])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb = embed(\n",
    "    input_tokens[\"value_tokens\"], \n",
    "    input_tokens[\"coord_type_tokens\"], \n",
    "    input_tokens[\"position_tokens\"]\n",
    ")\n",
    "emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "reformer = Reformer(dim=128, depth=2, max_seq_len=8192, bucket_size=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1968, 128])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = reformer(emb)\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config(object):\n",
    "    \n",
    "    def write_to_json(self, out_path):\n",
    "        with open(out_path, \"w\") as fw:\n",
    "            json.dump(self.config, fw, indent=4)\n",
    "            \n",
    "    def __getitem__(self, key):\n",
    "        return self.config[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VertexPolyGenConfig(Config):\n",
    "    \n",
    "    def __init__(self,\n",
    "                 embed_dim=256, \n",
    "                 max_seq_len=2400, \n",
    "                 tokenizer__bos_id=0,\n",
    "                 tokenizer__eos_id=1,\n",
    "                 tokenizer__pad_id=2,\n",
    "                 embedding__vocab_value=256 + 3, \n",
    "                 embedding__vocab_coord_type=4, \n",
    "                 embedding__vocab_position=1000, \n",
    "                 embedding__pad_idx_coord_type=0,\n",
    "                 embedding__pad_idx_value=2,\n",
    "                 reformer__depth=12,\n",
    "                 reformer__heads=8,\n",
    "                 reformer__n_hashes=8,\n",
    "                 reformer__bucket_size=48,\n",
    "                 reformer__causal=True,\n",
    "                 reformer__lsh_dropout=0.2, \n",
    "                 reformer__ff_dropout=0.2,\n",
    "                 reformer__post_attn_dropout=0.2,\n",
    "                 reformer__ff_mult=4):\n",
    "        \n",
    "        # tokenizer config\n",
    "        tokenizer_config = {\n",
    "            \"bos_id\": tokenizer__bos_id,\n",
    "            \"eos_id\": tokenizer__eos_id,\n",
    "            \"pad_id\": tokenizer__pad_id,\n",
    "            \"max_seq_len\": max_seq_len,\n",
    "        }\n",
    "        \n",
    "        # embedding config\n",
    "        embedding_config = {\n",
    "            \"vocab_value\": embedding__vocab_value,\n",
    "            \"vocab_coord_type\": embedding__vocab_coord_type,\n",
    "            \"vocab_position\": embedding__vocab_position,\n",
    "            \"pad_idx_value\": embedding__pad_idx_value,\n",
    "            \"pad_idx_coord_type\": embedding__pad_idx_coord_type,\n",
    "            \"embed_dim\": embed_dim,\n",
    "        }\n",
    "        \n",
    "        # reformer info\n",
    "        reformer_config = {\n",
    "            \"dim\": embed_dim,\n",
    "            \"depth\": reformer__depth,\n",
    "            \"max_seq_len\": max_seq_len,\n",
    "            \"heads\": reformer__heads,\n",
    "            \"bucket_size\": reformer__bucket_size,\n",
    "            \"n_hashes\": reformer__n_hashes,\n",
    "            \"causal\": reformer__causal,\n",
    "            \"lsh_dropout\": reformer__lsh_dropout, \n",
    "            \"ff_dropout\": reformer__ff_dropout,\n",
    "            \"post_attn_dropout\": reformer__post_attn_dropout,\n",
    "            \"ff_mult\": reformer__ff_mult,\n",
    "        }\n",
    "        \n",
    "        self.config = {\n",
    "            \"embed_dim\": embed_dim,\n",
    "            \"max_seq_len\": max_seq_len,\n",
    "            \"tokenizer\": tokenizer_config,\n",
    "            \"embedding\": embedding_config,\n",
    "            \"reformer\": reformer_config,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VertexPolyGen(nn.Module):\n",
    "    \n",
    "    def __init__(self, model_config):\n",
    "        super().__init__()\n",
    "        self.tokenizer = DecodeVertexTokenizer(**model_config[\"tokenizer\"])\n",
    "        self.embedding = VertexEmbedding(**model_config[\"embedding\"])\n",
    "        self.reformer = Reformer(**model_config[\"reformer\"])\n",
    "        self.layernorm = nn.LayerNorm(model_config[\"embed_dim\"])\n",
    "        self.loss_func = nn.CrossEntropyLoss(ignore_index=model_config[\"tokenizer\"][\"pad_id\"])\n",
    "    \n",
    "    def forward(self, tokens, device=None):\n",
    "        \n",
    "        hs = self.embedding(\n",
    "            tokens[\"value_tokens\"], \n",
    "            tokens[\"coord_type_tokens\"], \n",
    "            tokens[\"position_tokens\"]\n",
    "        )\n",
    "        \n",
    "        hs = self.reformer(\n",
    "            hs, input_mask=tokens[\"padding_mask\"]\n",
    "        )\n",
    "        hs = self.layernorm(hs)\n",
    "        \n",
    "        return hs\n",
    "        \n",
    "    def __call__(self, inputs, device=None):\n",
    "        tokens = self.tokenizer.tokenize(inputs)\n",
    "        tokens = {k: v.to(device) for k, v in tokens.items()}\n",
    "        \n",
    "        hs = self.forward(tokens, device=device)\n",
    "        hs = F.linear(hs, self.embedding.value_embed.weight)\n",
    "        BATCH, LENGTH, EMBED = hs.shape\n",
    "        hs = hs.reshape(BATCH*LENGTH, EMBED)\n",
    "        targets = tokens[\"target_tokens\"].reshape(BATCH*LENGTH,)\n",
    "        \n",
    "        loss = self.loss_func(hs, targets)\n",
    "        return loss\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def predict(self, max_seq_len=2400, device=None):\n",
    "        tokenizer = self.tokenizer\n",
    "        special_tokens = tokenizer.special_tokens\n",
    "        \n",
    "        tokens = tokenizer.get_pred_start()\n",
    "        tokens = {k: v.to(device) for k, v in tokens.items()}\n",
    "        preds = []\n",
    "        pred_idx = 0\n",
    "        \n",
    "        while (pred_idx <= max_seq_len-1)\\\n",
    "        and ((len(preds) == 0) or (preds[-1] != special_tokens[\"eos\"]-len(special_tokens))):\n",
    "            \n",
    "            if pred_idx >= 1:\n",
    "                tokens = tokenizer.tokenize([torch.stack(preds)])\n",
    "                tokens[\"value_tokens\"][:, pred_idx+1] = special_tokens[\"pad\"]\n",
    "                tokens[\"padding_mask\"][:, pred_idx+1] = True\n",
    "            \n",
    "            try:\n",
    "                hs = self.forward(tokens, device=device)\n",
    "            except IndexError:\n",
    "                print(pred_idx)\n",
    "                for k, v in tokens.items():\n",
    "                    print(k)\n",
    "                    print(v.shape)\n",
    "                    print(v)\n",
    "                import traceback\n",
    "                print(traceback.format_exc())\n",
    "                break\n",
    "\n",
    "            hs = F.linear(hs[:, pred_idx], self.embedding.value_embed.weight)\n",
    "            pred = hs.argmax(dim=1) - len(special_tokens)\n",
    "            preds.append(pred[0])\n",
    "            pred_idx += 1\n",
    "            \n",
    "        return torch.stack(preds) + len(special_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = VertexPolyGenConfig(embed_dim=64, reformer__depth=1)\n",
    "model = VertexPolyGen(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Trying to create tensor with negative dimension -1: [-1]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-126-e077e8eba777>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_seq_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2400\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.2.0/envs/3dEnv/lib/python3.7/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-124-4c46b574b16f>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, max_seq_len, device)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpred_idx\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m                 \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m                 \u001b[0mtokens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"value_tokens\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_idx\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspecial_tokens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"pad\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m                 \u001b[0mtokens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"padding_mask\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_idx\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Github/porijen_pytorch/src/tokenizers/vertex.py\u001b[0m in \u001b[0;36mtokenize\u001b[0;34m(self, vertices, padding)\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m             vertices = torch.stack(\n\u001b[0;32m---> 95\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_padding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvertices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspecial_tokens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"pad\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_seq_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m             )\n\u001b[1;32m     97\u001b[0m             vertices_target = torch.stack(\n",
      "\u001b[0;32m~/Desktop/Github/porijen_pytorch/src/tokenizers/base.py\u001b[0m in \u001b[0;36m_padding\u001b[0;34m(self, ids_tensor, pad_token, max_length)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0mids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad_token\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_length\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mids\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             ])\n\u001b[0;32m---> 15\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mids\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mids_tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         ]\n\u001b[1;32m     17\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mids_tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Github/porijen_pytorch/src/tokenizers/base.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0mids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad_token\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_length\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mids\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             ])\n\u001b[0;32m---> 15\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mids\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mids_tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         ]\n\u001b[1;32m     17\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mids_tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Trying to create tensor with negative dimension -1: [-1]"
     ]
    }
   ],
   "source": [
    "model.predict(max_seq_len=2400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model(v_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'value_tokens': tensor([[0, 3, 1, 2]]),\n",
       " 'target_tokens': tensor([[3, 1, 2, 2]]),\n",
       " 'coord_type_tokens': tensor([[0, 1, 0, 0]]),\n",
       " 'position_tokens': tensor([[0, 1, 0, 0]]),\n",
       " 'padding_mask': tensor([[False, False, False,  True]])}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec_tokenizer.tokenize([torch.tensor([0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3dEnv",
   "language": "python",
   "name": "3denv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
